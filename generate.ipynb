{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/venv/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# import streamlit as st\n",
    "from PIL import Image\n",
    "from data.dataset import ClassifierDataset,TransformerDatasetREMI\n",
    "import random\n",
    "from config import *\n",
    "from transformer_generator import *\n",
    "from torch.nn.functional import softmax\n",
    "from data.process_data import MIDIEncoderREMI\n",
    "import os\n",
    "from music21 import converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ece661-final-proj2/data/dataset.py:239: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  self.sequences = torch.Tensor(self.sequences)\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 256\n",
    "single_file_dataset_path = \"data/single_file_dataset.npz\"\n",
    "classifier_dataset = ClassifierDataset(single_file_dataset_path, seq_len=max_seq_len, labels_path=\"data/emopia/EMOPIA_2.2/label.csv\")\n",
    "generator_dataset = TransformerDatasetREMI(single_file_dataset_path, seq_len=max_seq_len)\n",
    "\n",
    "Q1, Q2, Q3, Q4 = [], [], [], []\n",
    "for dic in classifier_dataset:\n",
    "    label = dic['target']\n",
    "    if label == 0:\n",
    "        Q1.append(dic)\n",
    "    elif label == 1:\n",
    "        Q2.append(dic)\n",
    "    elif label == 2:\n",
    "        Q3.append(dic)\n",
    "    elif label == 3:\n",
    "        Q4.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model1 = TransformerModel(MAX_SEQ_LEN, VOCAB_SIZE, EMSIZE, NHEAD, D_HID, NLAYERS, dropout = 0.1).to(device)\n",
    "# model2 = Transformer(VOCAB_SIZE, VOCAB_SIZE, EMSIZE, NHEAD, NLAYERS, D_HID, MAX_SEQ_LEN, dropout=0.2).to(device)\n",
    "# model3 = Generator(VOCAB_SIZE, MAX_SEQ_LEN, EMSIZE, D_HID, NHEAD, NLAYERS, dropout=0.2).to(device)\n",
    "\n",
    "model1.load_state_dict(torch.load('checkpoints/transformer_v3.pt'))\n",
    "model2.load_state_dict(torch.load('checkpoints/transformer.pt'))\n",
    "model3.load_state_dict(torch.load('checkpoints/generator.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(emotion = None):\n",
    "    # Generate music based on the selected emotion\n",
    "\n",
    "    if emotion is None:\n",
    "        data = random.choice(generator_dataset)\n",
    "        input = data['input'].to(device)\n",
    "        target = data['target'].to(device)\n",
    "    else:\n",
    "        if emotion == 'Happy':\n",
    "            dic = random.choice(Q1)\n",
    "        elif emotion == 'Sad':\n",
    "            dic = random.choice(Q2)\n",
    "        elif emotion == 'Angry':\n",
    "            dic = random.choice(Q3)\n",
    "        elif emotion == 'Peaceful':\n",
    "            dic = random.choice(Q4)\n",
    "        input = dic['input'].to(device)\n",
    "        target = torch.cat((input[1:], torch.tensor([0],dtype=torch.long).to(device)))\n",
    "\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    model3.eval()\n",
    "\n",
    "    # current_token = start_token\n",
    "    generated_musics = {'model1':[], 'model2':[], 'model3':[]}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_musics['model1'].append(input[0])\n",
    "        generated_musics['model2'].append(input[0])\n",
    "        generated_musics['model3'].append(input[0])\n",
    "\n",
    "        output1 = model1(input)\n",
    "        output2 = model2(input.unsqueeze(0), target.unsqueeze(0))\n",
    "        output3 = model3(input)\n",
    "        # Apply temperature to the output probabilities for diversity\n",
    "\n",
    "        probabilities1 = softmax(output1.squeeze() / TEMPERATURE, dim=-1)\n",
    "        probabilities2 = softmax(output2.squeeze() / TEMPERATURE, dim=-1)\n",
    "        probabilities3 = softmax(output3.squeeze() / TEMPERATURE, dim=-1)\n",
    "\n",
    "        for j in range(MAX_SEQ_LEN):\n",
    "            current_token1 = torch.multinomial(probabilities1[j], 1).item()\n",
    "            if current_token1 == END_TOKEN:\n",
    "                break\n",
    "            else:\n",
    "                generated_musics['model1'].append(current_token1)\n",
    "        for j in range(MAX_SEQ_LEN):\n",
    "            current_token2 = torch.multinomial(probabilities2[j], 1).item()\n",
    "            if current_token2 == END_TOKEN:\n",
    "                break\n",
    "            else:\n",
    "                generated_musics['model2'].append(current_token2)\n",
    "        for j in range(MAX_SEQ_LEN):\n",
    "            current_token3 = torch.multinomial(probabilities3[j], 1).item()\n",
    "            if current_token3 == END_TOKEN:\n",
    "                break\n",
    "            else:\n",
    "                generated_musics['model3'].append(current_token3)\n",
    "    return generated_musics\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_dict = generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your MidiEncoder and MidiEncoderREMI\n",
    "path_to_midi = \"data/emopia/EMOPIA_2.2/midis/\"\n",
    "midi_files_list = [os.path.join(path_to_midi, file) for file in os.listdir(path_to_midi) if file.endswith(\".mid\")]\n",
    "midi_encoder_remi = MIDIEncoderREMI(dict_path=\"data/encoder_dict.pkl\", midi_files_list=midi_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in music_dict.keys():\n",
    "    midi_encoder_remi.words_to_midi(music_dict[key],f'presentation/{key}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id=\"midiPlayerDiv1770\"></div>\n",
       "                <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "                \n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {\n",
       "                        'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                    }\n",
       "                });\n",
       "                require(['music21'], function(music21) {\n",
       "                    mp = new music21.miditools.MidiPlayer();\n",
       "                    mp.addPlayer(\"#midiPlayerDiv1770\");\n",
       "                    mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAAj0A/wMFUGlhbm8AwAAA4ABAAMAAkACQLFiEAJAtTACQLWCCAIAsAACQPDyCAIA8AIErgC0AAIAtAIxVkCY0ggCAJgAAkEocAJBNQIQAkDgwggCASgAAkEE0AJBCSIIAgDgAAJBFZIIAgE0AggCAQQAAkC1gAJA+SIJVgC0AgSuQJ1yCAJBNZACQOSRVgCcAgSuARQAAgD4AAJA8YACQP1yCAJAdMIIAgE0AhACAQgAAgDwAAIA/AACQQlxVgDkAgyuAHQAAkCtIAJAdMIIAkD9kgSuAHQBVgEIAAJAtKACQPTiCAIArAACQRRhVgC0AgSuQNWgAkDRAhACARQCCAIA1AACANACCAJA+QIYAkC1gAJA0UIIAgD8AAIAtAACQNiQAkD1AggCAPQAAkENgggCANAAAgDYAggCAQwCCAIA9AIIAkDM0ggCAMwAAkDFAggCAMQAAkDs0ggCAOwAAkEI0ggCQSlhVgD4AgSuQNVyCAIBCAIIAgEoAAJA0PIYAkDVYAJBFWIQAkEwgAJA/WACQPVCCAIA1AACQQUiCAIA0AIIAgDUAAIBFAACATAAAgD8AAIA9AACQNVgAkEVYAJBBSIIAkCwwAJA2TIIAgDUAAIBFAACQRVAAkEQ0gyuALACCAIBBAIJVgEQAAJAwSACQRUyCAIA2AACAMAAAkCpYggCARQAAkEhIglWASABWgCoAVYBFAIIAkEMwggCAQwCEAJAyVIErgEEAjFWAMgCEAJA0UIUrgDQAiAD/LwA=\");\n",
       "                });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m1_music = converter.parse('presentation/model1.mid')\n",
    "m1_music.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id=\"midiPlayerDiv6104\"></div>\n",
       "                <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "                \n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {\n",
       "                        'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                    }\n",
       "                });\n",
       "                require(['music21'], function(music21) {\n",
       "                    mp = new music21.miditools.MidiPlayer();\n",
       "                    mp.addPlayer(\"#midiPlayerDiv6104\");\n",
       "                    mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAAnMA/wMFUGlhbm8AwAAA4ABAAMAAoACQOByIAJA6FACQLiQAkElIggCAOgAAkElIAJA6RIErgC4AAIBJAIQAgEkAVZBJPACQQUSCVYA4AACASQCBK5BJRACQLjgAkFBUVYA6AIErkEk4AJBGTACQOjRVgEkAgSuASQAAgEYAAJBJHACQRjAAkEkwhACASQAAgEYAAIBJAACQRkAAkEtQggCQRiwAkEk4VYBGAIErgEEAAJBGKACQQSBVgEYAAIBJAIErgEsAAJBJMACQSTAAkEswglWASQAAgEkAgSuQSUwAkC4sVYAuAFaASwBVgFAAAIA6AACARgAAgEEAAIBJAACQSTAAkEswAJBGJACQUFQAkDo0AJAuLIIAkEswVYBJAACASwAAgEYAgSuQSTAAkEk0AJBGJFWASwCBK4BJAACASQAAkEkwAJBLLIIAkEhQVYAuAIErgFAAAIBIAACQLiyCAIAuAACQSDQAkEgwggCAOgAAgEgAAIBIAACQREwAkD9AAJA4RACQLDyCVYBJAACASwBWgEYAVZBIMIIAgEQAAJBEJFWALgCBK4BIAACQSDAAkEk0VYBEAIErgEgAAJBELACQSDCCAJBIKACQRCxVgEQAAIBIAIErkEQkAJBIKACQRiBVgEgAAIBEAIErgD8AAIBEAACQRCQAkD8UggCAOAAAgCwAAIBJAACASAAAgEYAAJBEKACQRCQAkD8UAJBIKACQOEQAkCw8AJBGIFWARAAAgD8AgSuARAAAgD8AAIBIAACQSSxVgEQAgyuAOAAAgCwAtgCARgAAkEgkAJA6HJkrgEkAiFWASAAAgDoAiAD/LwA=\");\n",
       "                });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m2_music = converter.parse('presentation/model2.mid') \n",
    "m2_music.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id=\"midiPlayerDiv7890\"></div>\n",
       "                <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "                \n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {\n",
       "                        'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                    }\n",
       "                });\n",
       "                require(['music21'], function(music21) {\n",
       "                    mp = new music21.miditools.MidiPlayer();\n",
       "                    mp.addPlayer(\"#midiPlayerDiv7890\");\n",
       "                    mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAAisA/wMFUGlhbm8AwAAA4ABAAMAAiACQUViKAIBRAIIAkDlUhACQFjCCAJA3SACQNDAAkENEggCQJzQAkDNAhACANwCCAJA+PIIAkDJkVYA0AIMrgDkAAIAWAACAQwAAgD4AAIAyAACQFjAAkCc0AJAzQACQOTCCAIA5AIQAgBYAgyuAJwAAgDMAggCAJwAAgDMAllWQUkAAkDw0ggCQKTAAkD88AJAdPACQOFAAkDdAAJBIMIJVgCkAAIA/AIErkEM0ggCAHQAAgDgAAIBDAACQUCyCAIA3AACASAAAkEBUhgCAUAAAkEI8AJBBHIJVgEIAgyuAQAAAgEEAAJA5WACQO1QAkDBEggCQRjQAkEVcglWAUgCBK5AzJIIAgDwAAIA5AACAOwAAgDAAAIBGAACARQAAkDBEAJBFXFWAMwCCAIAwAIcrgEUAogCQOBiEAJBZNIIAgDgAhACQQ0SCAJAsZACQNCyCAIAsAIYAgFkAAIA0AACQSSAAkFk0VYBDAIMrgFkAAJBCUACQOUAAkChMggCASQAAgEIAggCQKUSCAJAzSIIAgCkAggCQXjQAkDw0gSuAMwBVkDlQggCQPDCEAJA7RIIAgF4AAIA8AACQKUQAkDlEVYA7AFaAOQBVgDkAAIApAACQNDgAkFM0hACAOQCCAIAoAACAPAAAgDQAAJA+aACQRiwAkChMAJA8MIIAgD4AAIBGAIRVgCgAjSuAUwBVgDwAiAD/LwA=\");\n",
       "                });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m3_music = converter.parse('presentation/model3.mid') \n",
    "m3_music.show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: timidity: not found\n",
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "pipe:: Invalid data found when processing input\n",
      "sh: 1: timidity: not found\n",
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "pipe:: Invalid data found when processing input\n",
      "sh: 1: timidity: not found\n",
      "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 31.100 / 56. 31.100\n",
      "  libavcodec     58. 54.100 / 58. 54.100\n",
      "  libavformat    58. 29.100 / 58. 29.100\n",
      "  libavdevice    58.  8.100 / 58.  8.100\n",
      "  libavfilter     7. 57.100 /  7. 57.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  5.100 /  5.  5.100\n",
      "  libswresample   3.  5.100 /  3.  5.100\n",
      "  libpostproc    55.  5.100 / 55.  5.100\n",
      "pipe:: Invalid data found when processing input\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('timidity presentation/model1.mid -Ow -o - | ffmpeg -i - -acodec libmp3lame -ab 64k presentation/model1.mp3')\n",
    "os.system('timidity presentation/model2.mid -Ow -o - | ffmpeg -i - -acodec libmp3lame -ab 64k presentation/model2.mp3')\n",
    "os.system('timidity presentation/model3.mid -Ow -o - | ffmpeg -i - -acodec libmp3lame -ab 64k presentation/model3.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([1702]),\n",
       " 'input': tensor([160,  57,  73, 115, 135,  43,  37,  85,  83,  26,  53,  18, 111,  46,\n",
       "          44,  82, 127,  59,  10,  85,  64,  59,  42, 102,  83,   2,   3,  40,\n",
       "          21,  15,  49,  53, 102,   9,  62,  75,  21,  15,  81,  44,  85,   9,\n",
       "           6,  13,  47,   9,   6,  40,  21,  69,  34,  44, 102,  83,  12,   7,\n",
       "          21,  15,  12,  37,  92,  15,  16,  42,  85,  19,  20,  53,  30, 133,\n",
       "          20,  17,  85, 133,  20,  37, 101,  24,  20,  13,  47, 133,  20,  53,\n",
       "         121,  32,  57,  75, 121, 161,  43,  22,  77,  83,  26,  44, 115, 134,\n",
       "          26,  56, 101, 136,  46,  42, 142, 111,  59,  56,  18, 124,  48,  44,\n",
       "          82, 137,  48,  37,  77, 137,   2,   3,  53, 102,  15,  49,  44,  21,\n",
       "          15,  62,  42, 102,   9,  81,  44,  21,  15,   6,  44,  84,   9,  34,\n",
       "          56,  21,  15,  12,  44, 102,  83,  16,  42,  21,  15,  20,  56,  84,\n",
       "          19,  39,  42,  21,  19,  39,  42, 142, 133,  39,  42,  90, 133,  39,\n",
       "          53,  89,  32,  39,  42, 114, 133,  57,  44, 102,   9,  43,  44,  21,\n",
       "          15,  26,  40, 122,  72,  46,  40,  21,  15,  59,  44, 102,   9,  48,\n",
       "          42,  21,  15,   2,   3,   7, 122,   9,  49,  44,  21,  15,  62,  56,\n",
       "         102,   9,  81,  53,  21,  15,   6,   7,  85,  24,  34, 100, 122,  72,\n",
       "          34,   7,  21,  15,  12,  53, 102,  83,  16,  40,  21,  15,  16,  22,\n",
       "         125,  15,  16,  13,  77,  15,  20,  42,  85,  19,  20,  13, 104,  19,\n",
       "          20,   7, 101,  19]),\n",
       " 'target': tensor(0),\n",
       " 'input_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
