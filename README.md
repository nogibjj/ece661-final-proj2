# Emotion-Conditioned Music Generation with Transformer GANs 


#### Project Members: Chloe Liu, Emma Wang, Dingkun Yang

#### Abstract

Generative models have been widely applied to the realm of natural language. Automatic generation of images or texts has been prevalent, while music generation is a relatively niche area that we aim to delve deeper into via this project. 
As Henry Wadsworth Longfellow wrote, “Music is the universal language of mankind.” In this project, we utilize generative models to perform automatic music generation and evaluate if music generation can be as "realistic" or "human-like" as language models. Specifically, we explore both the conventional Transformer and Generative Adversarial Network (GAN)-based models to evaluate their quality and performance in the context of conditional music generation.
