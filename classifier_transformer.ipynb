{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from data.process_data import MidiEncoder, MIDIEncoderREMI\n",
    "import pickle as pkl\n",
    "from torch.utils.data import DataLoader\n",
    "from data.dataset import TransformerDatasetREMI\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_midi = \"data/emopia/EMOPIA_2.2/midis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your MidiEncoder and MidiEncoderREMI\n",
    "midi_files_list = [os.path.join(path_to_midi, file) for file in os.listdir(path_to_midi) if file.endswith(\".mid\")]\n",
    "midi_encoder = MidiEncoder(steps_per_sec=100, num_vel_bins=32, min_pitch=21, max_pitch=108)\n",
    "midi_encoder_remi = MIDIEncoderREMI(dict_path=\"data/encoder_dict.pkl\", midi_files_list=midi_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/emopia/EMOPIA_2.2/midis/Q1_9v2WSpn4FCw_10.mid\n",
      "0.02978801727294922\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_1.mid\n",
      "0.042944908142089844\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_3ZnxqCZ7qGg_0.mid\n",
      "0.009124279022216797\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vpTguZtJAFA_2.mid\n",
      "0.019979238510131836\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_5.mid\n",
      "0.013935089111328125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JP3QKZlyQz4_0.mid\n",
      "0.010724067687988281\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Y5JcZQ0xg4Y_3.mid\n",
      "0.035540103912353516\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1Qc15G0ZHIg_3.mid\n",
      "0.023600101470947266\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ZgT7yq2jsBk_0.mid\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027865886688232422\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1kny88W533Q_4.mid\n",
      "0.02965092658996582\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_xIsvaT20pZ0_1.mid\n",
      "0.021212100982666016\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k-FNDbK6Qhg_2.mid\n",
      "0.15807867050170898\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_YAAxPW1GB7w_1.mid\n",
      "0.013483524322509766\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Q5b5unyP8BM_0.mid\n",
      "0.035289764404296875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JxSU49jFKwM_1.mid\n",
      "0.012176990509033203\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_PK8YIUaV3Xw_1.mid\n",
      "0.013318538665771484\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Jn9r0avp0fY_3.mid\n",
      "0.033811330795288086\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TonQX8XbvX8_2.mid\n",
      "0.015692949295043945\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iHPKusssXzk_2.mid\n",
      "0.020656347274780273\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_POaIGvLsp5M_1.mid\n",
      "0.017627954483032227\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_eVMSeElk81Q_2.mid\n",
      "0.014144182205200195\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1vjy9oMFa8c_2.mid\n",
      "0.015867233276367188\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_1Q3MoBFh6eU_2.mid\n",
      "0.02005147933959961\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_HY9vPoHbgaI_1.mid\n",
      "0.01983475685119629\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_f2b4kpdw7_c_0.mid\n",
      "0.014867305755615234\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3ahg_eQZhxs_1.mid\n",
      "0.022269725799560547\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_f2b4kpdw7_c_1.mid\n",
      "0.018788814544677734\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_oTi57hZfArE_1.mid\n",
      "0.010854482650756836\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0H4rq0L9OSw_0.mid\n",
      "0.048526763916015625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_3.mid\n",
      "0.024364709854125977\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_3.mid\n",
      "0.039937734603881836\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_2.mid\n",
      "0.019295930862426758\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1EDThWjNxOI_1.mid\n",
      "0.014400959014892578\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_xrhWli_R98g_0.mid\n",
      "0.021073102951049805\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_fey-8bOR95E_0.mid\n",
      "0.03262019157409668\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_4.mid\n",
      "0.022333860397338867\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6Uf9XBUD3wE_0.mid\n",
      "0.016249895095825195\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zvWX_dwQPtU_0.mid\n",
      "0.017620563507080078\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_38i12IPkL5c_2.mid\n",
      "0.034750938415527344\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ivCNV47tsRw_0.mid\n",
      "0.03770017623901367\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_7JIdJLkJ0S4_3.mid\n",
      "0.02495121955871582\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_9v2WSpn4FCw_2.mid\n",
      "0.022949695587158203\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_10.mid\n",
      "0.023729801177978516\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Dg935IbDggo_0.mid\n",
      "0.033353567123413086\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kMHiU0fhWVw_1.mid\n",
      "0.021729707717895508\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_wzSr6qR3Ra0_0.mid\n",
      "0.017531871795654297\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lQCrA2TE-fo_0.mid\n",
      "0.013941049575805664\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_SQDuF0qxGQw_1.mid\n",
      "0.03149533271789551\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_jTPXwbDtIpA_0.mid\n",
      "0.014585494995117188\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Cg2u_Ldjv8g_0.mid\n",
      "0.022990703582763672\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DhnX54kOW8U_0.mid\n",
      "0.030798673629760742\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_2.mid\n",
      "0.03412151336669922\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jO2zX6Ul8GM_0.mid\n",
      "0.011669397354125977\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_im4Qxn3GQvo_1.mid\n",
      "0.021777629852294922\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_9Yb9OEVwups_0.mid\n",
      "0.0174100399017334\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_XC_SiJszQx0_1.mid\n",
      "0.028414011001586914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_3.mid\n",
      "0.022424697875976562\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UJcnNfeCN1c_1.mid\n",
      "0.015757322311401367\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0wRQRwnQiqY_0.mid\n",
      "0.025054931640625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_AacIP9mDLw8_1.mid\n",
      "0.01722407341003418\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_2.mid\n",
      "0.027744770050048828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_im4Qxn3GQvo_0.mid\n",
      "0.023513078689575195\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pRuwHN-lI44_0.mid\n",
      "0.01856708526611328\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_CxFXrYgdSSI_0.mid\n",
      "0.014721393585205078\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_4Er-eFHSHA4_3.mid\n",
      "0.020443201065063477\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ii1Jw1-7Ka4_1.mid\n",
      "0.01905536651611328\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_4.mid\n",
      "0.02351236343383789\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_fuCxYrru2S4_1.mid\n",
      "0.022365570068359375\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lTxVVdhFE6Q_0.mid\n",
      "0.020612716674804688\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0lEL_XHyhuU_2.mid\n",
      "0.012758970260620117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_7gifuoofgpk_1.mid\n",
      "0.010972738265991211\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_DX1IK3z1w10_0.mid\n",
      "0.02146315574645996\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ZvD8QSO7NPw_2.mid\n",
      "0.04891252517700195\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_aYe-2Glruu4_4.mid\n",
      "0.04184913635253906\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UbKAl4roB8k_1.mid\n",
      "0.024706602096557617\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_2.mid\n",
      "0.004822492599487305\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_qlbazHayULg_3.mid\n",
      "0.0330963134765625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_9Xg69XrVaYU_2.mid\n",
      "0.021658658981323242\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jNzZCplNNyY_0.mid\n",
      "0.021865129470825195\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_fOYX0uH8mSQ_0.mid\n",
      "0.015866756439208984\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_X1p8xcarVu0_0.mid\n",
      "0.014325618743896484\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bQS8eAXAhyE_2.mid\n",
      "0.030307531356811523\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_3.mid\n",
      "0.031234264373779297\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_K6OFDxBU370_1.mid\n",
      "0.020534038543701172\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ADJ_PDauy-g_0.mid\n",
      "0.010413408279418945\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TonQX8XbvX8_1.mid\n",
      "0.015556573867797852\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yrvKReuwVlY_3.mid\n",
      "0.024509191513061523\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_VXh4IaR5C6s_0.mid\n",
      "0.02094268798828125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_9eMxCs-LXCE_2.mid\n",
      "0.02119731903076172\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_I2MrA-o5H8I_1.mid\n",
      "0.030358314514160156\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wlOa1jkTn_U_0.mid\n",
      "0.026383161544799805\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0v2N1ROvEI0_1.mid\n",
      "0.017979860305786133\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_tw_lArYiHTo_0.mid\n",
      "0.02996373176574707\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_8TYY0qG-KOw_0.mid\n",
      "0.02030634880065918\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_2.mid\n",
      "0.013939857482910156\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_eVMSeElk81Q_0.mid\n",
      "0.01663804054260254\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e838BE_MH6s_3.mid\n",
      "0.03454113006591797\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_4ydjOX3pWds_0.mid\n",
      "0.023702144622802734\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_By3JCii1k3w_2.mid\n",
      "0.014022350311279297\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Jn9r0avp0fY_1.mid\n",
      "0.044481754302978516\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_5.mid\n",
      "0.02661442756652832\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__kJtgm1OUNA_2.mid\n",
      "0.0163118839263916\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HYVmgq5Y93g_0.mid\n",
      "0.019153118133544922\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ldCQ6N9G6Mk_2.mid\n",
      "0.008971929550170898\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_1.mid\n",
      "0.013783454895019531\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_EtAbPc20mn8_0.mid\n",
      "0.017810821533203125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_12.mid\n",
      "0.02344536781311035\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_xrhWli_R98g_3.mid\n",
      "0.0186617374420166\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Iq6g_4AwUWs_0.mid\n",
      "0.03523755073547363\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XPLYvpyfKUM_0.mid\n",
      "0.013417959213256836\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_miqLU2739dk_0.mid\n",
      "0.03031301498413086\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_TcFVq0leii4_0.mid\n",
      "0.015811443328857422\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cFWdWpyvwag_0.mid\n",
      "0.021901845932006836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_BaHHHgDd0BU_0.mid\n",
      "0.02295064926147461\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ISCVfmBvYoM_0.mid\n",
      "0.021230459213256836\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_7.mid\n",
      "0.01953721046447754\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KxlqB3j0zys_4.mid\n",
      "0.013622760772705078\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_1.mid\n",
      "0.03302264213562012\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nBIls0laAAU_2.mid\n",
      "0.03237557411193848\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_VXgRfsVd_o0_2.mid\n",
      "0.028258323669433594\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pzeHffxmdcE_0.mid\n",
      "0.025502681732177734\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_FfwKrQyQ7WU_3.mid\n",
      "0.02045917510986328\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_AjN_5CdVUdw_0.mid\n",
      "0.01582479476928711\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OgkB7PfqWzA_1.mid\n",
      "0.009634017944335938\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_1.mid\n",
      "0.012628555297851562\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jO2zX6Ul8GM_1.mid\n",
      "0.01401066780090332\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UbKAl4roB8k_2.mid\n",
      "0.018663406372070312\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8izVTDgBQPc_0.mid\n",
      "0.023673057556152344\n",
      "data/emopia/EMOPIA_2.2/midis/Q3__vZOEQCYSaY_2.mid\n",
      "0.027776479721069336\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ZvD8QSO7NPw_0.mid\n",
      "0.012711048126220703\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Jn9r0avp0fY_2.mid\n",
      "0.03433036804199219\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Q49PWE0RJLY_0.mid\n",
      "0.024965524673461914\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_D8Ed5PZXfF4_0.mid\n",
      "0.01613163948059082\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_E6MARl3zjnQ_0.mid\n",
      "0.026776790618896484\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_pouxqiySdI8_1.mid\n",
      "0.024402141571044922\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_JNzqL24ZcZ8_2.mid\n",
      "0.021409034729003906\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_rrD7XMtPs0Q_0.mid\n",
      "0.017126083374023438\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_eGQUZ9FlUJ4_0.mid\n",
      "0.037206411361694336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rW1I58_lMEg_1.mid\n",
      "0.01600790023803711\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_KxlqB3j0zys_1.mid\n",
      "0.012655019760131836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_4.mid\n",
      "0.014060497283935547\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_7n32BtYb4d4_0.mid\n",
      "0.15740060806274414\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_08t73Qgjkt4_2.mid\n",
      "0.04070305824279785\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_V3Y9L4UOcpk_1.mid\n",
      "0.022949695587158203\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_7n32BtYb4d4_2.mid\n",
      "0.033934593200683594\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_HY9vPoHbgaI_2.mid\n",
      "0.021323204040527344\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UYh88SRZC24_0.mid\n",
      "0.03081655502319336\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0lEL_XHyhuU_3.mid\n",
      "0.008824348449707031\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_qlbazHayULg_9.mid\n",
      "0.015070438385009766\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GY3f6ckBVkA_0.mid\n",
      "0.01811361312866211\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jrVXitpLGMk_2.mid\n",
      "0.04481792449951172\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_tfuul78deOs_1.mid\n",
      "0.01639389991760254\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_1.mid\n",
      "0.014223098754882812\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Hwd6l9jK7bo_1.mid\n",
      "0.012948274612426758\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_0.mid\n",
      "0.02022385597229004\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_3.mid\n",
      "0.020836830139160156\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UJcnNfeCN1c_2.mid\n",
      "0.015698671340942383\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XPLYvpyfKUM_1.mid\n",
      "0.018229007720947266\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DYBBfpEx-JI_0.mid\n",
      "0.031180858612060547\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rW1I58_lMEg_2.mid\n",
      "0.01773810386657715\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_gwmVjvR-sVs_1.mid\n",
      "0.01796698570251465\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Uu-oRTRT6uQ_0.mid\n",
      "0.03829002380371094\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FSzOgraSKhs_1.mid\n",
      "0.016060590744018555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pRuwHN-lI44_3.mid\n",
      "0.015921354293823242\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TYkTOwBfFB8_0.mid\n",
      "0.022500276565551758\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_TNoaOTrTkTQ_2.mid\n",
      "0.017585277557373047\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_2.mid\n",
      "0.023526668548583984\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UJcnNfeCN1c_3.mid\n",
      "0.012239456176757812\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_NP0lwB-_-og_0.mid\n",
      "0.01469111442565918\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_5NW0zDu6IYM_2.mid\n",
      "0.06607651710510254\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_2.mid\n",
      "0.015276670455932617\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lvfNo4KOTmM_1.mid\n",
      "0.013460636138916016\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ZvD8QSO7NPw_1.mid\n",
      "0.027307987213134766\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_4.mid\n",
      "0.051981449127197266\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UYh88SRZC24_1.mid\n",
      "0.03606271743774414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_yZGBxiNPu3k_2.mid\n",
      "0.02462911605834961\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_6.mid\n",
      "0.11145257949829102\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_AacIP9mDLw8_0.mid\n",
      "0.021228313446044922\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_PZN7XLKzLDI_0.mid\n",
      "0.027595043182373047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_5.mid\n",
      "0.03395247459411621\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_1.mid\n",
      "0.04327702522277832\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Hwd6l9jK7bo_0.mid\n",
      "0.013446807861328125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_OO7zYVeK814_1.mid\n",
      "0.01836872100830078\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_0.mid\n",
      "0.013714790344238281\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_hoPp_GLXQis_1.mid\n",
      "0.014429330825805664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_2Z9SjI131jA_6.mid\n",
      "0.01944255828857422\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Ie5koh4qvJc_12.mid\n",
      "0.07352066040039062\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3N2G21U7guk_1.mid\n",
      "0.014108419418334961\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_D3onzY4MNxE_0.mid\n",
      "0.014076471328735352\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_9v2WSpn4FCw_0.mid\n",
      "0.0168759822845459\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_aQ4PIaRMLwE_0.mid\n",
      "0.010465860366821289\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_0.mid\n",
      "0.06311774253845215\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lvfNo4KOTmM_0.mid\n",
      "0.015240907669067383\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_heBmBQDWj-M_2.mid\n",
      "0.013336896896362305\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_p2qihp_PnLY_1.mid\n",
      "0.025368690490722656\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Xsn9zT-05ns_1.mid\n",
      "0.04905080795288086\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_0.mid\n",
      "0.022796630859375\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__vZOEQCYSaY_1.mid\n",
      "0.018148422241210938\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_6oLmO9ZSJt0_1.mid\n",
      "0.007808208465576172\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_61EA0xRX8gE_2.mid\n",
      "0.021892547607421875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ezoAduuCkUs_0.mid\n",
      "0.04410958290100098\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_jziI_cuN_H8_1.mid\n",
      "0.032480478286743164\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_7.mid\n",
      "0.02888321876525879\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_TcFVq0leii4_2.mid\n",
      "0.04527640342712402\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_f2BXXa7lPuE_3.mid\n",
      "0.0392918586730957\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_1kny88W533Q_1.mid\n",
      "0.014430046081542969\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JT1XJnVmABo_6.mid\n",
      "0.033822059631347656\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yrvKReuwVlY_2.mid\n",
      "0.049169301986694336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_prUUays30Mg_1.mid\n",
      "0.011905670166015625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Xsn9zT-05ns_0.mid\n",
      "0.03394508361816406\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bIx4DwkZxFY_0.mid\n",
      "0.014134407043457031\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_k6aLLVX1D7Y_1.mid\n",
      "0.026294708251953125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Cg2u_Ldjv8g_1.mid\n",
      "0.14651751518249512\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0J7lX-Tcx-w_2.mid\n",
      "0.029227495193481445\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_1.mid\n",
      "0.07610607147216797\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_CxFXrYgdSSI_2.mid\n",
      "0.039443254470825195\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kfYaGryaGzI_0.mid\n",
      "0.013930559158325195\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vpTguZtJAFA_1.mid\n",
      "0.010140419006347656\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_SQDuF0qxGQw_2.mid\n",
      "0.02986931800842285\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ltxNPJda7zE_2.mid\n",
      "0.017931461334228516\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_RiQMuhk_SuQ_0.mid\n",
      "0.008296966552734375\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_3.mid\n",
      "0.01568317413330078\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_CxFXrYgdSSI_1.mid\n",
      "0.03622078895568848\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_K6OFDxBU370_0.mid\n",
      "0.019826412200927734\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zjr_-ql5Avk_1.mid\n",
      "0.008430242538452148\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_x4B0raxVODA_2.mid\n",
      "0.012379884719848633\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FOcdHIhI0_s_1.mid\n",
      "0.014587879180908203\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_PLfFWFZflQU_0.mid\n",
      "0.01893925666809082\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_bbU31JLtlug_1.mid\n",
      "0.035327911376953125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__kJtgm1OUNA_0.mid\n",
      "0.020572185516357422\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_-_FjI4bT2Wo_0.mid\n",
      "0.022603273391723633\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_77z6Ep3aOmg_0.mid\n",
      "0.019666671752929688\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_g15aRCHUJEI_0.mid\n",
      "0.01286458969116211\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5J_zI7QE9W8_2.mid\n",
      "0.02028822898864746\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lQCrA2TE-fo_1.mid\n",
      "0.014348268508911133\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_WBxql6cuU7c_0.mid\n",
      "0.04149341583251953\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pRuwHN-lI44_2.mid\n",
      "0.013115644454956055\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_-jJVb0xvbdg_0.mid\n",
      "0.020355224609375\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_jziI_cuN_H8_2.mid\n",
      "0.04329514503479004\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_1.mid\n",
      "0.011934995651245117\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_-vAz_HTFEXs_0.mid\n",
      "0.01490163803100586\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TYkTOwBfFB8_1.mid\n",
      "0.025353431701660156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_qRceKZtwRWA_0.mid\n",
      "0.011563301086425781\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_sUJ4a74Skk8_0.mid\n",
      "0.017204761505126953\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_1cgO42sh-ZY_0.mid\n",
      "0.008713245391845703\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_X1p8xcarVu0_2.mid\n",
      "0.01306605339050293\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e8NQ2NH0nc8_1.mid\n",
      "0.0206453800201416\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_0.mid\n",
      "0.013893365859985352\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wS0RzrBL9UI_0.mid\n",
      "0.013702154159545898\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_iwxwLEvqeD8_0.mid\n",
      "0.009991168975830078\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_b8HVQtIoBYU_1.mid\n",
      "0.029059886932373047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_7n32BtYb4d4_3.mid\n",
      "0.030518293380737305\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_kDGmND1BgmA_1.mid\n",
      "0.0068132877349853516\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UAm0aWvzFI8_1.mid\n",
      "0.03570270538330078\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_DvIH5yUrboc_1.mid\n",
      "0.030198097229003906\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_r_sD61KeUQU_0.mid\n",
      "0.020961523056030273\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_8.mid\n",
      "0.05343890190124512\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_g-yM0Lsp4lc_0.mid\n",
      "0.01529073715209961\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cQp1BYDGcRo_1.mid\n",
      "0.03554391860961914\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_PLfFWFZflQU_1.mid\n",
      "0.028109312057495117\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DYBBfpEx-JI_3.mid\n",
      "0.03507876396179199\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ury1cdB79s0_0.mid\n",
      "0.01157236099243164\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_15.mid\n",
      "0.014362096786499023\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_0.mid\n",
      "0.025838851928710938\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_vVTP0DOL_2Q_1.mid\n",
      "0.014415979385375977\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Kk60F8a7-Jw_0.mid\n",
      "0.0236513614654541\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__FVzelKlBFs_2.mid\n",
      "0.022452831268310547\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_0.mid\n",
      "0.011762380599975586\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_2.mid\n",
      "0.04156947135925293\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_UJcnNfeCN1c_0.mid\n",
      "0.012393712997436523\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_02t1bj7ZABY_1.mid\n",
      "0.01589226722717285\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_12tDlCQVRtA_1.mid\n",
      "0.016483783721923828\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xf2fox7zhCQ_0.mid\n",
      "0.01633286476135254\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6kRPHamGDSo_3.mid\n",
      "0.01878499984741211\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KRlAez34QfE_1.mid\n",
      "0.016835451126098633\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_-_FjI4bT2Wo_2.mid\n",
      "0.011985063552856445\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Uu-oRTRT6uQ_1.mid\n",
      "0.04343557357788086\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_12.mid\n",
      "0.03307461738586426\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_RiQMuhk_SuQ_2.mid\n",
      "0.08442807197570801\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_2.mid\n",
      "0.021158456802368164\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_VXgRfsVd_o0_1.mid\n",
      "0.04090070724487305\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Dg935IbDggo_1.mid\n",
      "0.03744220733642578\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_T92R7xjce34_1.mid\n",
      "0.018450021743774414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_x4B0raxVODA_1.mid\n",
      "0.008124828338623047\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5DqIntcmdRI_1.mid\n",
      "0.020153522491455078\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_epX33OVpkmA_1.mid\n",
      "0.0419163703918457\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_9.mid\n",
      "0.040308475494384766\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltxNPJda7zE_1.mid\n",
      "0.011449575424194336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_d_49EtXDMFE_1.mid\n",
      "0.012234687805175781\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_94ROf10d1iA_0.mid\n",
      "0.011916637420654297\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_2.mid\n",
      "0.027491331100463867\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_VrWAZLRdQO8_0.mid\n",
      "0.010729551315307617\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_xrhWli_R98g_1.mid\n",
      "0.02898859977722168\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iGHgeUCPotc_0.mid\n",
      "0.014088630676269531\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Y5JcZQ0xg4Y_1.mid\n",
      "0.021404027938842773\n",
      "data/emopia/EMOPIA_2.2/midis/Q3__vZOEQCYSaY_0.mid\n",
      "0.01927661895751953\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_0.mid\n",
      "0.042157649993896484\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_78C_TpQDvVE_1.mid\n",
      "0.022597789764404297\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XC_SiJszQx0_0.mid\n",
      "0.01102304458618164\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_veG92Oi-DlU_0.mid\n",
      "0.020174264907836914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_dfNdpy8TUzA_1.mid\n",
      "0.016022205352783203\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_fShAWhXIits_1.mid\n",
      "0.016485929489135742\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZTrEoB8T9YA_0.mid\n",
      "0.03279590606689453\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_17.mid\n",
      "0.0119171142578125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_TNoaOTrTkTQ_1.mid\n",
      "0.022603750228881836\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yhIncZ_Ue4E_0.mid\n",
      "0.018159151077270508\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_7yW9c7t8Hq0_3.mid\n",
      "0.04216432571411133\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_31.mid\n",
      "0.016490936279296875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_XfA2KXodrOE_0.mid\n",
      "0.03278493881225586\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_BGf5nCdzPOc_0.mid\n",
      "0.04453873634338379\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bQS8eAXAhyE_0.mid\n",
      "0.01618218421936035\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DYBBfpEx-JI_2.mid\n",
      "0.03628253936767578\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zvWX_dwQPtU_1.mid\n",
      "0.022836923599243164\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_mX-xs3OVhTs_1.mid\n",
      "0.017650604248046875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_QwsQ8ejbMKg_0.mid\n",
      "0.03633403778076172\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3N2G21U7guk_5.mid\n",
      "0.023224592208862305\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_QJlnTN7HRwE_0.mid\n",
      "0.009478569030761719\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ldCQ6N9G6Mk_5.mid\n",
      "0.03543353080749512\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_4Er-eFHSHA4_1.mid\n",
      "0.018637895584106445\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_DvIH5yUrboc_0.mid\n",
      "0.02606368064880371\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_L3_TadjSQQ0_0.mid\n",
      "0.1826183795928955\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UOSlDydo94E_0.mid\n",
      "0.019939184188842773\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__SJQaaRzD-A_1.mid\n",
      "0.025484561920166016\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_b8HVQtIoBYU_0.mid\n",
      "0.019043445587158203\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1EDThWjNxOI_0.mid\n",
      "0.012130260467529297\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_0.mid\n",
      "0.005408525466918945\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_2w5XkAt_3WU_0.mid\n",
      "0.012015342712402344\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Dw7M69CidJ8_0.mid\n",
      "0.011563539505004883\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_WQrPcuy50aA_1.mid\n",
      "0.02589702606201172\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_vVTP0DOL_2Q_3.mid\n",
      "0.0161135196685791\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_mlHheZbblT0_1.mid\n",
      "0.023351192474365234\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1Qc15G0ZHIg_1.mid\n",
      "0.025435924530029297\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1vjy9oMFa8c_4.mid\n",
      "0.012966394424438477\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_L3_TadjSQQ0_1.mid\n",
      "0.03940320014953613\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_4.mid\n",
      "0.024471521377563477\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_AacIP9mDLw8_2.mid\n",
      "0.023493051528930664\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_4.mid\n",
      "0.04009699821472168\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GY3f6ckBVkA_1.mid\n",
      "0.014045476913452148\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_f2BXXa7lPuE_0.mid\n",
      "0.021342992782592773\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KRlAez34QfE_2.mid\n",
      "0.016036510467529297\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_JNzqL24ZcZ8_0.mid\n",
      "0.022989511489868164\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_epX33OVpkmA_2.mid\n",
      "0.028850793838500977\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s6-SbDSZzEU_0.mid\n",
      "0.020497560501098633\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_fnqb8zqHqdY_1.mid\n",
      "0.010193586349487305\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pkz8OkWhwnk_1.mid\n",
      "0.016808509826660156\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FH28sPhm9Dc_1.mid\n",
      "0.026314258575439453\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_POaIGvLsp5M_0.mid\n",
      "0.016471147537231445\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_WpZ1rWHOCAQ_0.mid\n",
      "0.013947725296020508\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_cXxGBDgFCs8_0.mid\n",
      "0.02085590362548828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_7yW9c7t8Hq0_2.mid\n",
      "0.021375417709350586\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_fShAWhXIits_0.mid\n",
      "0.035218238830566406\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_dfNdpy8TUzA_2.mid\n",
      "0.01791238784790039\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UTo7E0evQWw_0.mid\n",
      "0.021695613861083984\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_1.mid\n",
      "0.03261971473693848\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_94ROf10d1iA_2.mid\n",
      "0.006443023681640625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_snfsc7pEzlk_1.mid\n",
      "0.03677701950073242\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_z5ewpQwGDNw_0.mid\n",
      "0.015105247497558594\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_FUAK5TBaNY8_1.mid\n",
      "0.0219271183013916\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0H4rq0L9OSw_1.mid\n",
      "0.04974985122680664\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S7Bo4-NCEDk_1.mid\n",
      "0.039014577865600586\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_REq37pDAm3A_3.mid\n",
      "0.024713516235351562\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltNK_MY1HkM_2.mid\n",
      "0.006536006927490234\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_yZGBxiNPu3k_1.mid\n",
      "0.01713705062866211\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZdyiXIlKe_Y_1.mid\n",
      "0.021427154541015625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_BzqX-9TA-GY_0.mid\n",
      "0.004366874694824219\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_sA9ac1rod84_0.mid\n",
      "0.02039623260498047\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_PdwxeMPXOCk_1.mid\n",
      "0.027420759201049805\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_cCfEDTkuMvg_0.mid\n",
      "0.010783910751342773\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_d_49EtXDMFE_2.mid\n",
      "0.011063814163208008\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OoxI6k0Qsno_0.mid\n",
      "0.011231660842895508\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_TcFVq0leii4_1.mid\n",
      "0.03554844856262207\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0lEL_XHyhuU_0.mid\n",
      "0.008437156677246094\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wxXpvnmq_-E_2.mid\n",
      "0.015302181243896484\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JT1XJnVmABo_3.mid\n",
      "0.013208627700805664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KRlAez34QfE_0.mid\n",
      "0.01674175262451172\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_0.mid\n",
      "0.014077186584472656\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D-gDPh9ZpFk_2.mid\n",
      "0.035196781158447266\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D5kyjnlDNZs_0.mid\n",
      "0.032156944274902344\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_4.mid\n",
      "0.014504432678222656\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_4dXC1cC7crw_1.mid\n",
      "0.028888702392578125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OUb9uaOlWAM_0.mid\n",
      "0.009917736053466797\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cFWdWpyvwag_1.mid\n",
      "0.04735612869262695\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_4Er-eFHSHA4_2.mid\n",
      "0.01832413673400879\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e8NQ2NH0nc8_0.mid\n",
      "0.02208423614501953\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_V_jbWvQNh5c_1.mid\n",
      "0.009032249450683594\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_snfsc7pEzlk_0.mid\n",
      "0.01719832420349121\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yrvKReuwVlY_0.mid\n",
      "0.016069650650024414\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_9eMxCs-LXCE_0.mid\n",
      "0.008864879608154297\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ldCQ6N9G6Mk_4.mid\n",
      "0.01912546157836914\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0EWWyyV7RJA_0.mid\n",
      "0.02463841438293457\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UpHutdJvZMI_0.mid\n",
      "0.012998580932617188\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__8v0MFBZoco_0.mid\n",
      "0.054756879806518555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_v3Nl5rUxLqE_1.mid\n",
      "0.0073854923248291016\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OoxI6k0Qsno_1.mid\n",
      "0.011264324188232422\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_1.mid\n",
      "0.019821882247924805\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_pNwQ9Tu_bCs_1.mid\n",
      "0.02431631088256836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5J_zI7QE9W8_1.mid\n",
      "0.015447139739990234\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ijfxkQPAQdE_2.mid\n",
      "0.054178714752197266\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_MT2_mXn-vGU_0.mid\n",
      "0.014683246612548828\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_VCSDjQxAJzc_1.mid\n",
      "0.01716303825378418\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6wFJhmhNeeg_0.mid\n",
      "0.05202364921569824\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_xYZ8n8ULaNo_1.mid\n",
      "0.01802825927734375\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_3.mid\n",
      "0.015237808227539062\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3TYeU9idRGI_0.mid\n",
      "0.009152412414550781\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xlv4PPGrRRs_1.mid\n",
      "0.017569541931152344\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JMt4m608s3k_0.mid\n",
      "0.025832414627075195\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1TAKQK3s6qQ_0.mid\n",
      "0.044736385345458984\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_3.mid\n",
      "0.03542590141296387\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kMHiU0fhWVw_2.mid\n",
      "0.016022920608520508\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Jn9r0avp0fY_0.mid\n",
      "0.03320884704589844\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_cXxGBDgFCs8_2.mid\n",
      "0.01548314094543457\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_x5ibvz38jOs_0.mid\n",
      "0.023513078689575195\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_xYZ8n8ULaNo_0.mid\n",
      "0.012726068496704102\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3N2G21U7guk_4.mid\n",
      "0.015086650848388672\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_o20YCzej5_s_0.mid\n",
      "0.0506443977355957\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FyK_c-TIcCA_0.mid\n",
      "0.0292208194732666\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_mGYKWCVnMwQ_1.mid\n",
      "0.02521061897277832\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Fc1qk52SaKY_0.mid\n",
      "0.030421972274780273\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_BzqX-9TA-GY_2.mid\n",
      "0.014398574829101562\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_OCqMDeD6Fmc_0.mid\n",
      "0.024708032608032227\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s5b8viFsVJE_1.mid\n",
      "0.04051017761230469\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Cir1kZyB7QM_0.mid\n",
      "0.017313718795776367\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_21.mid\n",
      "0.03510308265686035\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1kny88W533Q_2.mid\n",
      "0.03515005111694336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_wfXSdMsd4q8_5.mid\n",
      "0.030979156494140625\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jSWItJI-Gmk_1.mid\n",
      "0.01585865020751953\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_7n32BtYb4d4_1.mid\n",
      "0.018501758575439453\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_eGQUZ9FlUJ4_1.mid\n",
      "0.03951716423034668\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_E5qEloUO3SM_0.mid\n",
      "0.02095174789428711\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wlOa1jkTn_U_1.mid\n",
      "0.022536039352416992\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_TOXg4-ZGb-g_2.mid\n",
      "0.011809587478637695\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_pNwQ9Tu_bCs_2.mid\n",
      "0.024123668670654297\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_tfuul78deOs_0.mid\n",
      "0.01524972915649414\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_5.mid\n",
      "0.0326228141784668\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_k-FNDbK6Qhg_1.mid\n",
      "0.02266240119934082\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XWk5XUEBXmg_0.mid\n",
      "0.014671802520751953\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zHwJG8Rrx6c_1.mid\n",
      "0.017297029495239258\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_qlbazHayULg_13.mid\n",
      "0.1528337001800537\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_6.mid\n",
      "0.03807544708251953\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_RaUSISlnhKw_2.mid\n",
      "0.033231258392333984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_16.mid\n",
      "0.005841493606567383\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_24.mid\n",
      "0.02418828010559082\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FoTXpYZXxJs_0.mid\n",
      "0.017374277114868164\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_gxsdWKc1QaM_0.mid\n",
      "0.025994062423706055\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_BIRDDxz0E4c_1.mid\n",
      "0.012398958206176758\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_12tDlCQVRtA_0.mid\n",
      "0.010560989379882812\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_aQ4PIaRMLwE_1.mid\n",
      "0.018594741821289062\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_SlsXsqotUis_0.mid\n",
      "0.038362741470336914\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Y1F0c3zgMJo_1.mid\n",
      "0.012485504150390625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_--2B4d4lQhs_1.mid\n",
      "0.06840348243713379\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s5b8viFsVJE_2.mid\n",
      "0.03366661071777344\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1kny88W533Q_3.mid\n",
      "0.03243517875671387\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_38i12IPkL5c_1.mid\n",
      "0.03274226188659668\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xlv4PPGrRRs_0.mid\n",
      "0.013859987258911133\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_FfwKrQyQ7WU_1.mid\n",
      "0.022799015045166016\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_eVMSeElk81Q_1.mid\n",
      "0.040525197982788086\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_oTi57hZfArE_0.mid\n",
      "0.012523412704467773\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jIKX3ShvLxo_1.mid\n",
      "0.052474260330200195\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Gcbk0GPT3-g_0.mid\n",
      "0.01625657081604004\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JYVXM0qNQAg_1.mid\n",
      "0.03749442100524902\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1fdxsFbnsX4_0.mid\n",
      "0.012553215026855469\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_IgpNyJVWcBo_0.mid\n",
      "0.023151636123657227\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_X1p8xcarVu0_3.mid\n",
      "0.012592315673828125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5Ju9q1N2x0E_1.mid\n",
      "0.03515458106994629\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_u_7b9CwyM8Q_0.mid\n",
      "0.01645064353942871\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_7.mid\n",
      "0.03614044189453125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_cB-Xh8H_7-Q_0.mid\n",
      "0.03814840316772461\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_16OaOpfOPZ0_1.mid\n",
      "0.01935744285583496\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TonQX8XbvX8_0.mid\n",
      "0.008378744125366211\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_egYSmNuIFGk_2.mid\n",
      "0.018103361129760742\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_J6X3rVU1H-c_1.mid\n",
      "0.02387070655822754\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_D3onzY4MNxE_1.mid\n",
      "0.012690544128417969\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_rEz0D3VohFA_2.mid\n",
      "0.0486297607421875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0v2N1ROvEI0_0.mid\n",
      "0.07296633720397949\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_f0NbGeyJYms_0.mid\n",
      "0.021706581115722656\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Dw7M69CidJ8_1.mid\n",
      "0.01950812339782715\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_iwxwLEvqeD8_1.mid\n",
      "0.012758731842041016\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_60LLKmpgzRM_0.mid\n",
      "0.005829572677612305\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_9.mid\n",
      "0.018080711364746094\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_2.mid\n",
      "0.05405449867248535\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XC_SiJszQx0_2.mid\n",
      "0.011857748031616211\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_3.mid\n",
      "0.04250335693359375\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_v2an-9szi8M_0.mid\n",
      "0.014351606369018555\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_3.mid\n",
      "0.012324333190917969\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0qYNvMCEwaw_0.mid\n",
      "0.03145551681518555\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_8.mid\n",
      "0.030173063278198242\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_K84TcgjCRt4_0.mid\n",
      "0.010383844375610352\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_16OaOpfOPZ0_3.mid\n",
      "0.021419286727905273\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UE0y8MHqT-g_2.mid\n",
      "0.03649330139160156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Q49PWE0RJLY_1.mid\n",
      "0.018013954162597656\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_OO7zYVeK814_2.mid\n",
      "0.009940147399902344\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_fey-8bOR95E_1.mid\n",
      "0.03486371040344238\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_13.mid\n",
      "0.02410411834716797\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_3.mid\n",
      "0.04698443412780762\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_BGf5nCdzPOc_1.mid\n",
      "0.03765249252319336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZdyiXIlKe_Y_0.mid\n",
      "0.025408267974853516\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_snfsc7pEzlk_2.mid\n",
      "0.03864693641662598\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_7yW9c7t8Hq0_1.mid\n",
      "0.040973663330078125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_xrhWli_R98g_2.mid\n",
      "0.015855073928833008\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k-FNDbK6Qhg_0.mid\n",
      "0.04284262657165527\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_g15aRCHUJEI_2.mid\n",
      "0.013402462005615234\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FyK_c-TIcCA_2.mid\n",
      "0.09142851829528809\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_B3aRl8iTEKw_1.mid\n",
      "0.026477813720703125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ufRISSD28XA_1.mid\n",
      "0.022453784942626953\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iHPKusssXzk_1.mid\n",
      "0.01737380027770996\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ldCQ6N9G6Mk_1.mid\n",
      "0.014272928237915039\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZTrEoB8T9YA_2.mid\n",
      "0.02564525604248047\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_0.mid\n",
      "0.01455545425415039\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_4.mid\n",
      "0.02083730697631836\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_uqRLEByE6pU_2.mid\n",
      "0.049184322357177734\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nFunbdBrukY_0.mid\n",
      "0.01408696174621582\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nBao46YGZDg_0.mid\n",
      "0.01043391227722168\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_K84TcgjCRt4_2.mid\n",
      "0.02301168441772461\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xf2fox7zhCQ_2.mid\n",
      "0.016833066940307617\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_nGkpcWNAxDU_2.mid\n",
      "0.02308511734008789\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_PZN7XLKzLDI_1.mid\n",
      "0.02346634864807129\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k4lT-sXg3iI_2.mid\n",
      "0.027281999588012695\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cm6E860vDjY_2.mid\n",
      "0.1491224765777588\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ivCNV47tsRw_1.mid\n",
      "0.03463172912597656\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_IH2KrGjKXw0_3.mid\n",
      "0.043354034423828125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1vjy9oMFa8c_5.mid\n",
      "0.03881573677062988\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kMHiU0fhWVw_3.mid\n",
      "0.017241954803466797\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_GwdQliEv6Z0_0.mid\n",
      "0.028929471969604492\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_19.mid\n",
      "0.013278484344482422\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__kJtgm1OUNA_1.mid\n",
      "0.030774593353271484\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_GwdQliEv6Z0_1.mid\n",
      "0.023189783096313477\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_2eIsQtm4YNs_1.mid\n",
      "0.019169092178344727\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JP3QKZlyQz4_2.mid\n",
      "0.009514093399047852\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_qRceKZtwRWA_1.mid\n",
      "0.017822742462158203\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D-gDPh9ZpFk_1.mid\n",
      "0.037926435470581055\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Ie5koh4qvJc_6.mid\n",
      "0.03634476661682129\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_RaUSISlnhKw_0.mid\n",
      "0.019513368606567383\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_3_MxhSS86oU_0.mid\n",
      "0.04228043556213379\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_0.mid\n",
      "0.026597023010253906\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_o5AIp2Yc01M_1.mid\n",
      "0.045363426208496094\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HYVmgq5Y93g_2.mid\n",
      "0.01598358154296875\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FUAK5TBaNY8_0.mid\n",
      "0.024518966674804688\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_2.mid\n",
      "0.007937192916870117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xf2fox7zhCQ_1.mid\n",
      "0.014279842376708984\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_epMOLn5Axw0_0.mid\n",
      "0.022641658782958984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_7gifuoofgpk_0.mid\n",
      "0.014333963394165039\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nBIls0laAAU_1.mid\n",
      "0.020086288452148438\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_4.mid\n",
      "0.03189253807067871\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OgkB7PfqWzA_0.mid\n",
      "0.00984954833984375\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_p2qihp_PnLY_0.mid\n",
      "0.02748274803161621\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_2v6gJi03LlA_0.mid\n",
      "0.018182039260864258\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_dCoUuknChhE_0.mid\n",
      "0.009724617004394531\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UOSlDydo94E_1.mid\n",
      "0.016942262649536133\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1Qc15G0ZHIg_0.mid\n",
      "0.019116878509521484\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_7JIdJLkJ0S4_2.mid\n",
      "0.015506744384765625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_x5ibvz38jOs_1.mid\n",
      "0.0346071720123291\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__BK2o77sTc0_1.mid\n",
      "0.021915674209594727\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_z5ewpQwGDNw_2.mid\n",
      "0.024225473403930664\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_5CEAeMiXKaA_0.mid\n",
      "0.01868891716003418\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_sEQf5lcnj_o_2.mid\n",
      "0.05679774284362793\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_VrWAZLRdQO8_1.mid\n",
      "0.01812744140625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_11.mid\n",
      "0.04042649269104004\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_j8Ir-ssM-AA_0.mid\n",
      "0.02998948097229004\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_1.mid\n",
      "0.0067882537841796875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_jziI_cuN_H8_0.mid\n",
      "0.02538585662841797\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_3.mid\n",
      "0.01637434959411621\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_10.mid\n",
      "0.013673782348632812\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ivCNV47tsRw_2.mid\n",
      "0.0530848503112793\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_PXOWy7NiZhk_0.mid\n",
      "0.019701242446899414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wS0RzrBL9UI_2.mid\n",
      "0.02470254898071289\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_2Z9SjI131jA_5.mid\n",
      "0.012785673141479492\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_0.mid\n",
      "0.020128965377807617\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DYBBfpEx-JI_1.mid\n",
      "0.022248268127441406\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GbUV3TXUzeQ_2.mid\n",
      "0.03589987754821777\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JMt4m608s3k_2.mid\n",
      "0.041144371032714844\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8rupdevqfuI_1.mid\n",
      "0.016640186309814453\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ii1Jw1-7Ka4_2.mid\n",
      "0.02231311798095703\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_QJlnTN7HRwE_1.mid\n",
      "0.010244131088256836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1vjy9oMFa8c_3.mid\n",
      "0.010566234588623047\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_K84TcgjCRt4_1.mid\n",
      "0.017101764678955078\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_tLmXAWfbGqs_0.mid\n",
      "0.015831947326660156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_12tDlCQVRtA_2.mid\n",
      "0.021317720413208008\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_CkjAksZstEA_1.mid\n",
      "0.01347661018371582\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_CkjAksZstEA_0.mid\n",
      "0.010238885879516602\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_5.mid\n",
      "0.04440617561340332\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_22.mid\n",
      "0.015144586563110352\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jrVXitpLGMk_0.mid\n",
      "0.023221254348754883\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_NTI9ode6bRk_1.mid\n",
      "0.018653392791748047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jrVXitpLGMk_1.mid\n",
      "0.033705711364746094\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1A9Hh2GrDTs_0.mid\n",
      "0.021558284759521484\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0c2dTJTDUR4_0.mid\n",
      "0.008348941802978516\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5J_zI7QE9W8_0.mid\n",
      "0.023730039596557617\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kMHiU0fhWVw_0.mid\n",
      "0.015817880630493164\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_78C_TpQDvVE_0.mid\n",
      "0.011868953704833984\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_x4B0raxVODA_3.mid\n",
      "0.009913444519042969\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_1.mid\n",
      "0.015049457550048828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_k4dxAlI5N-k_0.mid\n",
      "0.0449061393737793\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ADJ_PDauy-g_1.mid\n",
      "0.023703336715698242\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_fuCxYrru2S4_0.mid\n",
      "0.018689632415771484\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_VCSDjQxAJzc_2.mid\n",
      "0.01048898696899414\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_4.mid\n",
      "0.007489204406738281\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_VXgRfsVd_o0_0.mid\n",
      "0.01413726806640625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_sEQf5lcnj_o_0.mid\n",
      "0.039472103118896484\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cm6E860vDjY_0.mid\n",
      "0.0340418815612793\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_UuLTvhERcnk_0.mid\n",
      "0.01351022720336914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_k4dxAlI5N-k_1.mid\n",
      "0.06734657287597656\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_egYSmNuIFGk_0.mid\n",
      "0.021699190139770508\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_QmK_SND2jAw_1.mid\n",
      "0.03932523727416992\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_I2MrA-o5H8I_2.mid\n",
      "0.03401684761047363\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Adil-zpJdEs_0.mid\n",
      "0.03361344337463379\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltNK_MY1HkM_1.mid\n",
      "0.006684303283691406\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_170KC2CbJ7Y_1.mid\n",
      "0.013382673263549805\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_NGE9ynTJABg_2.mid\n",
      "0.02347874641418457\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_g15aRCHUJEI_1.mid\n",
      "0.012994050979614258\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_0.mid\n",
      "0.009693145751953125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_GAvPwG2wYZM_1.mid\n",
      "0.016360759735107422\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_3.mid\n",
      "0.013410806655883789\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_1.mid\n",
      "0.014622926712036133\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_8c7kcmsnf-s_0.mid\n",
      "0.03253006935119629\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_gwmVjvR-sVs_0.mid\n",
      "0.027712583541870117\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_dfNdpy8TUzA_0.mid\n",
      "0.013025522232055664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OyaY4213c2A_0.mid\n",
      "0.023596525192260742\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Gcbk0GPT3-g_1.mid\n",
      "0.015913963317871094\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_77z6Ep3aOmg_1.mid\n",
      "0.02671217918395996\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zHwJG8Rrx6c_3.mid\n",
      "0.0205535888671875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_z5ewpQwGDNw_1.mid\n",
      "0.01741337776184082\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_biROWEwkDQQ_2.mid\n",
      "0.013646125793457031\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_uqRLEByE6pU_0.mid\n",
      "0.04095649719238281\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_gvWDOIiocuE_2.mid\n",
      "0.012773990631103516\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jTPXwbDtIpA_1.mid\n",
      "0.04806375503540039\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_iFgSjUqI7iM_0.mid\n",
      "0.14802074432373047\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_NP0lwB-_-og_1.mid\n",
      "0.034604787826538086\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_5NW0zDu6IYM_1.mid\n",
      "0.028673410415649414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_16OaOpfOPZ0_0.mid\n",
      "0.013548135757446289\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_B3aRl8iTEKw_0.mid\n",
      "0.021241426467895508\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0J7lX-Tcx-w_0.mid\n",
      "0.023223876953125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_veG92Oi-DlU_2.mid\n",
      "0.015692949295043945\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_nOIBJHkqrE8_1.mid\n",
      "0.024219512939453125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wxXpvnmq_-E_0.mid\n",
      "0.015933513641357422\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_bfopzItCYrE_1.mid\n",
      "0.020696401596069336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ivCNV47tsRw_3.mid\n",
      "0.03429770469665527\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JMt4m608s3k_1.mid\n",
      "0.03279829025268555\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wlOa1jkTn_U_2.mid\n",
      "0.013144493103027344\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_MT2_mXn-vGU_1.mid\n",
      "0.018480539321899414\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_0c2dTJTDUR4_1.mid\n",
      "0.012967586517333984\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_RiQMuhk_SuQ_3.mid\n",
      "0.053170204162597656\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_VCSDjQxAJzc_0.mid\n",
      "0.018744707107543945\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_1.mid\n",
      "0.01228952407836914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_PdwxeMPXOCk_0.mid\n",
      "0.03291463851928711\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_sA9ac1rod84_1.mid\n",
      "0.02592182159423828\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_4.mid\n",
      "0.027205228805541992\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_e838BE_MH6s_0.mid\n",
      "0.024281740188598633\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_j8Ir-ssM-AA_1.mid\n",
      "0.017003774642944336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_RiQMuhk_SuQ_1.mid\n",
      "0.0308837890625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GbUV3TXUzeQ_1.mid\n",
      "0.02761983871459961\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5DqIntcmdRI_0.mid\n",
      "0.030703306198120117\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_IH2KrGjKXw0_2.mid\n",
      "0.013910531997680664\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_mlHheZbblT0_0.mid\n",
      "0.028548240661621094\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_5.mid\n",
      "0.02741551399230957\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_4Er-eFHSHA4_0.mid\n",
      "0.014193058013916016\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_8TYY0qG-KOw_1.mid\n",
      "0.02450084686279297\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_3ZnxqCZ7qGg_1.mid\n",
      "0.016091108322143555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_heBmBQDWj-M_1.mid\n",
      "0.019971847534179688\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yhIncZ_Ue4E_2.mid\n",
      "0.019031286239624023\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ItGNJM6skM4_1.mid\n",
      "0.049153804779052734\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_16OaOpfOPZ0_2.mid\n",
      "0.02829456329345703\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_V_jbWvQNh5c_0.mid\n",
      "0.009668350219726562\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zjr_-ql5Avk_0.mid\n",
      "0.006012439727783203\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_OCqMDeD6Fmc_3.mid\n",
      "0.048087120056152344\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_02t1bj7ZABY_2.mid\n",
      "0.019202232360839844\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_MbvPxCUMSek_2.mid\n",
      "0.008862018585205078\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UpHutdJvZMI_1.mid\n",
      "0.02233099937438965\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_4.mid\n",
      "0.019924402236938477\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D5kyjnlDNZs_2.mid\n",
      "0.05828547477722168\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rDhbGjFlKF8_0.mid\n",
      "0.01884007453918457\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_im4Qxn3GQvo_2.mid\n",
      "0.02540135383605957\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1fdxsFbnsX4_1.mid\n",
      "0.016498327255249023\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_MbvPxCUMSek_0.mid\n",
      "0.012197732925415039\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_7.mid\n",
      "0.03541398048400879\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_g-yM0Lsp4lc_1.mid\n",
      "0.008278608322143555\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ufRISSD28XA_0.mid\n",
      "0.019957304000854492\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltxNPJda7zE_3.mid\n",
      "0.016313791275024414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_3.mid\n",
      "0.014542341232299805\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_BaHHHgDd0BU_1.mid\n",
      "0.025687694549560547\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_J6X3rVU1H-c_0.mid\n",
      "0.009790182113647461\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_HY9vPoHbgaI_3.mid\n",
      "0.012819528579711914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e838BE_MH6s_1.mid\n",
      "0.01848125457763672\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_biROWEwkDQQ_3.mid\n",
      "0.022427797317504883\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3TYeU9idRGI_1.mid\n",
      "0.007901668548583984\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Wy2-my19YnY_1.mid\n",
      "0.02641892433166504\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UE0y8MHqT-g_1.mid\n",
      "0.044936418533325195\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_1Q3MoBFh6eU_0.mid\n",
      "0.018494367599487305\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_QJlnTN7HRwE_3.mid\n",
      "0.013305425643920898\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_r6laJv1-HMg_0.mid\n",
      "0.02594280242919922\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3As1t6JySDE_0.mid\n",
      "0.020613431930541992\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nBIls0laAAU_0.mid\n",
      "0.019730567932128906\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_f2BXXa7lPuE_2.mid\n",
      "0.04205036163330078\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_30.mid\n",
      "0.024805068969726562\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_By3JCii1k3w_1.mid\n",
      "0.015056133270263672\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_NGE9ynTJABg_0.mid\n",
      "0.0421910285949707\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_OCqMDeD6Fmc_1.mid\n",
      "0.0312809944152832\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JxSU49jFKwM_0.mid\n",
      "0.016397714614868164\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wxXpvnmq_-E_1.mid\n",
      "0.013520002365112305\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_4.mid\n",
      "0.011373281478881836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltNK_MY1HkM_0.mid\n",
      "0.008936643600463867\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FH28sPhm9Dc_0.mid\n",
      "0.017892837524414062\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_rEz0D3VohFA_1.mid\n",
      "0.037711143493652344\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yrvKReuwVlY_1.mid\n",
      "0.012755632400512695\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_QwsQ8ejbMKg_1.mid\n",
      "0.021306753158569336\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_S1T3UF1vhSk_0.mid\n",
      "0.03708386421203613\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HQ8ISDX6PiI_0.mid\n",
      "0.022656679153442383\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JT1XJnVmABo_5.mid\n",
      "0.01900172233581543\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_9eMxCs-LXCE_1.mid\n",
      "0.0118408203125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_YhXRyOl5pi0_0.mid\n",
      "0.024879932403564453\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kfYaGryaGzI_1.mid\n",
      "0.0060350894927978516\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GY3f6ckBVkA_3.mid\n",
      "0.021373510360717773\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iXiSFSGws-c_2.mid\n",
      "0.016437053680419922\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_WQrPcuy50aA_0.mid\n",
      "0.028668642044067383\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Dg935IbDggo_2.mid\n",
      "0.02952122688293457\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Dg935IbDggo_3.mid\n",
      "0.04746580123901367\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_wnB2cjd6zbE_0.mid\n",
      "0.035537004470825195\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_8c7kcmsnf-s_2.mid\n",
      "0.03407454490661621\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bIx4DwkZxFY_1.mid\n",
      "0.023186922073364258\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_08t73Qgjkt4_0.mid\n",
      "0.0211794376373291\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cm6E860vDjY_1.mid\n",
      "0.04113316535949707\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_5NW0zDu6IYM_0.mid\n",
      "0.02526092529296875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JYVXM0qNQAg_2.mid\n",
      "0.021305322647094727\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_v3Nl5rUxLqE_0.mid\n",
      "0.012297391891479492\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ijfxkQPAQdE_1.mid\n",
      "0.07181715965270996\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UaYYMRkHMYc_2.mid\n",
      "0.021117210388183594\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1vjy9oMFa8c_0.mid\n",
      "0.0209500789642334\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__FVzelKlBFs_1.mid\n",
      "0.051397085189819336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_MT2_mXn-vGU_2.mid\n",
      "0.01573491096496582\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_vVTP0DOL_2Q_2.mid\n",
      "0.017950773239135742\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6Uf9XBUD3wE_1.mid\n",
      "0.04925036430358887\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_4ydjOX3pWds_1.mid\n",
      "0.019962549209594727\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_28.mid\n",
      "0.021094799041748047\n",
      "data/emopia/EMOPIA_2.2/midis/Q3__S991V8N-8s_0.mid\n",
      "0.15756630897521973\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iXiSFSGws-c_0.mid\n",
      "0.023788928985595703\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zmZHNy9T8Pg_1.mid\n",
      "0.040177345275878906\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3ahg_eQZhxs_0.mid\n",
      "0.02891087532043457\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__FVzelKlBFs_0.mid\n",
      "0.04035305976867676\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_27.mid\n",
      "0.025646686553955078\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_biROWEwkDQQ_0.mid\n",
      "0.017737865447998047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_8.mid\n",
      "0.0317387580871582\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_sZe3IB1OVfw_1.mid\n",
      "0.021219253540039062\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_PXOWy7NiZhk_1.mid\n",
      "0.014838695526123047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_REq37pDAm3A_2.mid\n",
      "0.014100074768066406\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tjno89OVuRI_0.mid\n",
      "0.015240669250488281\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_8c7kcmsnf-s_1.mid\n",
      "0.040879249572753906\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_2.mid\n",
      "0.0260007381439209\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_veG92Oi-DlU_1.mid\n",
      "0.01846456527709961\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3N2G21U7guk_6.mid\n",
      "0.03055548667907715\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_2v6gJi03LlA_1.mid\n",
      "0.025397062301635742\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_bfopzItCYrE_0.mid\n",
      "0.011327505111694336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_6oLmO9ZSJt0_0.mid\n",
      "0.03494071960449219\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_x4B0raxVODA_0.mid\n",
      "0.007653474807739258\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k4lT-sXg3iI_0.mid\n",
      "0.021285533905029297\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_5Ju9q1N2x0E_2.mid\n",
      "0.045033931732177734\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_0.mid\n",
      "0.013904094696044922\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_fuCxYrru2S4_2.mid\n",
      "0.03403162956237793\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_14.mid\n",
      "0.015297651290893555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_d_49EtXDMFE_0.mid\n",
      "0.014301538467407227\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jTPXwbDtIpA_2.mid\n",
      "0.043161630630493164\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vpTguZtJAFA_0.mid\n",
      "0.015143632888793945\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_08t73Qgjkt4_1.mid\n",
      "0.016425132751464844\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_22S3w4idugs_0.mid\n",
      "0.012004852294921875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_TOXg4-ZGb-g_1.mid\n",
      "0.01120615005493164\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_13.mid\n",
      "0.054680824279785156\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_7JIdJLkJ0S4_0.mid\n",
      "0.0211789608001709\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_nGkpcWNAxDU_0.mid\n",
      "0.02084207534790039\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_-_FjI4bT2Wo_1.mid\n",
      "0.019849300384521484\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_kDGmND1BgmA_0.mid\n",
      "0.007330894470214844\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_1.mid\n",
      "0.02624344825744629\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_9v2WSpn4FCw_9.mid\n",
      "0.01765727996826172\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_G4rL_OtfFAU_0.mid\n",
      "0.03227066993713379\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ANZf1QXsNrY_6.mid\n",
      "0.022570133209228516\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rW1I58_lMEg_0.mid\n",
      "0.018291473388671875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_48EYLEAgaBc_1.mid\n",
      "0.005906343460083008\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Dw7M69CidJ8_2.mid\n",
      "0.03480792045593262\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UbKAl4roB8k_0.mid\n",
      "0.02953171730041504\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_2.mid\n",
      "0.01531076431274414\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6kRPHamGDSo_1.mid\n",
      "0.017429351806640625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_7.mid\n",
      "0.03795886039733887\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_f2BXXa7lPuE_1.mid\n",
      "0.03925013542175293\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_PK8YIUaV3Xw_0.mid\n",
      "0.01760077476501465\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_prUUays30Mg_0.mid\n",
      "0.013422489166259766\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_0vLPYiPN7qY_2.mid\n",
      "0.031058073043823242\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FUAK5TBaNY8_3.mid\n",
      "0.014731168746948242\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zHwJG8Rrx6c_0.mid\n",
      "0.014542579650878906\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KxlqB3j0zys_3.mid\n",
      "0.025319576263427734\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0lEL_XHyhuU_1.mid\n",
      "0.012331724166870117\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_NGE9ynTJABg_1.mid\n",
      "0.019686222076416016\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pkz8OkWhwnk_0.mid\n",
      "0.013863563537597656\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_TOXg4-ZGb-g_0.mid\n",
      "0.01647210121154785\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_1.mid\n",
      "0.013648033142089844\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zmZHNy9T8Pg_2.mid\n",
      "0.021415233612060547\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_11.mid\n",
      "0.04826045036315918\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_2.mid\n",
      "0.019492387771606445\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_FfwKrQyQ7WU_0.mid\n",
      "0.02435755729675293\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_02t1bj7ZABY_0.mid\n",
      "0.006793975830078125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_REq37pDAm3A_4.mid\n",
      "0.02318572998046875\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_0.mid\n",
      "0.016369104385375977\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ADJ_PDauy-g_2.mid\n",
      "0.016405105590820312\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_IH2KrGjKXw0_0.mid\n",
      "0.013239383697509766\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZTrEoB8T9YA_1.mid\n",
      "0.018140077590942383\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_7yW9c7t8Hq0_0.mid\n",
      "0.011223077774047852\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_YAAxPW1GB7w_0.mid\n",
      "0.011751651763916016\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_2.mid\n",
      "0.015460729598999023\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D-gDPh9ZpFk_0.mid\n",
      "0.02735304832458496\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OyaY4213c2A_1.mid\n",
      "0.014846563339233398\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_QmK_SND2jAw_0.mid\n",
      "0.025144338607788086\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_3.mid\n",
      "0.021121501922607422\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_XC_SiJszQx0_3.mid\n",
      "0.03271484375\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_NTI9ode6bRk_0.mid\n",
      "0.016228437423706055\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8rupdevqfuI_0.mid\n",
      "0.02555561065673828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_8.mid\n",
      "0.02116560935974121\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vJ77eDxHezE_0.mid\n",
      "0.028561115264892578\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_KxlqB3j0zys_0.mid\n",
      "0.01552271842956543\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_rEz0D3VohFA_0.mid\n",
      "0.007896661758422852\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_BzqX-9TA-GY_1.mid\n",
      "0.011656999588012695\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_fnqb8zqHqdY_2.mid\n",
      "0.016318798065185547\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_aYe-2Glruu4_1.mid\n",
      "0.03726840019226074\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_PdwxeMPXOCk_2.mid\n",
      "0.04007458686828613\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_DX1IK3z1w10_1.mid\n",
      "0.03011465072631836\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_By3JCii1k3w_0.mid\n",
      "0.018350601196289062\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_2.mid\n",
      "0.01605081558227539\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rW1I58_lMEg_3.mid\n",
      "0.025177001953125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UAm0aWvzFI8_0.mid\n",
      "0.05226778984069824\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_4.mid\n",
      "0.02177143096923828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_sZe3IB1OVfw_0.mid\n",
      "0.021730422973632812\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_XfA2KXodrOE_1.mid\n",
      "0.03525996208190918\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_15.mid\n",
      "0.02405691146850586\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_0.mid\n",
      "0.04147458076477051\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_qlbazHayULg_8.mid\n",
      "0.04200005531311035\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_7JIdJLkJ0S4_1.mid\n",
      "0.029007434844970703\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FoTXpYZXxJs_1.mid\n",
      "0.011610746383666992\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_--2B4d4lQhs_0.mid\n",
      "0.040384531021118164\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Y5JcZQ0xg4Y_2.mid\n",
      "0.026856422424316406\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rDhbGjFlKF8_1.mid\n",
      "0.01319742202758789\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_4.mid\n",
      "0.028905630111694336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ldCQ6N9G6Mk_0.mid\n",
      "0.005742311477661133\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_TNoaOTrTkTQ_0.mid\n",
      "0.03678250312805176\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_38i12IPkL5c_0.mid\n",
      "0.02577376365661621\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_X1p8xcarVu0_1.mid\n",
      "0.015973567962646484\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UpHutdJvZMI_2.mid\n",
      "0.020318031311035156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_V3Y9L4UOcpk_0.mid\n",
      "0.016631364822387695\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_20.mid\n",
      "0.02097320556640625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_osxmQReE_2o_0.mid\n",
      "0.027363061904907227\n",
      "data/emopia/EMOPIA_2.2/midis/Q4__BK2o77sTc0_2.mid\n",
      "0.026350021362304688\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_4dXC1cC7crw_0.mid\n",
      "0.024541854858398438\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_QJlnTN7HRwE_2.mid\n",
      "0.010327339172363281\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pRuwHN-lI44_1.mid\n",
      "0.016704559326171875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_q4T8Znozvkk_0.mid\n",
      "0.013360023498535156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UaYYMRkHMYc_1.mid\n",
      "0.041344404220581055\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_4.mid\n",
      "0.012709617614746094\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_-jJVb0xvbdg_1.mid\n",
      "0.15477919578552246\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_23.mid\n",
      "0.021938323974609375\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_94ROf10d1iA_3.mid\n",
      "0.027455806732177734\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_6.mid\n",
      "0.02612900733947754\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FSzOgraSKhs_0.mid\n",
      "0.011496782302856445\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lTxVVdhFE6Q_1.mid\n",
      "0.01909327507019043\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_4.mid\n",
      "0.01791834831237793\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_170KC2CbJ7Y_0.mid\n",
      "0.02173924446105957\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zHwJG8Rrx6c_2.mid\n",
      "0.02970147132873535\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_4.mid\n",
      "0.04201483726501465\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_yC0fAQxGgr0_1.mid\n",
      "0.027575969696044922\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zMa78n8ULtE_0.mid\n",
      "0.010757684707641602\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UaYYMRkHMYc_0.mid\n",
      "0.04344677925109863\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_FfwKrQyQ7WU_2.mid\n",
      "0.018091201782226562\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cQp1BYDGcRo_0.mid\n",
      "0.036516666412353516\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_xgtwQGeB6_0_0.mid\n",
      "0.01934671401977539\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_hoPp_GLXQis_0.mid\n",
      "0.025176525115966797\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_RaUSISlnhKw_1.mid\n",
      "0.03900718688964844\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ury1cdB79s0_1.mid\n",
      "0.024942398071289062\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zvWX_dwQPtU_2.mid\n",
      "0.025209426879882812\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_IH2KrGjKXw0_1.mid\n",
      "0.02041149139404297\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iHPKusssXzk_0.mid\n",
      "0.020802021026611328\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_kKFwiXKlhC8_0.mid\n",
      "0.02310490608215332\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k4lT-sXg3iI_1.mid\n",
      "0.021443843841552734\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltxNPJda7zE_0.mid\n",
      "0.008642196655273438\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XWk5XUEBXmg_1.mid\n",
      "0.017626523971557617\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_yC0fAQxGgr0_0.mid\n",
      "0.016840696334838867\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tjno89OVuRI_1.mid\n",
      "0.019318103790283203\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ldCQ6N9G6Mk_3.mid\n",
      "0.018517017364501953\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_3ZnxqCZ7qGg_2.mid\n",
      "0.023021697998046875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_biROWEwkDQQ_1.mid\n",
      "0.02224898338317871\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_6.mid\n",
      "0.03269338607788086\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_cXxGBDgFCs8_1.mid\n",
      "0.014013290405273438\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_E5qEloUO3SM_1.mid\n",
      "0.016825199127197266\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_uqRLEByE6pU_1.mid\n",
      "0.015607357025146484\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_aYe-2Glruu4_3.mid\n",
      "0.022217988967895508\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_48EYLEAgaBc_0.mid\n",
      "0.00784158706665039\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_yFw_kO7DF-Y_2.mid\n",
      "0.04275655746459961\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_k6aLLVX1D7Y_2.mid\n",
      "0.018307924270629883\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_bfopzItCYrE_2.mid\n",
      "0.016712665557861328\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_29.mid\n",
      "0.007066249847412109\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ItGNJM6skM4_0.mid\n",
      "0.039724111557006836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JP3QKZlyQz4_1.mid\n",
      "0.011188030242919922\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_GbUV3TXUzeQ_0.mid\n",
      "0.020117998123168945\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_T92R7xjce34_0.mid\n",
      "0.018546342849731445\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D5kyjnlDNZs_1.mid\n",
      "0.034749507904052734\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jIKX3ShvLxo_2.mid\n",
      "0.045455217361450195\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_26.mid\n",
      "0.021610021591186523\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_REq37pDAm3A_1.mid\n",
      "0.017477750778198242\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_iRu9KQvbtVw_0.mid\n",
      "0.01975536346435547\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_2.mid\n",
      "0.046918392181396484\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Y1F0c3zgMJo_0.mid\n",
      "0.01621413230895996\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_BIRDDxz0E4c_0.mid\n",
      "0.013665914535522461\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_pouxqiySdI8_0.mid\n",
      "0.024173736572265625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_3.mid\n",
      "0.040419578552246094\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_0.mid\n",
      "0.021085500717163086\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FOcdHIhI0_s_0.mid\n",
      "0.010148048400878906\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ijfxkQPAQdE_0.mid\n",
      "0.05508160591125488\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_uUtnyA6tLnI_0.mid\n",
      "0.022464990615844727\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_aQ4PIaRMLwE_2.mid\n",
      "0.0278778076171875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_SQDuF0qxGQw_0.mid\n",
      "0.021706581115722656\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_k6aLLVX1D7Y_0.mid\n",
      "0.0258181095123291\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8rupdevqfuI_2.mid\n",
      "0.017411470413208008\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_94ROf10d1iA_1.mid\n",
      "0.01539754867553711\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yZGBxiNPu3k_0.mid\n",
      "0.032222747802734375\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_pbVGv_g4n50_0.mid\n",
      "0.007848024368286133\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6kRPHamGDSo_0.mid\n",
      "0.01691746711730957\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1Qc15G0ZHIg_2.mid\n",
      "0.030687570571899414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_JNzqL24ZcZ8_1.mid\n",
      "0.01908254623413086\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_a5QCcwEjxAk_1.mid\n",
      "0.012038230895996094\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_heBmBQDWj-M_0.mid\n",
      "0.01983189582824707\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_UE0y8MHqT-g_0.mid\n",
      "0.016084909439086914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JYVXM0qNQAg_0.mid\n",
      "0.0217130184173584\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_DYBBfpEx-JI_4.mid\n",
      "0.01768970489501953\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bIx4DwkZxFY_2.mid\n",
      "0.01726245880126953\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S7Bo4-NCEDk_0.mid\n",
      "0.043463706970214844\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Uu-oRTRT6uQ_2.mid\n",
      "0.024201154708862305\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_--2B4d4lQhs_3.mid\n",
      "0.01608562469482422\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8izVTDgBQPc_1.mid\n",
      "0.02397298812866211\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_o5AIp2Yc01M_0.mid\n",
      "0.030829668045043945\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_9Xg69XrVaYU_0.mid\n",
      "0.02113795280456543\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_OO7zYVeK814_0.mid\n",
      "0.014018058776855469\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_nGkpcWNAxDU_1.mid\n",
      "0.02736496925354004\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_NzJjMGJg1wE_0.mid\n",
      "0.01698136329650879\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jO2zX6Ul8GM_2.mid\n",
      "0.01636648178100586\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TonQX8XbvX8_3.mid\n",
      "0.01578807830810547\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_1.mid\n",
      "0.026538372039794922\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_bbU31JLtlug_0.mid\n",
      "0.027881383895874023\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e838BE_MH6s_2.mid\n",
      "0.029610872268676758\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Wy2-my19YnY_0.mid\n",
      "0.02507615089416504\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_0vLPYiPN7qY_0.mid\n",
      "0.01471400260925293\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HYVmgq5Y93g_1.mid\n",
      "0.018210887908935547\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yhIncZ_Ue4E_1.mid\n",
      "0.01667928695678711\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_3.mid\n",
      "0.017834901809692383\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_18.mid\n",
      "0.018343210220336914\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5Ju9q1N2x0E_0.mid\n",
      "0.025904417037963867\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_G4rL_OtfFAU_1.mid\n",
      "0.05940747261047363\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_6kRPHamGDSo_2.mid\n",
      "0.016394376754760742\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zjr_-ql5Avk_2.mid\n",
      "0.006232261657714844\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_2uLw9Zs60A4_0.mid\n",
      "0.02337169647216797\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_14.mid\n",
      "0.016040325164794922\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_yFw_kO7DF-Y_0.mid\n",
      "0.03135848045349121\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_egYSmNuIFGk_1.mid\n",
      "0.019071102142333984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vJ77eDxHezE_1.mid\n",
      "0.026433229446411133\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_5.mid\n",
      "0.031946659088134766\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_4.mid\n",
      "0.03313612937927246\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_RL_cmmNVLfs_0.mid\n",
      "0.013859748840332031\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1Q3MoBFh6eU_1.mid\n",
      "0.03097057342529297\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Iq6g_4AwUWs_1.mid\n",
      "0.0234982967376709\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JT1XJnVmABo_4.mid\n",
      "0.018018007278442383\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ANZf1QXsNrY_7.mid\n",
      "0.03912758827209473\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_xIsvaT20pZ0_0.mid\n",
      "0.018039941787719727\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_gvWDOIiocuE_1.mid\n",
      "0.029572248458862305\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_9v2WSpn4FCw_1.mid\n",
      "0.014540672302246094\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zmZHNy9T8Pg_0.mid\n",
      "0.0225985050201416\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JT1XJnVmABo_0.mid\n",
      "0.15556097030639648\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_iFgSjUqI7iM_1.mid\n",
      "0.02179551124572754\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zMa78n8ULtE_1.mid\n",
      "0.00988316535949707\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_2.mid\n",
      "0.017824172973632812\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jSWItJI-Gmk_0.mid\n",
      "0.01667046546936035\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__8v0MFBZoco_1.mid\n",
      "0.0384371280670166\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_6n8HgIcJ6vo_0.mid\n",
      "0.014161825180053711\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_3.mid\n",
      "0.04149651527404785\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1vjy9oMFa8c_1.mid\n",
      "0.009882211685180664\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_4.mid\n",
      "0.01790785789489746\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3N2G21U7guk_3.mid\n",
      "0.0337519645690918\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wS0RzrBL9UI_1.mid\n",
      "0.013889074325561523\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0vLPYiPN7qY_3.mid\n",
      "0.033807992935180664\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S1T3UF1vhSk_2.mid\n",
      "0.02118372917175293\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_JT1XJnVmABo_1.mid\n",
      "0.019957304000854492\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_1.mid\n",
      "0.01016855239868164\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s6-SbDSZzEU_1.mid\n",
      "0.02065753936767578\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ItGNJM6skM4_2.mid\n",
      "0.05162668228149414\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_lFznCt5kvXM_0.mid\n",
      "0.04951047897338867\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_aYe-2Glruu4_0.mid\n",
      "0.0279543399810791\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_fey-8bOR95E_3.mid\n",
      "0.03529953956604004\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1kny88W533Q_0.mid\n",
      "0.01208806037902832\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_a5QCcwEjxAk_0.mid\n",
      "0.014387130737304688\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FUAK5TBaNY8_2.mid\n",
      "0.018465757369995117\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e838BE_MH6s_4.mid\n",
      "0.03428173065185547\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_u_7b9CwyM8Q_1.mid\n",
      "0.01321721076965332\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_REq37pDAm3A_0.mid\n",
      "0.010829687118530273\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_0.mid\n",
      "0.01935577392578125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_WpZ1rWHOCAQ_1.mid\n",
      "0.015333890914916992\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_3.mid\n",
      "0.016132593154907227\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S1T3UF1vhSk_1.mid\n",
      "0.013168811798095703\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_3.mid\n",
      "0.02095818519592285\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_4.mid\n",
      "0.07436013221740723\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_-vAz_HTFEXs_1.mid\n",
      "0.01878190040588379\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_fey-8bOR95E_2.mid\n",
      "0.028286457061767578\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_aYe-2Glruu4_2.mid\n",
      "0.031896352767944336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_sEQf5lcnj_o_3.mid\n",
      "0.053676605224609375\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_mGYKWCVnMwQ_0.mid\n",
      "0.01976919174194336\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_J6X3rVU1H-c_2.mid\n",
      "0.03352475166320801\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_32.mid\n",
      "0.01659393310546875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JT1XJnVmABo_2.mid\n",
      "0.012333393096923828\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_oTi57hZfArE_2.mid\n",
      "0.013744354248046875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Y5JcZQ0xg4Y_0.mid\n",
      "0.009964704513549805\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HQ8ISDX6PiI_1.mid\n",
      "0.017416715621948242\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iXiSFSGws-c_1.mid\n",
      "0.018949508666992188\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Dw7M69CidJ8_3.mid\n",
      "0.007869482040405273\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3N2G21U7guk_0.mid\n",
      "0.00838923454284668\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_pNwQ9Tu_bCs_0.mid\n",
      "0.01994919776916504\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bQS8eAXAhyE_1.mid\n",
      "0.016654253005981445\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_P-We4q3goKU_0.mid\n",
      "0.016533613204956055\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jNzZCplNNyY_1.mid\n",
      "0.02358269691467285\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltxNPJda7zE_4.mid\n",
      "0.007513761520385742\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ii1Jw1-7Ka4_0.mid\n",
      "0.006029605865478516\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UOSlDydo94E_2.mid\n",
      "0.026406049728393555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Cir1kZyB7QM_1.mid\n",
      "0.009952306747436523\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_11.mid\n",
      "0.01934647560119629\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_vVTP0DOL_2Q_0.mid\n",
      "0.016612768173217773\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_HY9vPoHbgaI_0.mid\n",
      "0.016049861907958984\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__SJQaaRzD-A_0.mid\n",
      "0.016812562942504883\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_lalnGhxT3PQ_1.mid\n",
      "0.03660106658935547\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_10.mid\n",
      "0.03345918655395508\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_1.mid\n",
      "0.020241737365722656\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_9Xg69XrVaYU_1.mid\n",
      "0.019649744033813477\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__BK2o77sTc0_0.mid\n",
      "0.023316383361816406\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_gSwv8hZGM-s_1.mid\n",
      "0.022849559783935547\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_OCqMDeD6Fmc_2.mid\n",
      "0.04937434196472168\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_MbvPxCUMSek_1.mid\n",
      "0.00823521614074707\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_DvIH5yUrboc_2.mid\n",
      "0.02503347396850586\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3N2G21U7guk_2.mid\n",
      "0.007901191711425781\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_kKFwiXKlhC8_1.mid\n",
      "0.048352956771850586\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_lalnGhxT3PQ_0.mid\n",
      "0.05267524719238281\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_QBJ6YYYpIyk_0.mid\n",
      "0.015261173248291016\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_sEQf5lcnj_o_1.mid\n",
      "0.0504460334777832\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_UuLTvhERcnk_1.mid\n",
      "0.021413087844848633\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_epX33OVpkmA_0.mid\n",
      "0.043517112731933594\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_fnqb8zqHqdY_0.mid\n",
      "0.014557838439941406\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_kopwU6zpS4k_0.mid\n",
      "0.01075601577758789\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_WpZ1rWHOCAQ_2.mid\n",
      "0.02617168426513672\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Q5b5unyP8BM_1.mid\n",
      "0.04986429214477539\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jIKX3ShvLxo_0.mid\n",
      "0.027045726776123047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_AWNbcxXDmt0_0.mid\n",
      "0.0319061279296875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_gSwv8hZGM-s_0.mid\n",
      "0.04015374183654785\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S7Bo4-NCEDk_2.mid\n",
      "0.0201570987701416\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_I2MrA-o5H8I_0.mid\n",
      "0.025346994400024414\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GY3f6ckBVkA_2.mid\n",
      "0.02876734733581543\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FyK_c-TIcCA_1.mid\n",
      "0.028926372528076172\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_3_MxhSS86oU_1.mid\n",
      "0.04145979881286621\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0J7lX-Tcx-w_1.mid\n",
      "0.0411677360534668\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_2eIsQtm4YNs_0.mid\n",
      "0.017193078994750977\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_GAvPwG2wYZM_0.mid\n",
      "0.010410785675048828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Fc1qk52SaKY_1.mid\n",
      "0.027564048767089844\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_mX-xs3OVhTs_0.mid\n",
      "0.01673722267150879\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__S991V8N-8s_1.mid\n",
      "0.02710127830505371\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_--2B4d4lQhs_2.mid\n",
      "0.04951167106628418\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_yFw_kO7DF-Y_1.mid\n",
      "0.028586149215698242\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_1.mid\n",
      "0.01886153221130371\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_gwmVjvR-sVs_2.mid\n",
      "0.010464668273925781\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KxlqB3j0zys_2.mid\n",
      "0.020493030548095703\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_25.mid\n",
      "0.024410247802734375\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s5b8viFsVJE_0.mid\n",
      "0.02998042106628418\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_miqLU2739dk_1.mid\n",
      "0.03716611862182617\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_0vLPYiPN7qY_1.mid\n",
      "0.03562450408935547\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_V3Y9L4UOcpk_2.mid\n",
      "0.02908921241760254\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_gvWDOIiocuE_0.mid\n",
      "0.017920970916748047\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_nOIBJHkqrE8_0.mid\n",
      "0.022083759307861328\n"
     ]
    }
   ],
   "source": [
    "encoded_sequences_path = \"data/encoded_sequences.pkl\"\n",
    "encoded_sequences = midi_encoder.encode_midi_list(midi_files_list, pkl_path=encoded_sequences_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the dataset and save it in a NumPy file\n",
    "dataset_path = \"data/datasets/\"\n",
    "midi_encoder_remi.save_dataset(midi_files_list, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:696: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset as a single file\n",
    "single_file_dataset_path = \"data/single_file_dataset.npz\"\n",
    "midi_encoder_remi.save_dataset_as_single_file(glob.glob(os.path.join(dataset_path, '*.npy')), single_file_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ece661-final-proj2/data/dataset.py:170: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  self.sequences = torch.Tensor(self.sequences)\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 256\n",
    "dataset = TransformerDatasetREMI(single_file_dataset_path, seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))\n",
    "valid_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  3507\n",
      "Validation dataset size:  751\n",
      "Test dataset size:  753\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size: \", len(train_dataset))\n",
    "print(\"Validation dataset size: \", len(valid_dataset))\n",
    "print(\"Test dataset size: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  54\n",
      "Validation dataset size:  11\n",
      "Test dataset size:  11\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "print(\"Train dataset size: \", len(train_dataloader))\n",
    "print(\"Validation dataset size: \", len(valid_dataloader))\n",
    "print(\"Test dataset size: \", len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = set()\n",
    "for dic in train_dataset:\n",
    "    ipt = dic['input'].numpy()\n",
    "    vocab_set = vocab_set.union(set(ipt))\n",
    "vocab_size = len(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.trainer import TransformerTrainer\n",
    "# from model.transformer import Generator, Discriminator, PatchDiscriminator\n",
    "# from utils.losses import MultiCrossEntropyLoss, TransfoCrossEntropyLoss,TransfoL1Loss, wgan_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = Generator(vocab_size, max_seq_len, dim=256)\n",
    "# discriminator = Discriminator(vocab_size, max_seq_len, dim=256)\n",
    "# patch_discriminator = PatchDiscriminator(vocab_size, max_seq_len, dim=256)\n",
    "\n",
    "# ce_loss = TransfoCrossEntropyLoss()\n",
    "# gan_loss = wgan_loss\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# generator.to(device)\n",
    "# discriminator.to(device)\n",
    "# patch_discriminator.to(device)\n",
    "\n",
    "# g_lr = 1e-4\n",
    "# d_lr = 1e-4\n",
    "\n",
    "# EPOCHS = 10\n",
    "# checkpoint_dir = \"checkpoints/model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = TransformerTrainer(generator, patch_discriminator, train_dataloader, train_dataloader, test_dataloader, ce_loss,\n",
    "#                gan_loss, device, g_lr, d_lr, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = trainer.train( EPOCHS, checkpoint_dir, validate = False, log_interval=20, load=False, save=True, train_gan=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's\n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "\n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and put it into features\n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, :len(row)] = np.array(row)[:seq_length]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroEmbedding(nn.Embedding):\n",
    "    \"\"\"\n",
    "    Used for biases.\n",
    "    \"\"\"\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        Initialize parameters.\n",
    "        \"\"\"\n",
    "\n",
    "        self.weight.data.zero_()\n",
    "        if self.padding_idx is not None:\n",
    "            self.weight.data[self.padding_idx].fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    PositionalEmbedding is a class for adding positional embeddings to token embeddings.\n",
    "\n",
    "    Args:\n",
    "        sequence_length (int): The maximum sequence length.\n",
    "        input_dim (int): The dimension of input token embeddings (vocabulary size)\n",
    "        output_dim (int): The dimension of output positional embeddings.\n",
    "\n",
    "    Attributes:\n",
    "        token_embeddings (nn.Embedding): The token embedding layer.\n",
    "        position_embeddings (nn.Embedding): The positional embedding layer.\n",
    "        sequence_length (int): The maximum sequence length.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sequence_length, input_dim, output_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        #TODO: add embedding layers to map words to vectors\n",
    "        self.token_embeddings = nn.Embedding(input_dim, output_dim)\n",
    "        #TODO: add embedding layers to map position index to vectors\n",
    "        self.position_embeddings = ZeroEmbedding(sequence_length, output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the PositionalEmbedding.\n",
    "\n",
    "        Args:\n",
    "            inputs (torch.Tensor): The input tensor of token indices.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor with positional embeddings added to token embeddings.\n",
    "        \"\"\"\n",
    "        length = inputs.size(-1)\n",
    "        device = inputs.device\n",
    "        #TODO: compute the position index 0, 1, ..., seq_len -1\n",
    "        positions = torch.arange(0, self.sequence_length).unsqueeze(0).to(device) # here we add the batch_size as first dim\n",
    "        #TODO: compute the word embeddings\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        #TODO: compute the positional embeddings\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        #TODO: return the final embeddings\n",
    "        return embedded_tokens + embedded_positions   # here the first dim of embedded_positions will be broadcasted to match the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        #TODO: Define multihead attention layer\n",
    "        #Input and output both have size (batch_size, seq_len, embed_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads,batch_first=True)\n",
    "\n",
    "\n",
    "        #TODO: define a two-layer Feed-forward network with hidden layer size dense_dim and output layer size embed_dim\n",
    "        self.dense_proj = nn.Sequential(\n",
    "            nn.Linear(embed_dim, dense_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dense_dim, embed_dim)\n",
    "        )\n",
    "        #TODO: define two layer normalization layers\n",
    "        self.layernorm_1 = nn.LayerNorm(embed_dim)\n",
    "        self.layernorm_2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the TransformerEncoder block.\n",
    "\n",
    "        Args:\n",
    "            inputs (torch.Tensor): The input tensor of shape (batch_size, seq_len, embed_dim).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor of shape ( batch_size,seq_len, embed_dim).\n",
    "        \"\"\"\n",
    "        #TODO: pass inputs through the multihead attention layer\n",
    "        attention_output, _ = self.attention(query=inputs, key=inputs, value=inputs)\n",
    "        #TODO: pass the attention output through the add+normalization layer\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        #TODO: pass through the feed-forward network\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        #TODO: pass through another add+normalization layer and output\n",
    "        return self.layernorm_2(proj_input + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderModel(nn.Module):\n",
    "    \"\"\"\n",
    "    TransformerEncoderModel is a class representing a text classification model using Transformer encoder with positional embeddings.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): The size of the vocabulary.\n",
    "        embed_dim (int): The dimension of the input embeddings and output embeddings.\n",
    "        num_heads (int): The number of attention heads in the Transformer encoder.\n",
    "        dense_dim (int): The dimension of the intermediate dense layer.\n",
    "        sequence_length (int): The maximum sequence length for positional embeddings.\n",
    "\n",
    "    Attributes:\n",
    "        embedding (PositionalEmbedding): The positional embedding layer.\n",
    "        transformer_encoder (TransformerEncoder): The Transformer encoder block.\n",
    "        global_max_pooling (nn.AdaptiveMaxPool1d): The global max-pooling layer.\n",
    "        dropout (nn.Dropout): The dropout layer.\n",
    "        fc (nn.Linear): The fully connected layer for classification.\n",
    "        sigmoid (nn.Sigmoid): The sigmoid activation function for binary classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, dense_dim, sequence_length, num_classes):\n",
    "        super(TransformerEncoderModel, self).__init__()\n",
    "\n",
    "        #TODO: add embedding layer that maps word to vectors\n",
    "        self.embedding = PositionalEmbedding(sequence_length, vocab_size, embed_dim)\n",
    "\n",
    "        #TODO: add transformer encoder\n",
    "        self.transformer_encoder = TransformerEncoder(embed_dim, dense_dim, num_heads)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(embed_dim, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the TransformerEncoderModel for text classification.\n",
    "\n",
    "        Args:\n",
    "            inputs (torch.Tensor): The input tensor of shape (batch_size, seq_len).\n",
    "            mask (torch.Tensor, optional): The attention mask tensor of shape (batch_size, seq_len).\n",
    "                Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor with sigmoid activation for binary classification.\n",
    "        \"\"\"\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.transformer_encoder(x)        # x has shape (Batch, Seq_Len, Embed_dim)\n",
    "        x,_ = torch.max(x, dim=1)              # x has shape (Batch, Embd_dim)\n",
    "        x = self.dropout(x)                    # pass dropout layer\n",
    "        x = self.fc(x)                         # pass a linear layer\n",
    "        return self.sigmoid(x)                 # pass sigmoid activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerEncoderModel(\n",
      "  (embedding): PositionalEmbedding(\n",
      "    (token_embeddings): Embedding(198, 512)\n",
      "    (position_embeddings): ZeroEmbedding(300, 512)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (dense_proj): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    )\n",
      "    (layernorm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (layernorm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "num_heads = 8\n",
    "dense_dim = 1024\n",
    "embed_dim = 512\n",
    "model = TransformerEncoderModel(vocab_size, embed_dim, num_heads, dense_dim, sequence_length = max_seq_len, num_classes=4)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import ClassifierDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ClassifierDataset(single_file_dataset_path, seq_len=max_seq_len, labels_path=\"data/emopia/EMOPIA_2.2/label.csv\")\n",
    "train_size = int(0.7 * len(dataset))\n",
    "valid_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  3520\n",
      "Validation dataset size:  754\n",
      "Test dataset size:  755\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size: \", len(train_dataset))\n",
    "print(\"Validation dataset size: \", len(valid_dataset))\n",
    "print(\"Test dataset size: \", len(test_dataset))\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "vocab_set = set()\n",
    "for dic in train_dataset:\n",
    "    ipt = dic['input'].numpy()\n",
    "    vocab_set = vocab_set.union(set(ipt))\n",
    "vocab_size = len(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, num_epochs=100):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    best_loss = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "        ### Traing Loop ####\n",
    "        #0. Loop through all the training batches\n",
    "        for batch in train_loader:\n",
    "            inputs = batch['input'].to(device)\n",
    "            labels = batch['target'].to(device)\n",
    "            #1. Compute the output\n",
    "            outputs = model(inputs).squeeze(1)\n",
    "            #2. Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            #3. Zero out gradients\n",
    "            optimizer.zero_grad()\n",
    "            #4. Compute new gradients, by backward propagation\n",
    "            loss.backward()\n",
    "            #5. Update the model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        # Print training loss for this epoch\n",
    "        # print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {train_loss / len(train_loader)}\")\n",
    "\n",
    "        ### Validation Loop ###\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                inputs = batch['input'].to(device)\n",
    "                labels = batch['target'].to(device)\n",
    "                outputs = model(inputs).squeeze(1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                predicted = torch.argmax(outputs, dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                test_loss += loss.item()\n",
    "            valid_losses.append(test_loss / len(valid_loader))\n",
    "\n",
    "        val_acc = 100 * correct / total\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            print(\"Saving...\")\n",
    "            torch.save(model.state_dict(), \"checkpoints/transformer_classifier.pt\")\n",
    "            print(\"Model saved!\")\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs},Training Loss: {(train_loss / len(train_loader)):.4f}, Validation Loss: {(test_loss / len(valid_loader)):.4f}, Validation Accuracy: {val_acc:.2f}\")\n",
    "\n",
    "    \n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n",
      "Model saved!\n",
      "Epoch 1/100,Training Loss: 1.1627, Validation Loss: 1.1095, Validation Accuracy: 52.97\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch 2/100,Training Loss: 1.0991, Validation Loss: 1.1025, Validation Accuracy: 52.03\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch 3/100,Training Loss: 1.0819, Validation Loss: 1.0880, Validation Accuracy: 60.47\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch 4/100,Training Loss: 1.0689, Validation Loss: 1.0808, Validation Accuracy: 62.50\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch 5/100,Training Loss: 1.0543, Validation Loss: 1.0781, Validation Accuracy: 63.44\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch 6/100,Training Loss: 1.0359, Validation Loss: 1.0702, Validation Accuracy: 61.56\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch 7/100,Training Loss: 1.0261, Validation Loss: 1.0609, Validation Accuracy: 62.66\n",
      "Epoch 8/100,Training Loss: 1.0177, Validation Loss: 1.0666, Validation Accuracy: 63.59\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch 9/100,Training Loss: 1.0155, Validation Loss: 1.0598, Validation Accuracy: 62.34\n",
      "Epoch 10/100,Training Loss: 1.0051, Validation Loss: 1.0608, Validation Accuracy: 61.56\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch 11/100,Training Loss: 0.9932, Validation Loss: 1.0507, Validation Accuracy: 65.00\n",
      "Epoch 12/100,Training Loss: 0.9812, Validation Loss: 1.0596, Validation Accuracy: 62.66\n",
      "Epoch 13/100,Training Loss: 0.9830, Validation Loss: 1.0630, Validation Accuracy: 63.75\n",
      "Epoch 14/100,Training Loss: 0.9696, Validation Loss: 1.0605, Validation Accuracy: 63.28\n",
      "Epoch 15/100,Training Loss: 0.9635, Validation Loss: 1.0603, Validation Accuracy: 64.06\n",
      "Epoch 16/100,Training Loss: 0.9551, Validation Loss: 1.0619, Validation Accuracy: 64.38\n",
      "Epoch 17/100,Training Loss: 0.9479, Validation Loss: 1.0549, Validation Accuracy: 66.88\n",
      "Epoch 18/100,Training Loss: 0.9478, Validation Loss: 1.0634, Validation Accuracy: 65.47\n",
      "Epoch 19/100,Training Loss: 0.9476, Validation Loss: 1.0749, Validation Accuracy: 63.59\n",
      "Epoch 20/100,Training Loss: 0.9389, Validation Loss: 1.0659, Validation Accuracy: 64.06\n",
      "Epoch 21/100,Training Loss: 0.9299, Validation Loss: 1.0600, Validation Accuracy: 65.62\n",
      "Epoch 22/100,Training Loss: 0.9273, Validation Loss: 1.0726, Validation Accuracy: 61.72\n",
      "Epoch 23/100,Training Loss: 0.9206, Validation Loss: 1.0630, Validation Accuracy: 65.47\n",
      "Epoch 24/100,Training Loss: 0.9136, Validation Loss: 1.0599, Validation Accuracy: 67.81\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch 25/100,Training Loss: 0.9112, Validation Loss: 1.0507, Validation Accuracy: 66.56\n",
      "Epoch 26/100,Training Loss: 0.9105, Validation Loss: 1.0778, Validation Accuracy: 63.28\n",
      "Epoch 27/100,Training Loss: 0.9117, Validation Loss: 1.0766, Validation Accuracy: 63.28\n",
      "Epoch 28/100,Training Loss: 0.9055, Validation Loss: 1.0642, Validation Accuracy: 67.03\n",
      "Epoch 29/100,Training Loss: 0.9053, Validation Loss: 1.0700, Validation Accuracy: 66.41\n",
      "Epoch 30/100,Training Loss: 0.9053, Validation Loss: 1.0602, Validation Accuracy: 65.47\n",
      "Epoch 31/100,Training Loss: 0.8938, Validation Loss: 1.0616, Validation Accuracy: 65.31\n",
      "Epoch 32/100,Training Loss: 0.8939, Validation Loss: 1.1018, Validation Accuracy: 57.34\n",
      "Epoch 33/100,Training Loss: 0.8970, Validation Loss: 1.0600, Validation Accuracy: 64.53\n",
      "Epoch 34/100,Training Loss: 0.8847, Validation Loss: 1.0721, Validation Accuracy: 63.59\n",
      "Epoch 35/100,Training Loss: 0.8784, Validation Loss: 1.0639, Validation Accuracy: 65.16\n",
      "Epoch 36/100,Training Loss: 0.8716, Validation Loss: 1.0679, Validation Accuracy: 63.28\n",
      "Epoch 37/100,Training Loss: 0.8896, Validation Loss: 1.0956, Validation Accuracy: 60.16\n",
      "Epoch 38/100,Training Loss: 0.8921, Validation Loss: 1.0810, Validation Accuracy: 61.88\n",
      "Epoch 39/100,Training Loss: 0.8858, Validation Loss: 1.0879, Validation Accuracy: 62.50\n",
      "Epoch 40/100,Training Loss: 0.8809, Validation Loss: 1.0811, Validation Accuracy: 62.50\n",
      "Epoch 41/100,Training Loss: 0.8686, Validation Loss: 1.0606, Validation Accuracy: 65.16\n",
      "Epoch 42/100,Training Loss: 0.8639, Validation Loss: 1.0842, Validation Accuracy: 64.53\n",
      "Epoch 43/100,Training Loss: 0.8690, Validation Loss: 1.0940, Validation Accuracy: 62.50\n",
      "Epoch 44/100,Training Loss: 0.8744, Validation Loss: 1.0903, Validation Accuracy: 60.31\n",
      "Epoch 45/100,Training Loss: 0.8809, Validation Loss: 1.1046, Validation Accuracy: 60.78\n",
      "Epoch 46/100,Training Loss: 0.8664, Validation Loss: 1.0975, Validation Accuracy: 60.16\n",
      "Epoch 47/100,Training Loss: 0.8565, Validation Loss: 1.1007, Validation Accuracy: 61.72\n",
      "Epoch 48/100,Training Loss: 0.8647, Validation Loss: 1.0877, Validation Accuracy: 62.97\n",
      "Epoch 49/100,Training Loss: 0.8482, Validation Loss: 1.1172, Validation Accuracy: 59.53\n",
      "Epoch 50/100,Training Loss: 0.8539, Validation Loss: 1.1266, Validation Accuracy: 57.34\n",
      "Epoch 51/100,Training Loss: 0.8580, Validation Loss: 1.1178, Validation Accuracy: 58.75\n",
      "Epoch 52/100,Training Loss: 0.8489, Validation Loss: 1.1171, Validation Accuracy: 60.00\n",
      "Epoch 53/100,Training Loss: 0.8581, Validation Loss: 1.0889, Validation Accuracy: 63.12\n",
      "Epoch 54/100,Training Loss: 0.8702, Validation Loss: 1.0746, Validation Accuracy: 64.06\n",
      "Epoch 55/100,Training Loss: 0.8702, Validation Loss: 1.0774, Validation Accuracy: 65.47\n",
      "Epoch 56/100,Training Loss: 0.8513, Validation Loss: 1.0842, Validation Accuracy: 63.91\n",
      "Epoch 57/100,Training Loss: 0.8423, Validation Loss: 1.0898, Validation Accuracy: 61.25\n",
      "Epoch 58/100,Training Loss: 0.8409, Validation Loss: 1.0890, Validation Accuracy: 63.12\n",
      "Epoch 59/100,Training Loss: 0.8410, Validation Loss: 1.0930, Validation Accuracy: 61.72\n",
      "Epoch 60/100,Training Loss: 0.8298, Validation Loss: 1.1065, Validation Accuracy: 60.62\n",
      "Epoch 61/100,Training Loss: 0.8319, Validation Loss: 1.0985, Validation Accuracy: 61.88\n",
      "Epoch 62/100,Training Loss: 0.8306, Validation Loss: 1.0987, Validation Accuracy: 61.41\n",
      "Epoch 63/100,Training Loss: 0.8357, Validation Loss: 1.0904, Validation Accuracy: 62.34\n",
      "Epoch 64/100,Training Loss: 0.8292, Validation Loss: 1.0830, Validation Accuracy: 63.28\n",
      "Epoch 65/100,Training Loss: 0.8272, Validation Loss: 1.0936, Validation Accuracy: 62.66\n",
      "Epoch 66/100,Training Loss: 0.8193, Validation Loss: 1.1035, Validation Accuracy: 62.81\n",
      "Epoch 67/100,Training Loss: 0.8201, Validation Loss: 1.0966, Validation Accuracy: 62.66\n",
      "Epoch 68/100,Training Loss: 0.8217, Validation Loss: 1.0858, Validation Accuracy: 63.91\n",
      "Epoch 69/100,Training Loss: 0.8219, Validation Loss: 1.0900, Validation Accuracy: 62.97\n",
      "Epoch 70/100,Training Loss: 0.8143, Validation Loss: 1.0894, Validation Accuracy: 61.41\n",
      "Epoch 71/100,Training Loss: 0.8074, Validation Loss: 1.0840, Validation Accuracy: 62.34\n",
      "Epoch 72/100,Training Loss: 0.8044, Validation Loss: 1.0960, Validation Accuracy: 62.50\n",
      "Epoch 73/100,Training Loss: 0.8000, Validation Loss: 1.0975, Validation Accuracy: 61.88\n",
      "Epoch 74/100,Training Loss: 0.7950, Validation Loss: 1.1021, Validation Accuracy: 62.50\n",
      "Epoch 75/100,Training Loss: 0.7882, Validation Loss: 1.0942, Validation Accuracy: 61.72\n",
      "Epoch 76/100,Training Loss: 0.7881, Validation Loss: 1.1130, Validation Accuracy: 61.25\n",
      "Epoch 77/100,Training Loss: 0.7980, Validation Loss: 1.1226, Validation Accuracy: 58.59\n",
      "Epoch 78/100,Training Loss: 0.7922, Validation Loss: 1.1165, Validation Accuracy: 59.53\n",
      "Epoch 79/100,Training Loss: 0.7938, Validation Loss: 1.1066, Validation Accuracy: 60.78\n",
      "Epoch 80/100,Training Loss: 0.7864, Validation Loss: 1.0986, Validation Accuracy: 62.03\n",
      "Epoch 81/100,Training Loss: 0.7912, Validation Loss: 1.1108, Validation Accuracy: 60.94\n",
      "Epoch 82/100,Training Loss: 0.7930, Validation Loss: 1.1004, Validation Accuracy: 61.72\n",
      "Epoch 83/100,Training Loss: 0.7879, Validation Loss: 1.1109, Validation Accuracy: 61.56\n",
      "Epoch 84/100,Training Loss: 0.7923, Validation Loss: 1.1180, Validation Accuracy: 59.06\n",
      "Epoch 85/100,Training Loss: 0.7935, Validation Loss: 1.1295, Validation Accuracy: 60.00\n",
      "Epoch 86/100,Training Loss: 0.7990, Validation Loss: 1.1032, Validation Accuracy: 63.12\n",
      "Epoch 87/100,Training Loss: 0.7962, Validation Loss: 1.1136, Validation Accuracy: 62.03\n",
      "Epoch 88/100,Training Loss: 0.7919, Validation Loss: 1.1066, Validation Accuracy: 60.31\n",
      "Epoch 89/100,Training Loss: 0.7936, Validation Loss: 1.0920, Validation Accuracy: 63.28\n",
      "Epoch 90/100,Training Loss: 0.7993, Validation Loss: 1.0937, Validation Accuracy: 62.81\n",
      "Epoch 91/100,Training Loss: 0.7924, Validation Loss: 1.1127, Validation Accuracy: 61.72\n",
      "Epoch 92/100,Training Loss: 0.7888, Validation Loss: 1.1104, Validation Accuracy: 60.78\n",
      "Epoch 93/100,Training Loss: 0.7903, Validation Loss: 1.0964, Validation Accuracy: 63.59\n",
      "Epoch 94/100,Training Loss: 0.7928, Validation Loss: 1.0969, Validation Accuracy: 62.81\n",
      "Epoch 95/100,Training Loss: 0.7865, Validation Loss: 1.0927, Validation Accuracy: 62.97\n",
      "Epoch 96/100,Training Loss: 0.7879, Validation Loss: 1.0922, Validation Accuracy: 64.06\n",
      "Epoch 97/100,Training Loss: 0.7865, Validation Loss: 1.1031, Validation Accuracy: 63.12\n",
      "Epoch 98/100,Training Loss: 0.7906, Validation Loss: 1.1162, Validation Accuracy: 61.25\n",
      "Epoch 99/100,Training Loss: 0.7950, Validation Loss: 1.1115, Validation Accuracy: 62.66\n",
      "Epoch 100/100,Training Loss: 0.7946, Validation Loss: 1.1011, Validation Accuracy: 62.97\n"
     ]
    }
   ],
   "source": [
    "train_losses, valid_losses = train(model, train_dataloader, valid_dataloader, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.classifier import PatchClassifier\n",
    "from utils.classifier_trainer import ClassifierTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your model, dataloaders, loss function, device, learning rate, vocabulary size, etc. defined\n",
    "\n",
    "# Instantiate your ClassifierTrainer\n",
    "classifier_model = PatchClassifier(vocab_size, max_seq_len, 256)  # Replace with your actual classifier model\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()  # Replace with your actual loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available, else use CPU\n",
    "\n",
    "classifier_model.to(device)\n",
    "\n",
    "vocab_size = vocab_size  \n",
    "learning_rate = 0.001  # Replace with your actual learning rate\n",
    "\n",
    "# Instantiate the ClassifierTrainer\n",
    "classifier_trainer = ClassifierTrainer(\n",
    "    model=classifier_model,\n",
    "    dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    ce_loss=cross_entropy_loss,\n",
    "    device=device,\n",
    "    lr=learning_rate,\n",
    "    vocab_size=vocab_size,\n",
    "    warmup_steps=1000,  # Replace with your desired warmup steps\n",
    "    total_iters=30000,  # Replace with your desired total iterations\n",
    "    schedule='cosine_with_warmup'  # Replace with your desired learning rate schedule\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "| End of epoch   1  | time: 3.7005s | valid loss 1.320108 | valid accuracy 0.367045 |\n",
      "Epoch 2/20\n",
      "----------\n",
      "| End of epoch   2  | time: 2.4831s | valid loss 0.946805 | valid accuracy 0.526705 |\n",
      "Epoch 3/20\n",
      "----------\n",
      "| End of epoch   3  | time: 2.4765s | valid loss 0.873441 | valid accuracy 0.567330 |\n",
      "Epoch 4/20\n",
      "----------\n",
      "| End of epoch   4  | time: 2.5036s | valid loss 0.791025 | valid accuracy 0.640909 |\n",
      "Epoch 5/20\n",
      "----------\n",
      "| End of epoch   5  | time: 2.4774s | valid loss 0.709347 | valid accuracy 0.690909 |\n",
      "Epoch 6/20\n",
      "----------\n",
      "| End of epoch   6  | time: 2.4580s | valid loss 0.705034 | valid accuracy 0.701136 |\n",
      "Epoch 7/20\n",
      "----------\n",
      "| End of epoch   7  | time: 2.4757s | valid loss 0.642763 | valid accuracy 0.732670 |\n",
      "Epoch 8/20\n",
      "----------\n",
      "| End of epoch   8  | time: 2.4528s | valid loss 0.673216 | valid accuracy 0.700568 |\n",
      "Epoch 9/20\n",
      "----------\n",
      "| End of epoch   9  | time: 2.4249s | valid loss 0.635992 | valid accuracy 0.727273 |\n",
      "Epoch 10/20\n",
      "----------\n",
      "| End of epoch  10  | time: 2.4385s | valid loss 0.581143 | valid accuracy 0.765909 |\n",
      "Epoch 11/20\n",
      "----------\n",
      "| End of epoch  11  | time: 2.4827s | valid loss 0.624262 | valid accuracy 0.755682 |\n",
      "Epoch 12/20\n",
      "----------\n",
      "| End of epoch  12  | time: 2.4385s | valid loss 0.627420 | valid accuracy 0.751420 |\n",
      "Epoch 13/20\n",
      "----------\n",
      "| End of epoch  13  | time: 2.4406s | valid loss 0.487383 | valid accuracy 0.821023 |\n",
      "Epoch 14/20\n",
      "----------\n",
      "| End of epoch  14  | time: 2.4656s | valid loss 0.473330 | valid accuracy 0.836080 |\n",
      "Epoch 15/20\n",
      "----------\n",
      "| End of epoch  15  | time: 2.4803s | valid loss 0.459297 | valid accuracy 0.840057 |\n",
      "Epoch 16/20\n",
      "----------\n",
      "| End of epoch  16  | time: 2.4771s | valid loss 0.459085 | valid accuracy 0.837216 |\n",
      "Epoch 17/20\n",
      "----------\n",
      "| End of epoch  17  | time: 2.4316s | valid loss 0.515612 | valid accuracy 0.805966 |\n",
      "Epoch 18/20\n",
      "----------\n",
      "| End of epoch  18  | time: 2.4310s | valid loss 0.448011 | valid accuracy 0.853977 |\n",
      "Epoch 19/20\n",
      "----------\n",
      "| End of epoch  19  | time: 2.4643s | valid loss 0.487570 | valid accuracy 0.825568 |\n",
      "Epoch 20/20\n",
      "----------\n",
      "| End of epoch  20  | time: 2.4247s | valid loss 0.474563 | valid accuracy 0.837216 |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'train_acc': [tensor(0.3670, device='cuda:0'),\n",
       "              tensor(0.5267, device='cuda:0'),\n",
       "              tensor(0.5673, device='cuda:0'),\n",
       "              tensor(0.6409, device='cuda:0'),\n",
       "              tensor(0.6909, device='cuda:0'),\n",
       "              tensor(0.7011, device='cuda:0'),\n",
       "              tensor(0.7327, device='cuda:0'),\n",
       "              tensor(0.7006, device='cuda:0'),\n",
       "              tensor(0.7273, device='cuda:0'),\n",
       "              tensor(0.7659, device='cuda:0'),\n",
       "              tensor(0.7557, device='cuda:0'),\n",
       "              tensor(0.7514, device='cuda:0'),\n",
       "              tensor(0.8210, device='cuda:0'),\n",
       "              tensor(0.8361, device='cuda:0'),\n",
       "              tensor(0.8401, device='cuda:0'),\n",
       "              tensor(0.8372, device='cuda:0'),\n",
       "              tensor(0.8060, device='cuda:0'),\n",
       "              tensor(0.8540, device='cuda:0'),\n",
       "              tensor(0.8256, device='cuda:0'),\n",
       "              tensor(0.8372, device='cuda:0')],\n",
       "             'train_loss': [1.3201083638451316,\n",
       "              0.9468052116307345,\n",
       "              0.8734406319531527,\n",
       "              0.7910249005664479,\n",
       "              0.709347106109966,\n",
       "              0.7050335331396623,\n",
       "              0.6427634407173504,\n",
       "              0.673215671560981,\n",
       "              0.6359923070127314,\n",
       "              0.5811434878544374,\n",
       "              0.6242619763721119,\n",
       "              0.6274195606058294,\n",
       "              0.48738265145908705,\n",
       "              0.47333043163472954,\n",
       "              0.45929682444442405,\n",
       "              0.45908530191941693,\n",
       "              0.5156117525967685,\n",
       "              0.44801101874221455,\n",
       "              0.48757000267505646,\n",
       "              0.4745626864108172],\n",
       "             'train_losses': [[1.650823950767517,\n",
       "               1.5016729831695557,\n",
       "               1.6571805477142334,\n",
       "               1.4179803133010864,\n",
       "               1.4229944944381714,\n",
       "               1.4684584140777588,\n",
       "               1.4793205261230469,\n",
       "               1.4189095497131348,\n",
       "               1.431554913520813,\n",
       "               1.420620322227478,\n",
       "               1.422082543373108,\n",
       "               1.451926350593567,\n",
       "               1.4144684076309204,\n",
       "               1.2780354022979736,\n",
       "               1.4871257543563843,\n",
       "               1.4592221975326538,\n",
       "               1.434975028038025,\n",
       "               1.4328781366348267,\n",
       "               1.3957451581954956,\n",
       "               1.3497402667999268,\n",
       "               1.4215160608291626,\n",
       "               1.4133516550064087,\n",
       "               1.3770045042037964,\n",
       "               1.4723414182662964,\n",
       "               1.3355741500854492,\n",
       "               1.464367389678955,\n",
       "               1.4363659620285034,\n",
       "               1.3813703060150146,\n",
       "               1.2915682792663574,\n",
       "               1.299270749092102,\n",
       "               1.3966953754425049,\n",
       "               1.3171536922454834,\n",
       "               1.2257471084594727,\n",
       "               1.2680203914642334,\n",
       "               1.3529542684555054,\n",
       "               1.3459454774856567,\n",
       "               1.2269046306610107,\n",
       "               1.308526635169983,\n",
       "               1.314200758934021,\n",
       "               1.2484776973724365,\n",
       "               1.2351385354995728,\n",
       "               1.1534072160720825,\n",
       "               1.1558945178985596,\n",
       "               1.0990309715270996,\n",
       "               1.1381150484085083,\n",
       "               1.1097289323806763,\n",
       "               1.0479785203933716,\n",
       "               1.302085041999817,\n",
       "               1.1597375869750977,\n",
       "               1.1065986156463623,\n",
       "               1.0905331373214722,\n",
       "               1.0841853618621826,\n",
       "               1.0958272218704224,\n",
       "               1.1174511909484863,\n",
       "               0.817176342010498],\n",
       "              [0.8991754055023193,\n",
       "               0.8761650919914246,\n",
       "               1.09225332736969,\n",
       "               1.0250136852264404,\n",
       "               0.7977060079574585,\n",
       "               1.1290900707244873,\n",
       "               1.3391103744506836,\n",
       "               0.9318633675575256,\n",
       "               1.0352452993392944,\n",
       "               1.0005106925964355,\n",
       "               1.0410125255584717,\n",
       "               0.8438771963119507,\n",
       "               0.8344589471817017,\n",
       "               0.8866267800331116,\n",
       "               1.0287976264953613,\n",
       "               0.9387244582176208,\n",
       "               1.1018551588058472,\n",
       "               0.9956353306770325,\n",
       "               0.9256083369255066,\n",
       "               0.868053138256073,\n",
       "               1.0094263553619385,\n",
       "               0.9240022897720337,\n",
       "               0.9787505865097046,\n",
       "               0.8890191912651062,\n",
       "               0.9619866609573364,\n",
       "               1.1118167638778687,\n",
       "               0.8826982378959656,\n",
       "               1.0187890529632568,\n",
       "               0.9049776792526245,\n",
       "               1.0298106670379639,\n",
       "               0.8770444393157959,\n",
       "               0.937138557434082,\n",
       "               0.996021568775177,\n",
       "               0.9845322370529175,\n",
       "               0.8292593955993652,\n",
       "               0.8193808794021606,\n",
       "               0.8725736141204834,\n",
       "               0.8982572555541992,\n",
       "               1.0361350774765015,\n",
       "               1.0609556436538696,\n",
       "               0.9193112254142761,\n",
       "               0.8104019165039062,\n",
       "               0.8067887425422668,\n",
       "               0.8907331228256226,\n",
       "               0.8831334114074707,\n",
       "               0.8655283451080322,\n",
       "               0.7905696630477905,\n",
       "               1.1443192958831787,\n",
       "               0.9348289370536804,\n",
       "               0.9891267418861389,\n",
       "               0.9294980764389038,\n",
       "               0.8623174428939819,\n",
       "               0.952229380607605,\n",
       "               0.9316495656967163,\n",
       "               0.7504917979240417],\n",
       "              [0.7990321516990662,\n",
       "               0.8523829579353333,\n",
       "               0.89680016040802,\n",
       "               0.9931875467300415,\n",
       "               0.7696250677108765,\n",
       "               1.131517767906189,\n",
       "               1.0666439533233643,\n",
       "               0.8638519048690796,\n",
       "               0.9698180556297302,\n",
       "               0.8304079174995422,\n",
       "               1.0151026248931885,\n",
       "               0.7632699608802795,\n",
       "               0.7725380063056946,\n",
       "               0.823596715927124,\n",
       "               1.0305453538894653,\n",
       "               0.961215615272522,\n",
       "               1.0094037055969238,\n",
       "               0.9026445150375366,\n",
       "               0.9393144845962524,\n",
       "               0.9096263647079468,\n",
       "               0.9128717184066772,\n",
       "               0.8905872106552124,\n",
       "               0.8715590834617615,\n",
       "               0.8346922993659973,\n",
       "               0.8232367038726807,\n",
       "               1.0020592212677002,\n",
       "               0.7851577997207642,\n",
       "               1.0429195165634155,\n",
       "               0.8579678535461426,\n",
       "               0.8607892990112305,\n",
       "               0.7864166498184204,\n",
       "               0.9639936089515686,\n",
       "               0.8273593783378601,\n",
       "               0.8975993990898132,\n",
       "               0.8457334637641907,\n",
       "               0.7720869779586792,\n",
       "               0.7791829705238342,\n",
       "               0.97919100522995,\n",
       "               0.8111171722412109,\n",
       "               0.850233256816864,\n",
       "               0.9066411256790161,\n",
       "               0.8014687895774841,\n",
       "               0.7210208773612976,\n",
       "               0.7810758352279663,\n",
       "               0.8097677826881409,\n",
       "               0.8342374563217163,\n",
       "               0.7387961745262146,\n",
       "               1.0835514068603516,\n",
       "               0.8333591222763062,\n",
       "               0.859050452709198,\n",
       "               0.839131772518158,\n",
       "               0.8230619430541992,\n",
       "               0.8661666512489319,\n",
       "               0.8103525638580322,\n",
       "               0.6362733840942383],\n",
       "              [0.6759464144706726,\n",
       "               0.7824349403381348,\n",
       "               0.8631677031517029,\n",
       "               0.7189093232154846,\n",
       "               0.6442669630050659,\n",
       "               0.8590327501296997,\n",
       "               0.9246599078178406,\n",
       "               0.8031454086303711,\n",
       "               0.7369964718818665,\n",
       "               0.7050670385360718,\n",
       "               0.7209824919700623,\n",
       "               0.7847338914871216,\n",
       "               0.663662850856781,\n",
       "               0.6963926553726196,\n",
       "               0.8946149349212646,\n",
       "               0.820364236831665,\n",
       "               0.852239191532135,\n",
       "               0.6528233885765076,\n",
       "               0.836530327796936,\n",
       "               0.7865915894508362,\n",
       "               0.7761871814727783,\n",
       "               0.8564672470092773,\n",
       "               0.8546246290206909,\n",
       "               0.6654051542282104,\n",
       "               0.7812665104866028,\n",
       "               0.9337905645370483,\n",
       "               0.9438508749008179,\n",
       "               0.9071822762489319,\n",
       "               0.7030673027038574,\n",
       "               0.7340008020401001,\n",
       "               0.7172067165374756,\n",
       "               0.9380401372909546,\n",
       "               0.8305754661560059,\n",
       "               0.6922327280044556,\n",
       "               0.801409900188446,\n",
       "               0.6555331945419312,\n",
       "               0.7496213912963867,\n",
       "               0.9100979566574097,\n",
       "               0.8860102891921997,\n",
       "               0.8358089327812195,\n",
       "               0.9979422688484192,\n",
       "               0.8645787239074707,\n",
       "               0.6825119256973267,\n",
       "               0.7284917235374451,\n",
       "               0.887703001499176,\n",
       "               0.7342885732650757,\n",
       "               0.7383288145065308,\n",
       "               0.939142644405365,\n",
       "               0.7820769548416138,\n",
       "               0.8473572731018066,\n",
       "               0.8366594910621643,\n",
       "               0.8185295462608337,\n",
       "               0.809191882610321,\n",
       "               0.672592282295227,\n",
       "               0.5720326900482178],\n",
       "              [0.6855443716049194,\n",
       "               0.7128669619560242,\n",
       "               0.8976064920425415,\n",
       "               0.6853312253952026,\n",
       "               0.584230899810791,\n",
       "               0.7773305177688599,\n",
       "               0.8682492971420288,\n",
       "               0.7728700041770935,\n",
       "               0.5856456160545349,\n",
       "               0.5513714551925659,\n",
       "               0.6126949191093445,\n",
       "               0.6084073185920715,\n",
       "               0.5226930379867554,\n",
       "               0.6117678880691528,\n",
       "               0.705938458442688,\n",
       "               0.7590624094009399,\n",
       "               0.6662628054618835,\n",
       "               0.5509872436523438,\n",
       "               0.8937690258026123,\n",
       "               0.6314040422439575,\n",
       "               0.8321818709373474,\n",
       "               0.6955500841140747,\n",
       "               0.7113634347915649,\n",
       "               0.7200614213943481,\n",
       "               0.6074178218841553,\n",
       "               0.6915756464004517,\n",
       "               0.9010444283485413,\n",
       "               0.8787959218025208,\n",
       "               0.5722854733467102,\n",
       "               0.7905086278915405,\n",
       "               0.6556617021560669,\n",
       "               0.6730992794036865,\n",
       "               0.6512123942375183,\n",
       "               0.6050662398338318,\n",
       "               0.6660220623016357,\n",
       "               0.5892474055290222,\n",
       "               0.6846609711647034,\n",
       "               0.6591977477073669,\n",
       "               0.8827932476997375,\n",
       "               0.6832358241081238,\n",
       "               0.9042750000953674,\n",
       "               0.6913413405418396,\n",
       "               0.6560734510421753,\n",
       "               0.5910778045654297,\n",
       "               0.8803123831748962,\n",
       "               0.6568114757537842,\n",
       "               0.6004994511604309,\n",
       "               0.9173551797866821,\n",
       "               0.829123854637146,\n",
       "               0.8494704365730286,\n",
       "               0.7892515063285828,\n",
       "               0.7737802863121033,\n",
       "               0.7372288107872009,\n",
       "               0.7994499802589417,\n",
       "               0.5030242800712585],\n",
       "              [0.6482478976249695,\n",
       "               0.592610776424408,\n",
       "               0.7460640668869019,\n",
       "               0.6488681435585022,\n",
       "               0.5995940566062927,\n",
       "               0.7660024166107178,\n",
       "               0.8559256196022034,\n",
       "               0.7393778562545776,\n",
       "               0.4741440415382385,\n",
       "               0.6389114856719971,\n",
       "               0.5367749333381653,\n",
       "               0.5777496099472046,\n",
       "               0.6907809972763062,\n",
       "               0.5770624876022339,\n",
       "               0.5422831773757935,\n",
       "               1.010433316230774,\n",
       "               0.6875697374343872,\n",
       "               0.4960990846157074,\n",
       "               0.5966124534606934,\n",
       "               0.7553163766860962,\n",
       "               0.7736428380012512,\n",
       "               0.5432210564613342,\n",
       "               0.6543851494789124,\n",
       "               0.4138171374797821,\n",
       "               0.721699059009552,\n",
       "               0.9318223595619202,\n",
       "               0.6900663375854492,\n",
       "               0.7245877981185913,\n",
       "               0.6891360282897949,\n",
       "               0.8791651725769043,\n",
       "               0.81357741355896,\n",
       "               0.7680066823959351,\n",
       "               0.6925291419029236,\n",
       "               0.6089329123497009,\n",
       "               0.6631080508232117,\n",
       "               0.645980954170227,\n",
       "               0.7802930474281311,\n",
       "               0.8176035284996033,\n",
       "               1.0204306840896606,\n",
       "               0.8390507698059082,\n",
       "               0.7442987561225891,\n",
       "               0.794378936290741,\n",
       "               0.6660814881324768,\n",
       "               0.6398328542709351,\n",
       "               0.6242581009864807,\n",
       "               0.7006215453147888,\n",
       "               0.6521486043930054,\n",
       "               0.9459975361824036,\n",
       "               0.7601591348648071,\n",
       "               0.6213755011558533,\n",
       "               0.7414714097976685,\n",
       "               0.8378044366836548,\n",
       "               0.8753241896629333,\n",
       "               0.72230464220047,\n",
       "               0.5993025302886963],\n",
       "              [0.6483116149902344,\n",
       "               0.6084384918212891,\n",
       "               0.7799537777900696,\n",
       "               0.7110084891319275,\n",
       "               0.5698124766349792,\n",
       "               0.8473716974258423,\n",
       "               0.8570175766944885,\n",
       "               0.6320642232894897,\n",
       "               0.4378482401371002,\n",
       "               0.5546854138374329,\n",
       "               0.6471519470214844,\n",
       "               0.551949143409729,\n",
       "               0.4335765838623047,\n",
       "               0.5196681022644043,\n",
       "               0.8146404027938843,\n",
       "               0.6197240352630615,\n",
       "               0.5064210295677185,\n",
       "               0.6678432822227478,\n",
       "               0.5548268556594849,\n",
       "               0.6014224290847778,\n",
       "               0.5291764736175537,\n",
       "               0.5878661274909973,\n",
       "               0.5861417651176453,\n",
       "               0.467865526676178,\n",
       "               0.5725217461585999,\n",
       "               0.5695609450340271,\n",
       "               0.3821733593940735,\n",
       "               0.7117238640785217,\n",
       "               0.654445469379425,\n",
       "               0.49227404594421387,\n",
       "               0.38362404704093933,\n",
       "               0.5760468244552612,\n",
       "               0.41845813393592834,\n",
       "               0.5903365015983582,\n",
       "               0.5797823667526245,\n",
       "               0.7221875190734863,\n",
       "               0.8310385346412659,\n",
       "               0.7528907060623169,\n",
       "               0.6602427363395691,\n",
       "               0.6154675483703613,\n",
       "               0.6096631288528442,\n",
       "               0.6321926116943359,\n",
       "               0.8486829996109009,\n",
       "               0.8276978731155396,\n",
       "               0.5884832739830017,\n",
       "               0.8293493986129761,\n",
       "               0.6777382493019104,\n",
       "               0.9409949779510498,\n",
       "               0.773445188999176,\n",
       "               0.6258702874183655,\n",
       "               0.7784779071807861,\n",
       "               0.8083104491233826,\n",
       "               0.8809951543807983,\n",
       "               0.7070351243019104,\n",
       "               0.5754925608634949],\n",
       "              [0.5652120113372803,\n",
       "               0.6973118185997009,\n",
       "               0.786470353603363,\n",
       "               0.7868514657020569,\n",
       "               0.5630360841751099,\n",
       "               0.8906946778297424,\n",
       "               0.8995971083641052,\n",
       "               0.5483059287071228,\n",
       "               0.5453867316246033,\n",
       "               0.5525824427604675,\n",
       "               0.5613122582435608,\n",
       "               0.505875289440155,\n",
       "               0.5141893625259399,\n",
       "               0.5792809128761292,\n",
       "               0.4978982210159302,\n",
       "               0.6255351901054382,\n",
       "               0.7375282049179077,\n",
       "               0.3907507359981537,\n",
       "               0.48105594515800476,\n",
       "               0.5063310265541077,\n",
       "               0.5644111037254333,\n",
       "               0.6363219618797302,\n",
       "               0.5053645968437195,\n",
       "               0.322642982006073,\n",
       "               0.5696089863777161,\n",
       "               0.9076314568519592,\n",
       "               0.6165255904197693,\n",
       "               0.7835583090782166,\n",
       "               0.5160925984382629,\n",
       "               0.788457453250885,\n",
       "               0.6809481382369995,\n",
       "               0.6316063404083252,\n",
       "               0.7459194660186768,\n",
       "               0.6881831288337708,\n",
       "               0.47181639075279236,\n",
       "               0.6329530477523804,\n",
       "               0.7648895978927612,\n",
       "               0.6071249842643738,\n",
       "               0.7233691215515137,\n",
       "               0.8729696273803711,\n",
       "               0.8176992535591125,\n",
       "               0.6138100028038025,\n",
       "               0.666839063167572,\n",
       "               0.7596921920776367,\n",
       "               0.8573240637779236,\n",
       "               0.6697544455528259,\n",
       "               0.7349165678024292,\n",
       "               0.8593785166740417,\n",
       "               0.9768635630607605,\n",
       "               0.7906283736228943,\n",
       "               0.9369244575500488,\n",
       "               0.9172245264053345,\n",
       "               0.7835924029350281,\n",
       "               0.7912213802337646,\n",
       "               0.5853924751281738],\n",
       "              [0.6676044464111328,\n",
       "               0.6621960997581482,\n",
       "               0.819678783416748,\n",
       "               0.7331016063690186,\n",
       "               0.661774218082428,\n",
       "               0.800006628036499,\n",
       "               0.8035508394241333,\n",
       "               0.5228155255317688,\n",
       "               0.5298210382461548,\n",
       "               0.6290004253387451,\n",
       "               0.7784053087234497,\n",
       "               0.5824660062789917,\n",
       "               0.6576581001281738,\n",
       "               0.6144533753395081,\n",
       "               0.6791427135467529,\n",
       "               0.7750623822212219,\n",
       "               0.5940138101577759,\n",
       "               0.49008020758628845,\n",
       "               0.4745543599128723,\n",
       "               0.6222254037857056,\n",
       "               0.7459990978240967,\n",
       "               0.36250630021095276,\n",
       "               0.6607850193977356,\n",
       "               0.3278682827949524,\n",
       "               0.3307008147239685,\n",
       "               0.4068737328052521,\n",
       "               0.3879619538784027,\n",
       "               0.7481496334075928,\n",
       "               0.5686101913452148,\n",
       "               0.5452911853790283,\n",
       "               0.4279042184352875,\n",
       "               0.8658121228218079,\n",
       "               0.6748358011245728,\n",
       "               0.4997189939022064,\n",
       "               0.710481584072113,\n",
       "               0.5703481435775757,\n",
       "               0.77702397108078,\n",
       "               0.5844253301620483,\n",
       "               0.6479853987693787,\n",
       "               0.642829418182373,\n",
       "               0.680863618850708,\n",
       "               0.5845242142677307,\n",
       "               0.5874779224395752,\n",
       "               0.6615837812423706,\n",
       "               0.6430050730705261,\n",
       "               0.6775283813476562,\n",
       "               0.6064882874488831,\n",
       "               0.836441159248352,\n",
       "               0.6525605916976929,\n",
       "               0.5970150232315063,\n",
       "               0.8340794444084167,\n",
       "               0.8541749119758606,\n",
       "               0.8060666918754578,\n",
       "               0.7291995882987976,\n",
       "               0.644845724105835],\n",
       "              [0.5918199419975281,\n",
       "               0.5776567459106445,\n",
       "               0.8326717615127563,\n",
       "               0.7947878241539001,\n",
       "               0.5730801224708557,\n",
       "               0.7966952323913574,\n",
       "               0.7165034413337708,\n",
       "               0.46263888478279114,\n",
       "               0.47502562403678894,\n",
       "               0.44377434253692627,\n",
       "               0.5248836278915405,\n",
       "               0.5149017572402954,\n",
       "               0.46498903632164,\n",
       "               0.46458378434181213,\n",
       "               0.6216977834701538,\n",
       "               0.6684573292732239,\n",
       "               0.5930907130241394,\n",
       "               0.33530673384666443,\n",
       "               0.4415944218635559,\n",
       "               0.652272641658783,\n",
       "               0.508940577507019,\n",
       "               0.32777008414268494,\n",
       "               0.3489726781845093,\n",
       "               0.24852599203586578,\n",
       "               0.4711429178714752,\n",
       "               0.5019739270210266,\n",
       "               0.6011518836021423,\n",
       "               0.4637228548526764,\n",
       "               0.2729916274547577,\n",
       "               0.656164824962616,\n",
       "               0.7041260600090027,\n",
       "               0.2726287543773651,\n",
       "               0.5218666195869446,\n",
       "               0.7949367761611938,\n",
       "               0.6689347624778748,\n",
       "               0.42618507146835327,\n",
       "               0.6523116230964661,\n",
       "               0.5348412394523621,\n",
       "               0.579824686050415,\n",
       "               0.7648335695266724,\n",
       "               0.7025958895683289,\n",
       "               0.5132438540458679,\n",
       "               0.5368205904960632,\n",
       "               0.5132772326469421,\n",
       "               0.647903561592102,\n",
       "               0.601320743560791,\n",
       "               0.6629379391670227,\n",
       "               0.7824189066886902,\n",
       "               0.599869966506958,\n",
       "               0.5286781787872314,\n",
       "               0.6717506051063538,\n",
       "               0.9488418102264404,\n",
       "               0.9759066104888916,\n",
       "               0.8404926657676697,\n",
       "               0.5685549974441528],\n",
       "              [0.467408686876297,\n",
       "               0.6173487305641174,\n",
       "               1.0137306451797485,\n",
       "               0.7163236737251282,\n",
       "               0.5005465149879456,\n",
       "               0.9372801780700684,\n",
       "               0.6129018068313599,\n",
       "               0.5796312093734741,\n",
       "               0.8226264119148254,\n",
       "               0.7058936953544617,\n",
       "               0.640640377998352,\n",
       "               0.5486882925033569,\n",
       "               0.5337282419204712,\n",
       "               0.5167999267578125,\n",
       "               0.5500413775444031,\n",
       "               0.5725072622299194,\n",
       "               0.7416426539421082,\n",
       "               0.3220643401145935,\n",
       "               0.4031466245651245,\n",
       "               0.5789340734481812,\n",
       "               0.3400571346282959,\n",
       "               0.6047139763832092,\n",
       "               0.36051422357559204,\n",
       "               0.2908482253551483,\n",
       "               0.4489278495311737,\n",
       "               0.4052278697490692,\n",
       "               0.6001996397972107,\n",
       "               0.6622398495674133,\n",
       "               0.29556918144226074,\n",
       "               0.5670989155769348,\n",
       "               0.4329494833946228,\n",
       "               0.3575017750263214,\n",
       "               0.42605260014533997,\n",
       "               0.5940811038017273,\n",
       "               0.5329473614692688,\n",
       "               0.5178471207618713,\n",
       "               0.5452938079833984,\n",
       "               0.9910813570022583,\n",
       "               0.9838029146194458,\n",
       "               0.7406111359596252,\n",
       "               0.7107413411140442,\n",
       "               0.8730437159538269,\n",
       "               0.7458539009094238,\n",
       "               0.720630943775177,\n",
       "               0.7007799744606018,\n",
       "               0.6410742402076721,\n",
       "               0.7263981103897095,\n",
       "               1.0572254657745361,\n",
       "               0.7811414003372192,\n",
       "               0.6564366817474365,\n",
       "               0.6226087808609009,\n",
       "               0.6754087209701538,\n",
       "               0.8235552906990051,\n",
       "               0.6943995952606201,\n",
       "               0.8256602883338928],\n",
       "              [0.6796177625656128,\n",
       "               0.6461811065673828,\n",
       "               0.6156333684921265,\n",
       "               0.5359792709350586,\n",
       "               0.6768518686294556,\n",
       "               0.8964114189147949,\n",
       "               0.6648130416870117,\n",
       "               0.6172875165939331,\n",
       "               0.6135056018829346,\n",
       "               0.49637261033058167,\n",
       "               0.8497526049613953,\n",
       "               0.6861606240272522,\n",
       "               1.0061827898025513,\n",
       "               0.8241004943847656,\n",
       "               0.5821086168289185,\n",
       "               0.7014778256416321,\n",
       "               0.6900753378868103,\n",
       "               0.4389358162879944,\n",
       "               0.43384331464767456,\n",
       "               0.593647301197052,\n",
       "               0.4707043468952179,\n",
       "               0.5194233655929565,\n",
       "               0.5786941647529602,\n",
       "               0.5434592962265015,\n",
       "               0.48640087246894836,\n",
       "               0.5735897421836853,\n",
       "               0.5669306516647339,\n",
       "               0.6461569666862488,\n",
       "               0.4353399872779846,\n",
       "               0.4646514058113098,\n",
       "               0.726061999797821,\n",
       "               0.4265647828578949,\n",
       "               0.47382980585098267,\n",
       "               0.6078147292137146,\n",
       "               0.533096432685852,\n",
       "               0.5307935476303101,\n",
       "               0.5975117087364197,\n",
       "               0.3940317630767822,\n",
       "               0.6488251090049744,\n",
       "               0.6686595678329468,\n",
       "               0.6073470115661621,\n",
       "               0.8368949890136719,\n",
       "               0.5278183817863464,\n",
       "               0.6282638311386108,\n",
       "               0.6783931851387024,\n",
       "               0.8856973648071289,\n",
       "               0.8516731858253479,\n",
       "               0.8825979232788086,\n",
       "               0.628506600856781,\n",
       "               0.5106099843978882,\n",
       "               0.6600645184516907,\n",
       "               0.6309759616851807,\n",
       "               0.7692164182662964,\n",
       "               0.6858040690422058,\n",
       "               0.5827338695526123],\n",
       "              [0.5486584305763245,\n",
       "               0.6071308851242065,\n",
       "               0.7214947938919067,\n",
       "               0.576034426689148,\n",
       "               0.4460684359073639,\n",
       "               0.6400607824325562,\n",
       "               0.5393915772438049,\n",
       "               0.414119154214859,\n",
       "               0.5286339521408081,\n",
       "               0.42687639594078064,\n",
       "               0.625965416431427,\n",
       "               0.5174186825752258,\n",
       "               0.5706759691238403,\n",
       "               0.5644425749778748,\n",
       "               0.5258340239524841,\n",
       "               0.44079506397247314,\n",
       "               0.6034016609191895,\n",
       "               0.40550968050956726,\n",
       "               0.4292111396789551,\n",
       "               0.5990536212921143,\n",
       "               0.23008668422698975,\n",
       "               0.41234591603279114,\n",
       "               0.37936294078826904,\n",
       "               0.3379785418510437,\n",
       "               0.27951905131340027,\n",
       "               0.4151827096939087,\n",
       "               0.48251640796661377,\n",
       "               0.45969852805137634,\n",
       "               0.3370656669139862,\n",
       "               0.27274781465530396,\n",
       "               0.1542985439300537,\n",
       "               0.2653217017650604,\n",
       "               0.4683968126773834,\n",
       "               0.64107745885849,\n",
       "               0.38740718364715576,\n",
       "               0.33505362272262573,\n",
       "               0.3745834231376648,\n",
       "               0.44729435443878174,\n",
       "               0.5098040699958801,\n",
       "               0.36955541372299194,\n",
       "               0.5211166143417358,\n",
       "               0.5292356014251709,\n",
       "               0.5513138771057129,\n",
       "               0.5802345871925354,\n",
       "               0.5393517017364502,\n",
       "               0.41072380542755127,\n",
       "               0.4750731587409973,\n",
       "               0.9066668152809143,\n",
       "               0.5395769476890564,\n",
       "               0.5143371224403381,\n",
       "               0.6421769261360168,\n",
       "               0.5434159636497498,\n",
       "               0.6542941331863403,\n",
       "               0.645819365978241,\n",
       "               0.46263569593429565],\n",
       "              [0.41869911551475525,\n",
       "               0.4357721209526062,\n",
       "               0.6807234287261963,\n",
       "               0.4869941473007202,\n",
       "               0.44778433442115784,\n",
       "               0.7131434679031372,\n",
       "               0.5994990468025208,\n",
       "               0.5362847447395325,\n",
       "               0.3594086766242981,\n",
       "               0.4125090539455414,\n",
       "               0.6502734422683716,\n",
       "               0.4117031693458557,\n",
       "               0.4259016811847687,\n",
       "               0.4356125593185425,\n",
       "               0.45906010270118713,\n",
       "               0.3713368773460388,\n",
       "               0.6685887575149536,\n",
       "               0.4073264002799988,\n",
       "               0.5637600421905518,\n",
       "               0.3061542212963104,\n",
       "               0.2566753029823303,\n",
       "               0.3211614489555359,\n",
       "               0.4070216417312622,\n",
       "               0.2654094398021698,\n",
       "               0.22093823552131653,\n",
       "               0.26686257123947144,\n",
       "               0.3931863009929657,\n",
       "               0.33098888397216797,\n",
       "               0.40258389711380005,\n",
       "               0.4089324474334717,\n",
       "               0.5111602544784546,\n",
       "               0.4980465769767761,\n",
       "               0.45557907223701477,\n",
       "               0.5870322585105896,\n",
       "               0.19633576273918152,\n",
       "               0.5806040167808533,\n",
       "               0.5026737451553345,\n",
       "               0.46654409170150757,\n",
       "               0.47131040692329407,\n",
       "               0.5115015506744385,\n",
       "               0.5270053148269653,\n",
       "               0.459903746843338,\n",
       "               0.4467763304710388,\n",
       "               0.4486722946166992,\n",
       "               0.5471395254135132,\n",
       "               0.38273265957832336,\n",
       "               0.454214483499527,\n",
       "               0.9288234710693359,\n",
       "               0.6742656230926514,\n",
       "               0.5199633836746216,\n",
       "               0.5310184359550476,\n",
       "               0.5891869068145752,\n",
       "               0.6727259755134583,\n",
       "               0.5737189054489136,\n",
       "               0.4319433867931366],\n",
       "              [0.4337380826473236,\n",
       "               0.45747166872024536,\n",
       "               0.5167485475540161,\n",
       "               0.5171600580215454,\n",
       "               0.3195384740829468,\n",
       "               0.5844204425811768,\n",
       "               0.4128304123878479,\n",
       "               0.45159485936164856,\n",
       "               0.35090821981430054,\n",
       "               0.35945576429367065,\n",
       "               0.5022481679916382,\n",
       "               0.7979868650436401,\n",
       "               0.5852468609809875,\n",
       "               0.43889737129211426,\n",
       "               0.5092918872833252,\n",
       "               0.4575819671154022,\n",
       "               0.49191799759864807,\n",
       "               0.424447238445282,\n",
       "               0.47722455859184265,\n",
       "               0.3858336806297302,\n",
       "               0.400199830532074,\n",
       "               0.44150251150131226,\n",
       "               0.5106483101844788,\n",
       "               0.3252662420272827,\n",
       "               0.2976897656917572,\n",
       "               0.3998866081237793,\n",
       "               0.4356314241886139,\n",
       "               0.40049535036087036,\n",
       "               0.30962783098220825,\n",
       "               0.3781087398529053,\n",
       "               0.48800215125083923,\n",
       "               0.49481528997421265,\n",
       "               0.38006895780563354,\n",
       "               0.5332010388374329,\n",
       "               0.46876493096351624,\n",
       "               0.2233455330133438,\n",
       "               0.4405392110347748,\n",
       "               0.4103068709373474,\n",
       "               0.5694267749786377,\n",
       "               0.45953625440597534,\n",
       "               0.48032307624816895,\n",
       "               0.49639207124710083,\n",
       "               0.377805233001709,\n",
       "               0.33251455426216125,\n",
       "               0.41352757811546326,\n",
       "               0.41367965936660767,\n",
       "               0.48835963010787964,\n",
       "               0.8635131120681763,\n",
       "               0.5879499316215515,\n",
       "               0.5731459259986877,\n",
       "               0.5378693342208862,\n",
       "               0.5047740340232849,\n",
       "               0.5379000902175903,\n",
       "               0.4268624186515808,\n",
       "               0.38510194420814514],\n",
       "              [0.6478038430213928,\n",
       "               0.4287763237953186,\n",
       "               0.6362212300300598,\n",
       "               0.41015124320983887,\n",
       "               0.3737034201622009,\n",
       "               0.5453108549118042,\n",
       "               0.40066444873809814,\n",
       "               0.4259546399116516,\n",
       "               0.3124024271965027,\n",
       "               0.3839344084262848,\n",
       "               0.4502003490924835,\n",
       "               0.4192124307155609,\n",
       "               0.4719299376010895,\n",
       "               0.5463729500770569,\n",
       "               0.6176856756210327,\n",
       "               0.5232386589050293,\n",
       "               0.4912356436252594,\n",
       "               0.4640980660915375,\n",
       "               0.43072229623794556,\n",
       "               0.5544460415840149,\n",
       "               0.5133331418037415,\n",
       "               0.34488940238952637,\n",
       "               0.3211924433708191,\n",
       "               0.15122872591018677,\n",
       "               0.4235384166240692,\n",
       "               0.4021962285041809,\n",
       "               0.3107350766658783,\n",
       "               0.5852002501487732,\n",
       "               0.3038913905620575,\n",
       "               0.4354102313518524,\n",
       "               0.1884920597076416,\n",
       "               0.32150015234947205,\n",
       "               0.440499871969223,\n",
       "               0.5386996865272522,\n",
       "               0.3176000714302063,\n",
       "               0.493849515914917,\n",
       "               0.3316897749900818,\n",
       "               0.34721502661705017,\n",
       "               0.3028690814971924,\n",
       "               0.47256267070770264,\n",
       "               0.5379710793495178,\n",
       "               0.5596261024475098,\n",
       "               0.40017423033714294,\n",
       "               0.39433175325393677,\n",
       "               0.5221757292747498,\n",
       "               0.4428738057613373,\n",
       "               0.39849868416786194,\n",
       "               0.7866213917732239,\n",
       "               0.6035215854644775,\n",
       "               0.5661524534225464,\n",
       "               0.5709179043769836,\n",
       "               0.6711751222610474,\n",
       "               0.66163170337677,\n",
       "               0.6074121594429016,\n",
       "               0.4459497928619385],\n",
       "              [0.4324549734592438,\n",
       "               0.5176550149917603,\n",
       "               0.7207739353179932,\n",
       "               0.5760132074356079,\n",
       "               0.47562772035598755,\n",
       "               0.6596766710281372,\n",
       "               0.7083762884140015,\n",
       "               0.7151902914047241,\n",
       "               0.32646358013153076,\n",
       "               0.47378894686698914,\n",
       "               0.8481947183609009,\n",
       "               0.5756393074989319,\n",
       "               0.6574808955192566,\n",
       "               0.4086959660053253,\n",
       "               0.5697007775306702,\n",
       "               0.5195026993751526,\n",
       "               0.6030545234680176,\n",
       "               0.7934009432792664,\n",
       "               0.5517206788063049,\n",
       "               0.5594874024391174,\n",
       "               0.6209065914154053,\n",
       "               0.4540148079395294,\n",
       "               0.540215015411377,\n",
       "               0.43943071365356445,\n",
       "               0.5026638507843018,\n",
       "               0.3548118770122528,\n",
       "               0.3755013942718506,\n",
       "               0.5336265563964844,\n",
       "               0.3029175400733948,\n",
       "               0.5254713296890259,\n",
       "               0.3729718029499054,\n",
       "               0.5045985579490662,\n",
       "               0.33947283029556274,\n",
       "               0.6096330881118774,\n",
       "               0.3876166045665741,\n",
       "               0.5766364932060242,\n",
       "               0.468977689743042,\n",
       "               0.5475451350212097,\n",
       "               0.5907312035560608,\n",
       "               0.376981258392334,\n",
       "               0.6373035907745361,\n",
       "               0.48578381538391113,\n",
       "               0.4389873147010803,\n",
       "               0.38257521390914917,\n",
       "               0.4771402180194855,\n",
       "               0.3257337212562561,\n",
       "               0.5204737186431885,\n",
       "               0.527778148651123,\n",
       "               0.40064913034439087,\n",
       "               0.5376015305519104,\n",
       "               0.6325002908706665,\n",
       "               0.44478604197502136,\n",
       "               0.5112494826316833,\n",
       "               0.5808730125427246,\n",
       "               0.33758828043937683],\n",
       "              [0.4576326012611389,\n",
       "               0.3606436550617218,\n",
       "               0.6389982104301453,\n",
       "               0.5128952860832214,\n",
       "               0.40186306834220886,\n",
       "               0.5713269114494324,\n",
       "               0.5354061722755432,\n",
       "               0.3639407455921173,\n",
       "               0.32095420360565186,\n",
       "               0.23989814519882202,\n",
       "               0.4074231684207916,\n",
       "               0.3415326178073883,\n",
       "               0.37127724289894104,\n",
       "               0.30722618103027344,\n",
       "               0.6706900596618652,\n",
       "               0.3836638033390045,\n",
       "               0.36547452211380005,\n",
       "               0.6181990504264832,\n",
       "               0.4246314764022827,\n",
       "               0.4172551929950714,\n",
       "               0.44464507699012756,\n",
       "               0.4636378884315491,\n",
       "               0.4544130861759186,\n",
       "               0.40338608622550964,\n",
       "               0.4239128530025482,\n",
       "               0.2917800843715668,\n",
       "               0.3254282474517822,\n",
       "               0.6820035576820374,\n",
       "               0.8803519010543823,\n",
       "               0.4147101938724518,\n",
       "               0.33524030447006226,\n",
       "               0.39576372504234314,\n",
       "               0.5120072960853577,\n",
       "               0.9405268430709839,\n",
       "               0.5396338105201721,\n",
       "               0.2340245097875595,\n",
       "               0.31192541122436523,\n",
       "               0.45710277557373047,\n",
       "               0.5282129049301147,\n",
       "               0.2604224681854248,\n",
       "               0.3869692087173462,\n",
       "               0.30583319067955017,\n",
       "               0.2942196726799011,\n",
       "               0.28325632214546204,\n",
       "               0.2940354645252228,\n",
       "               0.2798656225204468,\n",
       "               0.4805557131767273,\n",
       "               0.7125517129898071,\n",
       "               0.6048000454902649,\n",
       "               0.6580086350440979,\n",
       "               0.584926962852478,\n",
       "               0.36362189054489136,\n",
       "               0.5704744458198547,\n",
       "               0.46545037627220154,\n",
       "               0.34597542881965637],\n",
       "              [0.29667040705680847,\n",
       "               0.41358184814453125,\n",
       "               0.6468504667282104,\n",
       "               0.511448860168457,\n",
       "               0.4791368246078491,\n",
       "               0.6629953980445862,\n",
       "               0.43243783712387085,\n",
       "               0.37897640466690063,\n",
       "               0.41195517778396606,\n",
       "               0.34354862570762634,\n",
       "               0.35277190804481506,\n",
       "               0.38463300466537476,\n",
       "               0.3722950518131256,\n",
       "               0.2499799281358719,\n",
       "               0.29207751154899597,\n",
       "               0.3707573711872101,\n",
       "               0.48385748267173767,\n",
       "               0.38906827569007874,\n",
       "               0.2948356568813324,\n",
       "               0.3604203462600708,\n",
       "               0.5321734547615051,\n",
       "               0.40505674481391907,\n",
       "               0.33428725600242615,\n",
       "               0.612410306930542,\n",
       "               0.4270780086517334,\n",
       "               0.8593467473983765,\n",
       "               0.6862249970436096,\n",
       "               0.6150676012039185,\n",
       "               0.4960431754589081,\n",
       "               0.6660017967224121,\n",
       "               0.49142366647720337,\n",
       "               0.7087036371231079,\n",
       "               0.43852704763412476,\n",
       "               0.7962151169776917,\n",
       "               0.41021794080734253,\n",
       "               0.4589729607105255,\n",
       "               0.5003811717033386,\n",
       "               0.7069593071937561,\n",
       "               0.4574253261089325,\n",
       "               0.45480746030807495,\n",
       "               0.499480277299881,\n",
       "               0.34753358364105225,\n",
       "               0.374798059463501,\n",
       "               0.4224547743797302,\n",
       "               0.7019073367118835,\n",
       "               0.32521161437034607,\n",
       "               0.3609480559825897,\n",
       "               0.7878351211547852,\n",
       "               0.5393752455711365,\n",
       "               0.44878923892974854,\n",
       "               0.44490739703178406,\n",
       "               0.6693739295005798,\n",
       "               0.7677199244499207,\n",
       "               0.6024848818778992,\n",
       "               0.3379085958003998],\n",
       "              [0.30647602677345276,\n",
       "               0.42792463302612305,\n",
       "               0.4973435699939728,\n",
       "               0.5510226488113403,\n",
       "               0.5662711262702942,\n",
       "               0.5235174298286438,\n",
       "               0.4231846034526825,\n",
       "               0.4668979346752167,\n",
       "               0.6458751559257507,\n",
       "               0.2517169713973999,\n",
       "               0.3463006317615509,\n",
       "               0.32619789242744446,\n",
       "               0.4411986172199249,\n",
       "               0.31035593152046204,\n",
       "               0.26618507504463196,\n",
       "               0.45446330308914185,\n",
       "               0.34679797291755676,\n",
       "               0.567851185798645,\n",
       "               0.37187662720680237,\n",
       "               0.38605448603630066,\n",
       "               0.674853503704071,\n",
       "               0.4073488414287567,\n",
       "               0.4850641191005707,\n",
       "               0.3852272927761078,\n",
       "               0.20438553392887115,\n",
       "               0.5088810324668884,\n",
       "               0.6012006402015686,\n",
       "               0.614393413066864,\n",
       "               0.44051602482795715,\n",
       "               0.48694807291030884,\n",
       "               0.4321828782558441,\n",
       "               0.34160736203193665,\n",
       "               0.2537565231323242,\n",
       "               0.5472174882888794,\n",
       "               0.3077835738658905,\n",
       "               0.47170597314834595,\n",
       "               0.30897435545921326,\n",
       "               0.4218677282333374,\n",
       "               0.5387434363365173,\n",
       "               0.5232027173042297,\n",
       "               0.49743154644966125,\n",
       "               0.38007599115371704,\n",
       "               0.41611480712890625,\n",
       "               0.7702035903930664,\n",
       "               0.6686545610427856,\n",
       "               0.5667195916175842,\n",
       "               0.5760089755058289,\n",
       "               0.7294782400131226,\n",
       "               0.7607365846633911,\n",
       "               0.62087482213974,\n",
       "               0.5554378628730774,\n",
       "               0.6553452610969543,\n",
       "               0.5470000505447388,\n",
       "               0.5824813842773438,\n",
       "               0.3410121500492096]],\n",
       "             'time': [3.7005434036254883,\n",
       "              6.183642864227295,\n",
       "              8.660142183303833,\n",
       "              11.163712978363037,\n",
       "              13.641098737716675,\n",
       "              16.09905433654785,\n",
       "              18.574732542037964,\n",
       "              21.02755308151245,\n",
       "              23.452425956726074,\n",
       "              25.89091658592224,\n",
       "              28.373623847961426,\n",
       "              30.812074899673462,\n",
       "              33.2527220249176,\n",
       "              35.71831965446472,\n",
       "              38.19864821434021,\n",
       "              40.675763845443726,\n",
       "              43.10738730430603,\n",
       "              45.53842043876648,\n",
       "              48.00276231765747,\n",
       "              50.4274377822876]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_trainer.train(EPOCHS=20, checkpoint_dir='checkpoints/original_classifier.pt')  # Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_length, dim, num_heads, num_layers, d_ff, dropout):\n",
    "        super(Generator, self).__init__()\n",
    "        self.transformer = Transformer(vocab_size, vocab_size, dim, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "        self.fc = nn.Linear(dim, vocab_size)\n",
    "        \n",
    "    def forward(self, src, tgt):\n",
    "        output = self.transformer(src, tgt)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_heads, dense_dim, num_classes,sequence_length):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.transformer = TransformerEncoderModel(vocab_size, embed_dim, num_heads, dense_dim, num_classes, sequence_length)\n",
    "        self.fc = nn.Linear(vocab_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        output = self.transformer(src, tgt)\n",
    "        output = self.sigmoid(self.fc(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "\n",
    "netG = Generator(vocab_size, max_seq_len, dim = 512, num_heads = 8, num_layers = 6, d_ff = 256, dropout = 0.2).to(device)\n",
    "# Create the Discriminator\n",
    "num_heads = 8\n",
    "dense_dim = 1024\n",
    "embed_dim = 512\n",
    "netD = Discriminator(vocab_size, embed_dim, num_heads, dense_dim, num_classes=1, sequence_length=max_seq_len).to(device)\n",
    "\n",
    "# Initialize the ``BCELoss`` function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "nz = 100\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 53,  60,  83,  ...,  46,  53,  60],\n",
       "        [ 50,  62,  10,  ...,  69,  26,  42],\n",
       "        [128,  58,  16,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [ 49,  65,  74,  ...,   0,   0,   0],\n",
       "        [ 19,  59,  53,  ..., 162, 102,  69],\n",
       "        [ 62, 110,  74,  ...,  52,  43,  73]], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((b_size,), real_label, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Forward pass real batch through D\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mnetD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_cpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Calculate loss on all-real batch\u001b[39;00m\n\u001b[1;32m     29\u001b[0m errD_real \u001b[38;5;241m=\u001b[39m criterion(output, label)\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[39], line 10\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, tgt):\n\u001b[0;32m---> 10\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output))\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "\n",
    "# Lists to keep track of progress\n",
    "txt_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        input = data['input']\n",
    "        target = data['target'].to(device)\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = input.to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu, target).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(train_dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            txt_list.append(fake)\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your model, dataloaders, loss function, device, learning rate, vocabulary size, etc. defined\n",
    "\n",
    "# Instantiate your ClassifierTrainer\n",
    "classifier_model = PatchClassifier()  # Replace with your actual classifier model\n",
    "train_dataloader = train_dataset  # Replace with your actual training dataloader\n",
    "valid_dataloader = test_dataset  # Replace with your actual validation dataloader\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()  # Replace with your actual loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available, else use CPU\n",
    "\n",
    "vocab_size = 10000  # Replace with your actual vocabulary size\n",
    "learning_rate = 0.001  # Replace with your actual learning rate\n",
    "\n",
    "# Instantiate the ClassifierTrainer\n",
    "classifier_trainer = ClassifierTrainer(\n",
    "    model=classifier_model,\n",
    "    dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    ce_loss=cross_entropy_loss,\n",
    "    device=device,\n",
    "    lr=learning_rate,\n",
    "    vocab_size=vocab_size,\n",
    "    warmup_steps=1000,  # Replace with your desired warmup steps\n",
    "    total_iters=30000,  # Replace with your desired total iterations\n",
    "    schedule='cosine_with_warmup'  # Replace with your desired learning rate schedule\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your MidiEncoder\n",
    "midi_encoder = MidiEncoder(steps_per_sec=100, num_vel_bins=32, min_pitch=21, max_pitch=108)\n",
    "\n",
    "# Define a list of MIDI files to encode\n",
    "\n",
    "midi_files_list = [os.path.join(path_to_midi, file) for file in os.listdir(path_to_midi) if file.endswith(\".midi\")]\n",
    "\n",
    "# Encode the MIDI files and save the encoded sequences to a pickle file\n",
    "encoded_sequences_path = \"/workspaces/Transformers_sentiment/data/pickle/encoded_sequences.pkl\"\n",
    "encoded_sequences = midi_encoder.encode_midi_list(midi_files_list, pkl_path=encoded_sequences_path)\n",
    "\n",
    "# Load the encoded sequences from the pickle file (optional)\n",
    "with open(encoded_sequences_path, 'rb') as handle:\n",
    "    loaded_encoded_sequences = pkl.load(handle)\n",
    "\n",
    "# Instantiate your MIDIEncoderREMI\n",
    "midi_encoder_remi = MIDIEncoderREMI(dict_path=\"midi_transcribed/src_001\", midi_files_list=midi_files_list)\n",
    "\n",
    "# Convert MIDI files to REMI words and save the dataset\n",
    "dataset_dir = \"data/train_data\"\n",
    "midi_encoder_remi.save_dataset(midi_files_list, dataset_dir)\n",
    "\n",
    "# Save the dataset as a single file\n",
    "single_file_dataset_path = \"data/npz_midi/single_file_dataset.npz\"\n",
    "midi_encoder_remi.save_dataset_as_single_file(glob.glob(os.path.join(dataset_dir, '*.npy')), single_file_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the single file (optional)\n",
    "loaded_dataset = np.load(single_file_dataset_path)\n",
    "loaded_sequences = loaded_dataset['sequences']\n",
    "loaded_ids = loaded_dataset['ids']\n",
    "\n",
    "# Convert REMI words back to MIDI and save\n",
    "output_midi_path = \"path/to/save/output_midi.mid\"\n",
    "midi_encoder_remi.words_to_midi(loaded_sequences[0], output_midi_path)\n",
    "\n",
    "# Calculate scores for a MIDI file using MidiEncoder\n",
    "midi_file_to_score = \"path/to/midi/file1.mid\"\n",
    "scores = midi_encoder.calculate_scores(midi_file_to_score)\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
