{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import muspy\n",
    "\n",
    "# emopia = muspy.EMOPIADataset(\"data/emopia/\", download_and_extract=True)\n",
    "# emopia.convert()\n",
    "# music = emopia[0]\n",
    "# print(music.annotations[0].annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from data.process_data import MidiEncoder, MIDIEncoderREMI\n",
    "import pickle as pkl\n",
    "from torch.utils.data import DataLoader\n",
    "from data.dataset import TransformerDatasetREMI\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_midi = \"data/emopia/EMOPIA_2.2/midis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your MidiEncoder and MidiEncoderREMI\n",
    "midi_files_list = [os.path.join(path_to_midi, file) for file in os.listdir(path_to_midi) if file.endswith(\".mid\")]\n",
    "midi_encoder = MidiEncoder(steps_per_sec=100, num_vel_bins=32, min_pitch=21, max_pitch=108)\n",
    "midi_encoder_remi = MIDIEncoderREMI(dict_path=\"data/encoder_dict.pkl\", midi_files_list=midi_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/emopia/EMOPIA_2.2/midis/Q1_9v2WSpn4FCw_10.mid\n",
      "0.02989935874938965\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_1.mid\n",
      "0.04293966293334961\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_3ZnxqCZ7qGg_0.mid\n",
      "0.009528160095214844\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vpTguZtJAFA_2.mid\n",
      "0.019782543182373047\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_5.mid\n",
      "0.014501571655273438\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JP3QKZlyQz4_0.mid\n",
      "0.010675430297851562\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Y5JcZQ0xg4Y_3.mid\n",
      "0.034755706787109375\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1Qc15G0ZHIg_3.mid\n",
      "0.023369550704956055\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ZgT7yq2jsBk_0.mid\n",
      "0.027832984924316406\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1kny88W533Q_4.mid\n",
      "0.029520273208618164\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_xIsvaT20pZ0_1.mid\n",
      "0.02054309844970703\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k-FNDbK6Qhg_2.mid\n",
      "0.15623235702514648\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_YAAxPW1GB7w_1.mid\n",
      "0.013345479965209961\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Q5b5unyP8BM_0.mid\n",
      "0.03593850135803223\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JxSU49jFKwM_1.mid\n",
      "0.012140035629272461\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_PK8YIUaV3Xw_1.mid\n",
      "0.013767480850219727\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Jn9r0avp0fY_3.mid\n",
      "0.03411269187927246\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TonQX8XbvX8_2.mid\n",
      "0.015815019607543945\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iHPKusssXzk_2.mid\n",
      "0.02041316032409668\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_POaIGvLsp5M_1.mid\n",
      "0.01774764060974121\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_eVMSeElk81Q_2.mid\n",
      "0.014837026596069336\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1vjy9oMFa8c_2.mid\n",
      "0.0157623291015625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_1Q3MoBFh6eU_2.mid\n",
      "0.02089548110961914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_HY9vPoHbgaI_1.mid\n",
      "0.0189971923828125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_f2b4kpdw7_c_0.mid\n",
      "0.014256000518798828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3ahg_eQZhxs_1.mid\n",
      "0.022488832473754883\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_f2b4kpdw7_c_1.mid\n",
      "0.01883530616760254\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_oTi57hZfArE_1.mid\n",
      "0.010767698287963867\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0H4rq0L9OSw_0.mid\n",
      "0.04650712013244629\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_3.mid\n",
      "0.024724483489990234\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_3.mid\n",
      "0.039331912994384766\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_2.mid\n",
      "0.019582271575927734\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1EDThWjNxOI_1.mid\n",
      "0.013645410537719727\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_xrhWli_R98g_0.mid\n",
      "0.019875049591064453\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_fey-8bOR95E_0.mid\n",
      "0.035422325134277344\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_4.mid\n",
      "0.022262096405029297\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6Uf9XBUD3wE_0.mid\n",
      "0.016152143478393555\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zvWX_dwQPtU_0.mid\n",
      "0.01733851432800293\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_38i12IPkL5c_2.mid\n",
      "0.034969329833984375\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ivCNV47tsRw_0.mid\n",
      "0.037099361419677734\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_7JIdJLkJ0S4_3.mid\n",
      "0.025218963623046875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_9v2WSpn4FCw_2.mid\n",
      "0.02214360237121582\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_10.mid\n",
      "0.02337503433227539\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Dg935IbDggo_0.mid\n",
      "0.03314995765686035\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kMHiU0fhWVw_1.mid\n",
      "0.021814823150634766\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_wzSr6qR3Ra0_0.mid\n",
      "0.018373966217041016\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lQCrA2TE-fo_0.mid\n",
      "0.014175653457641602\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_SQDuF0qxGQw_1.mid\n",
      "0.03098773956298828\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_jTPXwbDtIpA_0.mid\n",
      "0.013460159301757812\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Cg2u_Ldjv8g_0.mid\n",
      "0.02253437042236328\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DhnX54kOW8U_0.mid\n",
      "0.03229570388793945\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_2.mid\n",
      "0.03329730033874512\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jO2zX6Ul8GM_0.mid\n",
      "0.011390447616577148\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_im4Qxn3GQvo_1.mid\n",
      "0.02138996124267578\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_9Yb9OEVwups_0.mid\n",
      "0.017145156860351562\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_XC_SiJszQx0_1.mid\n",
      "0.027867794036865234\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_3.mid\n",
      "0.02018427848815918\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UJcnNfeCN1c_1.mid\n",
      "0.015354156494140625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0wRQRwnQiqY_0.mid\n",
      "0.02490997314453125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_AacIP9mDLw8_1.mid\n",
      "0.01753544807434082\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_2.mid\n",
      "0.025158166885375977\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_im4Qxn3GQvo_0.mid\n",
      "0.02416706085205078\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pRuwHN-lI44_0.mid\n",
      "0.018283367156982422\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_CxFXrYgdSSI_0.mid\n",
      "0.01465916633605957\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_4Er-eFHSHA4_3.mid\n",
      "0.020192623138427734\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ii1Jw1-7Ka4_1.mid\n",
      "0.01896834373474121\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_4.mid\n",
      "0.02310633659362793\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_fuCxYrru2S4_1.mid\n",
      "0.022199392318725586\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lTxVVdhFE6Q_0.mid\n",
      "0.02007436752319336\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0lEL_XHyhuU_2.mid\n",
      "0.012431144714355469\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_7gifuoofgpk_1.mid\n",
      "0.010738372802734375\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_DX1IK3z1w10_0.mid\n",
      "0.019883394241333008\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ZvD8QSO7NPw_2.mid\n",
      "0.048592567443847656\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_aYe-2Glruu4_4.mid\n",
      "0.04187154769897461\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UbKAl4roB8k_1.mid\n",
      "0.02489948272705078\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_2.mid\n",
      "0.004923343658447266\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_qlbazHayULg_3.mid\n",
      "0.03342270851135254\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_9Xg69XrVaYU_2.mid\n",
      "0.030069351196289062\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jNzZCplNNyY_0.mid\n",
      "0.021794557571411133\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_fOYX0uH8mSQ_0.mid\n",
      "0.014910697937011719\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_X1p8xcarVu0_0.mid\n",
      "0.013826131820678711\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bQS8eAXAhyE_2.mid\n",
      "0.030489683151245117\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_3.mid\n",
      "0.0313105583190918\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_K6OFDxBU370_1.mid\n",
      "0.01986217498779297\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ADJ_PDauy-g_0.mid\n",
      "0.009930133819580078\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TonQX8XbvX8_1.mid\n",
      "0.015262842178344727\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yrvKReuwVlY_3.mid\n",
      "0.024635791778564453\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_VXh4IaR5C6s_0.mid\n",
      "0.0205230712890625\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_9eMxCs-LXCE_2.mid\n",
      "0.022006988525390625\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_I2MrA-o5H8I_1.mid\n",
      "0.029186487197875977\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wlOa1jkTn_U_0.mid\n",
      "0.02604961395263672\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0v2N1ROvEI0_1.mid\n",
      "0.01853346824645996\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_tw_lArYiHTo_0.mid\n",
      "0.029646635055541992\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_8TYY0qG-KOw_0.mid\n",
      "0.019623279571533203\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_2.mid\n",
      "0.013836860656738281\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_eVMSeElk81Q_0.mid\n",
      "0.016253948211669922\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e838BE_MH6s_3.mid\n",
      "0.033529043197631836\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_4ydjOX3pWds_0.mid\n",
      "0.023297548294067383\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_By3JCii1k3w_2.mid\n",
      "0.013406991958618164\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Jn9r0avp0fY_1.mid\n",
      "0.04356193542480469\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_5.mid\n",
      "0.02854776382446289\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__kJtgm1OUNA_2.mid\n",
      "0.016590118408203125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HYVmgq5Y93g_0.mid\n",
      "0.019652366638183594\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ldCQ6N9G6Mk_2.mid\n",
      "0.009124040603637695\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_1.mid\n",
      "0.012851476669311523\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_EtAbPc20mn8_0.mid\n",
      "0.017536640167236328\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_12.mid\n",
      "0.023049354553222656\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_xrhWli_R98g_3.mid\n",
      "0.01842522621154785\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Iq6g_4AwUWs_0.mid\n",
      "0.03566765785217285\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XPLYvpyfKUM_0.mid\n",
      "0.013545751571655273\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_miqLU2739dk_0.mid\n",
      "0.029384374618530273\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_TcFVq0leii4_0.mid\n",
      "0.01601552963256836\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cFWdWpyvwag_0.mid\n",
      "0.022072315216064453\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_BaHHHgDd0BU_0.mid\n",
      "0.022902965545654297\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ISCVfmBvYoM_0.mid\n",
      "0.02123880386352539\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_7.mid\n",
      "0.020223617553710938\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KxlqB3j0zys_4.mid\n",
      "0.01364898681640625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_1.mid\n",
      "0.03909945487976074\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nBIls0laAAU_2.mid\n",
      "0.02990245819091797\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_VXgRfsVd_o0_2.mid\n",
      "0.02657914161682129\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pzeHffxmdcE_0.mid\n",
      "0.025337934494018555\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_FfwKrQyQ7WU_3.mid\n",
      "0.022173643112182617\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_AjN_5CdVUdw_0.mid\n",
      "0.015429973602294922\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OgkB7PfqWzA_1.mid\n",
      "0.00953221321105957\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_1.mid\n",
      "0.0123748779296875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jO2zX6Ul8GM_1.mid\n",
      "0.013817787170410156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UbKAl4roB8k_2.mid\n",
      "0.018346309661865234\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8izVTDgBQPc_0.mid\n",
      "0.023101091384887695\n",
      "data/emopia/EMOPIA_2.2/midis/Q3__vZOEQCYSaY_2.mid\n",
      "0.02762889862060547\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ZvD8QSO7NPw_0.mid\n",
      "0.012436389923095703\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Jn9r0avp0fY_2.mid\n",
      "0.03350687026977539\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Q49PWE0RJLY_0.mid\n",
      "0.025691986083984375\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_D8Ed5PZXfF4_0.mid\n",
      "0.016053199768066406\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_E6MARl3zjnQ_0.mid\n",
      "0.02640986442565918\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_pouxqiySdI8_1.mid\n",
      "0.02407050132751465\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_JNzqL24ZcZ8_2.mid\n",
      "0.021405696868896484\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_rrD7XMtPs0Q_0.mid\n",
      "0.01692342758178711\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_eGQUZ9FlUJ4_0.mid\n",
      "0.03668093681335449\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rW1I58_lMEg_1.mid\n",
      "0.015501976013183594\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_KxlqB3j0zys_1.mid\n",
      "0.012449264526367188\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_4.mid\n",
      "0.01395273208618164\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_7n32BtYb4d4_0.mid\n",
      "0.16764616966247559\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_08t73Qgjkt4_2.mid\n",
      "0.04331469535827637\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_V3Y9L4UOcpk_1.mid\n",
      "0.022478103637695312\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_7n32BtYb4d4_2.mid\n",
      "0.03361821174621582\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_HY9vPoHbgaI_2.mid\n",
      "0.02031111717224121\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UYh88SRZC24_0.mid\n",
      "0.030022621154785156\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0lEL_XHyhuU_3.mid\n",
      "0.008738517761230469\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_qlbazHayULg_9.mid\n",
      "0.016017675399780273\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GY3f6ckBVkA_0.mid\n",
      "0.017884492874145508\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jrVXitpLGMk_2.mid\n",
      "0.04488396644592285\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_tfuul78deOs_1.mid\n",
      "0.01824164390563965\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_1.mid\n",
      "0.01392817497253418\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Hwd6l9jK7bo_1.mid\n",
      "0.011889457702636719\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_0.mid\n",
      "0.019540786743164062\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_3.mid\n",
      "0.02059626579284668\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UJcnNfeCN1c_2.mid\n",
      "0.015375614166259766\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XPLYvpyfKUM_1.mid\n",
      "0.017865419387817383\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DYBBfpEx-JI_0.mid\n",
      "0.030634164810180664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rW1I58_lMEg_2.mid\n",
      "0.01830148696899414\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_gwmVjvR-sVs_1.mid\n",
      "0.018996715545654297\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Uu-oRTRT6uQ_0.mid\n",
      "0.03793764114379883\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FSzOgraSKhs_1.mid\n",
      "0.01591968536376953\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pRuwHN-lI44_3.mid\n",
      "0.015588045120239258\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TYkTOwBfFB8_0.mid\n",
      "0.022075176239013672\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_TNoaOTrTkTQ_2.mid\n",
      "0.017400741577148438\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_2.mid\n",
      "0.0233001708984375\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UJcnNfeCN1c_3.mid\n",
      "0.011942863464355469\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_NP0lwB-_-og_0.mid\n",
      "0.014410734176635742\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_5NW0zDu6IYM_2.mid\n",
      "0.05812859535217285\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_2.mid\n",
      "0.015132904052734375\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lvfNo4KOTmM_1.mid\n",
      "0.013830900192260742\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ZvD8QSO7NPw_1.mid\n",
      "0.025901317596435547\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_4.mid\n",
      "0.050833940505981445\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UYh88SRZC24_1.mid\n",
      "0.035126686096191406\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_yZGBxiNPu3k_2.mid\n",
      "0.024152040481567383\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_6.mid\n",
      "0.10374712944030762\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_AacIP9mDLw8_0.mid\n",
      "0.021064043045043945\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_PZN7XLKzLDI_0.mid\n",
      "0.02748703956604004\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_5.mid\n",
      "0.03353548049926758\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_1.mid\n",
      "0.04748225212097168\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Hwd6l9jK7bo_0.mid\n",
      "0.013676881790161133\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_OO7zYVeK814_1.mid\n",
      "0.017598390579223633\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_0.mid\n",
      "0.013906002044677734\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_hoPp_GLXQis_1.mid\n",
      "0.018773794174194336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_2Z9SjI131jA_6.mid\n",
      "0.019687652587890625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Ie5koh4qvJc_12.mid\n",
      "0.07254195213317871\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3N2G21U7guk_1.mid\n",
      "0.013628244400024414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_D3onzY4MNxE_0.mid\n",
      "0.013897180557250977\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_9v2WSpn4FCw_0.mid\n",
      "0.016697168350219727\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_aQ4PIaRMLwE_0.mid\n",
      "0.010524272918701172\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_0.mid\n",
      "0.06454038619995117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lvfNo4KOTmM_0.mid\n",
      "0.015676021575927734\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_heBmBQDWj-M_2.mid\n",
      "0.013232946395874023\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_p2qihp_PnLY_1.mid\n",
      "0.025101184844970703\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Xsn9zT-05ns_1.mid\n",
      "0.04009723663330078\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_0.mid\n",
      "0.02220773696899414\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__vZOEQCYSaY_1.mid\n",
      "0.018020153045654297\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_6oLmO9ZSJt0_1.mid\n",
      "0.007436513900756836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_61EA0xRX8gE_2.mid\n",
      "0.02117180824279785\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ezoAduuCkUs_0.mid\n",
      "0.04302835464477539\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_jziI_cuN_H8_1.mid\n",
      "0.0323491096496582\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_7.mid\n",
      "0.028707504272460938\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_TcFVq0leii4_2.mid\n",
      "0.040264129638671875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_f2BXXa7lPuE_3.mid\n",
      "0.03865861892700195\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_1kny88W533Q_1.mid\n",
      "0.014205694198608398\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JT1XJnVmABo_6.mid\n",
      "0.03328514099121094\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yrvKReuwVlY_2.mid\n",
      "0.04896140098571777\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_prUUays30Mg_1.mid\n",
      "0.01217794418334961\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Xsn9zT-05ns_0.mid\n",
      "0.03319144248962402\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bIx4DwkZxFY_0.mid\n",
      "0.013960599899291992\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_k6aLLVX1D7Y_1.mid\n",
      "0.025956392288208008\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Cg2u_Ldjv8g_1.mid\n",
      "0.14113497734069824\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0J7lX-Tcx-w_2.mid\n",
      "0.028820037841796875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_1.mid\n",
      "0.07692861557006836\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_CxFXrYgdSSI_2.mid\n",
      "0.03961300849914551\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kfYaGryaGzI_0.mid\n",
      "0.013702869415283203\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vpTguZtJAFA_1.mid\n",
      "0.010254859924316406\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_SQDuF0qxGQw_2.mid\n",
      "0.0295562744140625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ltxNPJda7zE_2.mid\n",
      "0.026071548461914062\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_RiQMuhk_SuQ_0.mid\n",
      "0.008497476577758789\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_3.mid\n",
      "0.015276432037353516\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_CxFXrYgdSSI_1.mid\n",
      "0.0357668399810791\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_K6OFDxBU370_0.mid\n",
      "0.019078731536865234\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zjr_-ql5Avk_1.mid\n",
      "0.008260250091552734\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_x4B0raxVODA_2.mid\n",
      "0.011660337448120117\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FOcdHIhI0_s_1.mid\n",
      "0.013801813125610352\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_PLfFWFZflQU_0.mid\n",
      "0.018625497817993164\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_bbU31JLtlug_1.mid\n",
      "0.03501009941101074\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__kJtgm1OUNA_0.mid\n",
      "0.020130634307861328\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_-_FjI4bT2Wo_0.mid\n",
      "0.023483753204345703\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_77z6Ep3aOmg_0.mid\n",
      "0.01928877830505371\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_g15aRCHUJEI_0.mid\n",
      "0.012614250183105469\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5J_zI7QE9W8_2.mid\n",
      "0.01983046531677246\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lQCrA2TE-fo_1.mid\n",
      "0.013901472091674805\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_WBxql6cuU7c_0.mid\n",
      "0.03934955596923828\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pRuwHN-lI44_2.mid\n",
      "0.012358427047729492\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_-jJVb0xvbdg_0.mid\n",
      "0.0184328556060791\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_jziI_cuN_H8_2.mid\n",
      "0.0425567626953125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_1.mid\n",
      "0.011739969253540039\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_-vAz_HTFEXs_0.mid\n",
      "0.014553308486938477\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TYkTOwBfFB8_1.mid\n",
      "0.025705575942993164\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_qRceKZtwRWA_0.mid\n",
      "0.011706113815307617\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_sUJ4a74Skk8_0.mid\n",
      "0.016701221466064453\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_1cgO42sh-ZY_0.mid\n",
      "0.008620023727416992\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_X1p8xcarVu0_2.mid\n",
      "0.012770414352416992\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e8NQ2NH0nc8_1.mid\n",
      "0.020459890365600586\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_0.mid\n",
      "0.012989521026611328\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wS0RzrBL9UI_0.mid\n",
      "0.013249635696411133\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_iwxwLEvqeD8_0.mid\n",
      "0.009807586669921875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_b8HVQtIoBYU_1.mid\n",
      "0.02941107749938965\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_7n32BtYb4d4_3.mid\n",
      "0.028701066970825195\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_kDGmND1BgmA_1.mid\n",
      "0.006568431854248047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UAm0aWvzFI8_1.mid\n",
      "0.03512310981750488\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_DvIH5yUrboc_1.mid\n",
      "0.02971196174621582\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_r_sD61KeUQU_0.mid\n",
      "0.019428491592407227\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_8.mid\n",
      "0.05247020721435547\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_g-yM0Lsp4lc_0.mid\n",
      "0.014613866806030273\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cQp1BYDGcRo_1.mid\n",
      "0.0349423885345459\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_PLfFWFZflQU_1.mid\n",
      "0.027538776397705078\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DYBBfpEx-JI_3.mid\n",
      "0.04296517372131348\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ury1cdB79s0_0.mid\n",
      "0.01130366325378418\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_15.mid\n",
      "0.014063358306884766\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_0.mid\n",
      "0.025603532791137695\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_vVTP0DOL_2Q_1.mid\n",
      "0.014290809631347656\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Kk60F8a7-Jw_0.mid\n",
      "0.023334503173828125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__FVzelKlBFs_2.mid\n",
      "0.021672964096069336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_0.mid\n",
      "0.01125192642211914\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_2.mid\n",
      "0.042108774185180664\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_UJcnNfeCN1c_0.mid\n",
      "0.012401342391967773\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_02t1bj7ZABY_1.mid\n",
      "0.015616655349731445\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_12tDlCQVRtA_1.mid\n",
      "0.01672077178955078\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xf2fox7zhCQ_0.mid\n",
      "0.016138076782226562\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6kRPHamGDSo_3.mid\n",
      "0.018447399139404297\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KRlAez34QfE_1.mid\n",
      "0.01673722267150879\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_-_FjI4bT2Wo_2.mid\n",
      "0.011927366256713867\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Uu-oRTRT6uQ_1.mid\n",
      "0.04223775863647461\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_12.mid\n",
      "0.0327458381652832\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_RiQMuhk_SuQ_2.mid\n",
      "0.08266258239746094\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_2.mid\n",
      "0.02104496955871582\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_VXgRfsVd_o0_1.mid\n",
      "0.04155445098876953\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Dg935IbDggo_1.mid\n",
      "0.03707385063171387\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_T92R7xjce34_1.mid\n",
      "0.017516136169433594\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_x4B0raxVODA_1.mid\n",
      "0.007969141006469727\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5DqIntcmdRI_1.mid\n",
      "0.020109891891479492\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_epX33OVpkmA_1.mid\n",
      "0.04106760025024414\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_9.mid\n",
      "0.04025912284851074\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltxNPJda7zE_1.mid\n",
      "0.011512517929077148\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_d_49EtXDMFE_1.mid\n",
      "0.011919021606445312\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_94ROf10d1iA_0.mid\n",
      "0.011626243591308594\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_2.mid\n",
      "0.0181121826171875\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_VrWAZLRdQO8_0.mid\n",
      "0.008015871047973633\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_xrhWli_R98g_1.mid\n",
      "0.027854442596435547\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iGHgeUCPotc_0.mid\n",
      "0.0143280029296875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Y5JcZQ0xg4Y_1.mid\n",
      "0.02187657356262207\n",
      "data/emopia/EMOPIA_2.2/midis/Q3__vZOEQCYSaY_0.mid\n",
      "0.019354820251464844\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_0.mid\n",
      "0.041661977767944336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_78C_TpQDvVE_1.mid\n",
      "0.023270845413208008\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XC_SiJszQx0_0.mid\n",
      "0.011240959167480469\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_veG92Oi-DlU_0.mid\n",
      "0.01981186866760254\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_dfNdpy8TUzA_1.mid\n",
      "0.015984773635864258\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_fShAWhXIits_1.mid\n",
      "0.01622486114501953\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZTrEoB8T9YA_0.mid\n",
      "0.0321507453918457\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_17.mid\n",
      "0.011442899703979492\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_TNoaOTrTkTQ_1.mid\n",
      "0.022435426712036133\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yhIncZ_Ue4E_0.mid\n",
      "0.017858266830444336\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_7yW9c7t8Hq0_3.mid\n",
      "0.04164910316467285\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_31.mid\n",
      "0.016486406326293945\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_XfA2KXodrOE_0.mid\n",
      "0.03323674201965332\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_BGf5nCdzPOc_0.mid\n",
      "0.05054354667663574\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bQS8eAXAhyE_0.mid\n",
      "0.016017436981201172\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DYBBfpEx-JI_2.mid\n",
      "0.037099599838256836\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zvWX_dwQPtU_1.mid\n",
      "0.030671358108520508\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_mX-xs3OVhTs_1.mid\n",
      "0.030684471130371094\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_QwsQ8ejbMKg_0.mid\n",
      "0.03778839111328125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3N2G21U7guk_5.mid\n",
      "0.02260589599609375\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_QJlnTN7HRwE_0.mid\n",
      "0.00921010971069336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ldCQ6N9G6Mk_5.mid\n",
      "0.03481030464172363\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_4Er-eFHSHA4_1.mid\n",
      "0.017862558364868164\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_DvIH5yUrboc_0.mid\n",
      "0.027348041534423828\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_L3_TadjSQQ0_0.mid\n",
      "0.04958343505859375\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UOSlDydo94E_0.mid\n",
      "0.019617795944213867\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__SJQaaRzD-A_1.mid\n",
      "0.026187896728515625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_b8HVQtIoBYU_0.mid\n",
      "0.14292001724243164\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1EDThWjNxOI_0.mid\n",
      "0.011992692947387695\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_0.mid\n",
      "0.005352020263671875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_2w5XkAt_3WU_0.mid\n",
      "0.011731863021850586\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Dw7M69CidJ8_0.mid\n",
      "0.011344194412231445\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_WQrPcuy50aA_1.mid\n",
      "0.026766538619995117\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_vVTP0DOL_2Q_3.mid\n",
      "0.015709400177001953\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_mlHheZbblT0_1.mid\n",
      "0.022925853729248047\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1Qc15G0ZHIg_1.mid\n",
      "0.024827241897583008\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1vjy9oMFa8c_4.mid\n",
      "0.01204681396484375\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_L3_TadjSQQ0_1.mid\n",
      "0.03990364074707031\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_4.mid\n",
      "0.024688005447387695\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_AacIP9mDLw8_2.mid\n",
      "0.023440837860107422\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_4.mid\n",
      "0.040694475173950195\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GY3f6ckBVkA_1.mid\n",
      "0.015124797821044922\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_f2BXXa7lPuE_0.mid\n",
      "0.021669864654541016\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KRlAez34QfE_2.mid\n",
      "0.016228675842285156\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_JNzqL24ZcZ8_0.mid\n",
      "0.02271723747253418\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_epX33OVpkmA_2.mid\n",
      "0.02754831314086914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s6-SbDSZzEU_0.mid\n",
      "0.022668123245239258\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_fnqb8zqHqdY_1.mid\n",
      "0.010011434555053711\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pkz8OkWhwnk_1.mid\n",
      "0.016444921493530273\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FH28sPhm9Dc_1.mid\n",
      "0.025762081146240234\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_POaIGvLsp5M_0.mid\n",
      "0.016165494918823242\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_WpZ1rWHOCAQ_0.mid\n",
      "0.014001131057739258\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_cXxGBDgFCs8_0.mid\n",
      "0.02147960662841797\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_7yW9c7t8Hq0_2.mid\n",
      "0.021455764770507812\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_fShAWhXIits_0.mid\n",
      "0.03425002098083496\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_dfNdpy8TUzA_2.mid\n",
      "0.017426490783691406\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UTo7E0evQWw_0.mid\n",
      "0.019988059997558594\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_1.mid\n",
      "0.0317537784576416\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_94ROf10d1iA_2.mid\n",
      "0.006472110748291016\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_snfsc7pEzlk_1.mid\n",
      "0.03651022911071777\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_z5ewpQwGDNw_0.mid\n",
      "0.015160322189331055\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_FUAK5TBaNY8_1.mid\n",
      "0.02213764190673828\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0H4rq0L9OSw_1.mid\n",
      "0.04971146583557129\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S7Bo4-NCEDk_1.mid\n",
      "0.04026532173156738\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_REq37pDAm3A_3.mid\n",
      "0.023619413375854492\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltNK_MY1HkM_2.mid\n",
      "0.006138801574707031\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_yZGBxiNPu3k_1.mid\n",
      "0.017007827758789062\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZdyiXIlKe_Y_1.mid\n",
      "0.020781755447387695\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_BzqX-9TA-GY_0.mid\n",
      "0.004453182220458984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_sA9ac1rod84_0.mid\n",
      "0.02021956443786621\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_PdwxeMPXOCk_1.mid\n",
      "0.027828216552734375\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_cCfEDTkuMvg_0.mid\n",
      "0.010782241821289062\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_d_49EtXDMFE_2.mid\n",
      "0.01067042350769043\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OoxI6k0Qsno_0.mid\n",
      "0.011038541793823242\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_TcFVq0leii4_1.mid\n",
      "0.03420305252075195\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0lEL_XHyhuU_0.mid\n",
      "0.008401155471801758\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wxXpvnmq_-E_2.mid\n",
      "0.011900663375854492\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JT1XJnVmABo_3.mid\n",
      "0.01069951057434082\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KRlAez34QfE_0.mid\n",
      "0.015504837036132812\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_0.mid\n",
      "0.013553619384765625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D-gDPh9ZpFk_2.mid\n",
      "0.03452277183532715\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D5kyjnlDNZs_0.mid\n",
      "0.032624006271362305\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_4.mid\n",
      "0.014757156372070312\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_4dXC1cC7crw_1.mid\n",
      "0.02848052978515625\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OUb9uaOlWAM_0.mid\n",
      "0.009682893753051758\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cFWdWpyvwag_1.mid\n",
      "0.048973798751831055\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_4Er-eFHSHA4_2.mid\n",
      "0.01825690269470215\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e8NQ2NH0nc8_0.mid\n",
      "0.020888328552246094\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_V_jbWvQNh5c_1.mid\n",
      "0.008854389190673828\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_snfsc7pEzlk_0.mid\n",
      "0.016687393188476562\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yrvKReuwVlY_0.mid\n",
      "0.016105175018310547\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_9eMxCs-LXCE_0.mid\n",
      "0.008758544921875\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ldCQ6N9G6Mk_4.mid\n",
      "0.01921558380126953\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0EWWyyV7RJA_0.mid\n",
      "0.025116682052612305\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UpHutdJvZMI_0.mid\n",
      "0.013309717178344727\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__8v0MFBZoco_0.mid\n",
      "0.05466508865356445\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_v3Nl5rUxLqE_1.mid\n",
      "0.007309436798095703\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OoxI6k0Qsno_1.mid\n",
      "0.010962486267089844\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_1.mid\n",
      "0.019685983657836914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_pNwQ9Tu_bCs_1.mid\n",
      "0.02377152442932129\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5J_zI7QE9W8_1.mid\n",
      "0.014988422393798828\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ijfxkQPAQdE_2.mid\n",
      "0.0549778938293457\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_MT2_mXn-vGU_0.mid\n",
      "0.015533208847045898\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_VCSDjQxAJzc_1.mid\n",
      "0.017000436782836914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6wFJhmhNeeg_0.mid\n",
      "0.051566362380981445\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_xYZ8n8ULaNo_1.mid\n",
      "0.01830577850341797\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_3.mid\n",
      "0.01586151123046875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3TYeU9idRGI_0.mid\n",
      "0.008908987045288086\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xlv4PPGrRRs_1.mid\n",
      "0.016544580459594727\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JMt4m608s3k_0.mid\n",
      "0.025406599044799805\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1TAKQK3s6qQ_0.mid\n",
      "0.04442405700683594\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_3.mid\n",
      "0.03570103645324707\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kMHiU0fhWVw_2.mid\n",
      "0.01594853401184082\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Jn9r0avp0fY_0.mid\n",
      "0.03223085403442383\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_cXxGBDgFCs8_2.mid\n",
      "0.015182733535766602\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_x5ibvz38jOs_0.mid\n",
      "0.02268052101135254\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_xYZ8n8ULaNo_0.mid\n",
      "0.011993885040283203\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3N2G21U7guk_4.mid\n",
      "0.014531373977661133\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_o20YCzej5_s_0.mid\n",
      "0.04789018630981445\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FyK_c-TIcCA_0.mid\n",
      "0.029061079025268555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_mGYKWCVnMwQ_1.mid\n",
      "0.024998188018798828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Fc1qk52SaKY_0.mid\n",
      "0.029452085494995117\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_BzqX-9TA-GY_2.mid\n",
      "0.014069080352783203\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_OCqMDeD6Fmc_0.mid\n",
      "0.023647785186767578\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s5b8viFsVJE_1.mid\n",
      "0.037344932556152344\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Cir1kZyB7QM_0.mid\n",
      "0.01656794548034668\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_21.mid\n",
      "0.03479814529418945\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1kny88W533Q_2.mid\n",
      "0.03542041778564453\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_wfXSdMsd4q8_5.mid\n",
      "0.03154397010803223\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jSWItJI-Gmk_1.mid\n",
      "0.01627206802368164\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_7n32BtYb4d4_1.mid\n",
      "0.018082380294799805\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_eGQUZ9FlUJ4_1.mid\n",
      "0.0419926643371582\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_E5qEloUO3SM_0.mid\n",
      "0.02053236961364746\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wlOa1jkTn_U_1.mid\n",
      "0.026529550552368164\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_TOXg4-ZGb-g_2.mid\n",
      "0.011388778686523438\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_pNwQ9Tu_bCs_2.mid\n",
      "0.023790597915649414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_tfuul78deOs_0.mid\n",
      "0.015340089797973633\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_5.mid\n",
      "0.03269839286804199\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_k-FNDbK6Qhg_1.mid\n",
      "0.02293682098388672\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XWk5XUEBXmg_0.mid\n",
      "0.01415395736694336\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zHwJG8Rrx6c_1.mid\n",
      "0.016897201538085938\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_qlbazHayULg_13.mid\n",
      "0.036840200424194336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_6.mid\n",
      "0.15868258476257324\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_RaUSISlnhKw_2.mid\n",
      "0.034601449966430664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_16.mid\n",
      "0.005733013153076172\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_24.mid\n",
      "0.023806333541870117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FoTXpYZXxJs_0.mid\n",
      "0.01740097999572754\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_gxsdWKc1QaM_0.mid\n",
      "0.025872230529785156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_BIRDDxz0E4c_1.mid\n",
      "0.012336015701293945\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_12tDlCQVRtA_0.mid\n",
      "0.010502099990844727\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_aQ4PIaRMLwE_1.mid\n",
      "0.018706321716308594\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_SlsXsqotUis_0.mid\n",
      "0.03724527359008789\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Y1F0c3zgMJo_1.mid\n",
      "0.012228012084960938\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_--2B4d4lQhs_1.mid\n",
      "0.0707559585571289\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s5b8viFsVJE_2.mid\n",
      "0.03386402130126953\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1kny88W533Q_3.mid\n",
      "0.031896352767944336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_38i12IPkL5c_1.mid\n",
      "0.031674861907958984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xlv4PPGrRRs_0.mid\n",
      "0.013685941696166992\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_FfwKrQyQ7WU_1.mid\n",
      "0.021591663360595703\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_eVMSeElk81Q_1.mid\n",
      "0.04034566879272461\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_oTi57hZfArE_0.mid\n",
      "0.01919269561767578\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jIKX3ShvLxo_1.mid\n",
      "0.05362892150878906\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Gcbk0GPT3-g_0.mid\n",
      "0.024318456649780273\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JYVXM0qNQAg_1.mid\n",
      "0.04935646057128906\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1fdxsFbnsX4_0.mid\n",
      "0.01280069351196289\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_IgpNyJVWcBo_0.mid\n",
      "0.023082971572875977\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_X1p8xcarVu0_3.mid\n",
      "0.01735830307006836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5Ju9q1N2x0E_1.mid\n",
      "0.04654383659362793\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_u_7b9CwyM8Q_0.mid\n",
      "0.020661354064941406\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_7.mid\n",
      "0.03638482093811035\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_cB-Xh8H_7-Q_0.mid\n",
      "0.037629127502441406\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_16OaOpfOPZ0_1.mid\n",
      "0.019028186798095703\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TonQX8XbvX8_0.mid\n",
      "0.00831151008605957\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_egYSmNuIFGk_2.mid\n",
      "0.01787853240966797\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_J6X3rVU1H-c_1.mid\n",
      "0.023427248001098633\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_D3onzY4MNxE_1.mid\n",
      "0.011839151382446289\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_rEz0D3VohFA_2.mid\n",
      "0.04784417152404785\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0v2N1ROvEI0_0.mid\n",
      "0.07148218154907227\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_f0NbGeyJYms_0.mid\n",
      "0.021468639373779297\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Dw7M69CidJ8_1.mid\n",
      "0.019172191619873047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_iwxwLEvqeD8_1.mid\n",
      "0.012495756149291992\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_60LLKmpgzRM_0.mid\n",
      "0.005658864974975586\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_9.mid\n",
      "0.017605304718017578\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_2.mid\n",
      "0.05230855941772461\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XC_SiJszQx0_2.mid\n",
      "0.011414051055908203\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_3.mid\n",
      "0.04204511642456055\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_v2an-9szi8M_0.mid\n",
      "0.014328479766845703\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_3.mid\n",
      "0.012686967849731445\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0qYNvMCEwaw_0.mid\n",
      "0.032808780670166016\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_8.mid\n",
      "0.03047347068786621\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_K84TcgjCRt4_0.mid\n",
      "0.010235071182250977\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_16OaOpfOPZ0_3.mid\n",
      "0.021399974822998047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UE0y8MHqT-g_2.mid\n",
      "0.03596758842468262\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Q49PWE0RJLY_1.mid\n",
      "0.01751399040222168\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_OO7zYVeK814_2.mid\n",
      "0.009925127029418945\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_fey-8bOR95E_1.mid\n",
      "0.03439188003540039\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_13.mid\n",
      "0.02456212043762207\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_3.mid\n",
      "0.04669952392578125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_BGf5nCdzPOc_1.mid\n",
      "0.03763175010681152\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZdyiXIlKe_Y_0.mid\n",
      "0.024985551834106445\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_snfsc7pEzlk_2.mid\n",
      "0.039055585861206055\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_7yW9c7t8Hq0_1.mid\n",
      "0.037137508392333984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_xrhWli_R98g_2.mid\n",
      "0.015284061431884766\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k-FNDbK6Qhg_0.mid\n",
      "0.043077707290649414\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_g15aRCHUJEI_2.mid\n",
      "0.01353001594543457\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FyK_c-TIcCA_2.mid\n",
      "0.08959650993347168\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_B3aRl8iTEKw_1.mid\n",
      "0.025745153427124023\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ufRISSD28XA_1.mid\n",
      "0.02203226089477539\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iHPKusssXzk_1.mid\n",
      "0.017082929611206055\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ldCQ6N9G6Mk_1.mid\n",
      "0.013998985290527344\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZTrEoB8T9YA_2.mid\n",
      "0.02546095848083496\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_0.mid\n",
      "0.021538257598876953\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_4.mid\n",
      "0.020186424255371094\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_uqRLEByE6pU_2.mid\n",
      "0.05549883842468262\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nFunbdBrukY_0.mid\n",
      "0.013998270034790039\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nBao46YGZDg_0.mid\n",
      "0.010279417037963867\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_K84TcgjCRt4_2.mid\n",
      "0.022110700607299805\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xf2fox7zhCQ_2.mid\n",
      "0.01639080047607422\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_nGkpcWNAxDU_2.mid\n",
      "0.022696971893310547\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_PZN7XLKzLDI_1.mid\n",
      "0.025763750076293945\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k4lT-sXg3iI_2.mid\n",
      "0.1573936939239502\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cm6E860vDjY_2.mid\n",
      "0.0326998233795166\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ivCNV47tsRw_1.mid\n",
      "0.033937692642211914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_IH2KrGjKXw0_3.mid\n",
      "0.042308807373046875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1vjy9oMFa8c_5.mid\n",
      "0.037880897521972656\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kMHiU0fhWVw_3.mid\n",
      "0.017000198364257812\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_GwdQliEv6Z0_0.mid\n",
      "0.02881789207458496\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_19.mid\n",
      "0.012950420379638672\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__kJtgm1OUNA_1.mid\n",
      "0.029554128646850586\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_GwdQliEv6Z0_1.mid\n",
      "0.022132158279418945\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_2eIsQtm4YNs_1.mid\n",
      "0.018890857696533203\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JP3QKZlyQz4_2.mid\n",
      "0.010050058364868164\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_qRceKZtwRWA_1.mid\n",
      "0.017625808715820312\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D-gDPh9ZpFk_1.mid\n",
      "0.03689718246459961\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Ie5koh4qvJc_6.mid\n",
      "0.03776717185974121\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_RaUSISlnhKw_0.mid\n",
      "0.01934075355529785\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_3_MxhSS86oU_0.mid\n",
      "0.041518449783325195\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_0.mid\n",
      "0.027027368545532227\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_o5AIp2Yc01M_1.mid\n",
      "0.04493880271911621\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HYVmgq5Y93g_2.mid\n",
      "0.015711545944213867\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FUAK5TBaNY8_0.mid\n",
      "0.024504899978637695\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_2.mid\n",
      "0.007842302322387695\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xf2fox7zhCQ_1.mid\n",
      "0.014019966125488281\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_epMOLn5Axw0_0.mid\n",
      "0.022326231002807617\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_7gifuoofgpk_0.mid\n",
      "0.014005184173583984\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nBIls0laAAU_1.mid\n",
      "0.01967144012451172\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_4.mid\n",
      "0.03072810173034668\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OgkB7PfqWzA_0.mid\n",
      "0.009935140609741211\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_p2qihp_PnLY_0.mid\n",
      "0.026841163635253906\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_2v6gJi03LlA_0.mid\n",
      "0.01792144775390625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_dCoUuknChhE_0.mid\n",
      "0.010114908218383789\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UOSlDydo94E_1.mid\n",
      "0.016670942306518555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1Qc15G0ZHIg_0.mid\n",
      "0.013410091400146484\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_7JIdJLkJ0S4_2.mid\n",
      "0.015758514404296875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_x5ibvz38jOs_1.mid\n",
      "0.02881479263305664\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__BK2o77sTc0_1.mid\n",
      "0.02149224281311035\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_z5ewpQwGDNw_2.mid\n",
      "0.026263952255249023\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_5CEAeMiXKaA_0.mid\n",
      "0.01776432991027832\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_sEQf5lcnj_o_2.mid\n",
      "0.05566549301147461\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_VrWAZLRdQO8_1.mid\n",
      "0.008604764938354492\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_11.mid\n",
      "0.040148019790649414\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_j8Ir-ssM-AA_0.mid\n",
      "0.030747413635253906\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_1.mid\n",
      "0.005461692810058594\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_jziI_cuN_H8_0.mid\n",
      "0.02530956268310547\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_3.mid\n",
      "0.01619267463684082\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_10.mid\n",
      "0.022362947463989258\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ivCNV47tsRw_2.mid\n",
      "0.05495953559875488\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_PXOWy7NiZhk_0.mid\n",
      "0.02077317237854004\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wS0RzrBL9UI_2.mid\n",
      "0.025130510330200195\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_2Z9SjI131jA_5.mid\n",
      "0.012819051742553711\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_0.mid\n",
      "0.019914627075195312\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DYBBfpEx-JI_1.mid\n",
      "0.02211618423461914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GbUV3TXUzeQ_2.mid\n",
      "0.0370173454284668\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JMt4m608s3k_2.mid\n",
      "0.03889918327331543\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8rupdevqfuI_1.mid\n",
      "0.015584468841552734\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ii1Jw1-7Ka4_2.mid\n",
      "0.021542787551879883\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_QJlnTN7HRwE_1.mid\n",
      "0.010154008865356445\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1vjy9oMFa8c_3.mid\n",
      "0.010674715042114258\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_K84TcgjCRt4_1.mid\n",
      "0.01780247688293457\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_tLmXAWfbGqs_0.mid\n",
      "0.015674352645874023\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_12tDlCQVRtA_2.mid\n",
      "0.02185344696044922\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_CkjAksZstEA_1.mid\n",
      "0.01338648796081543\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_CkjAksZstEA_0.mid\n",
      "0.010092973709106445\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_5.mid\n",
      "0.04344820976257324\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_22.mid\n",
      "0.014703035354614258\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jrVXitpLGMk_0.mid\n",
      "0.02303481101989746\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_NTI9ode6bRk_1.mid\n",
      "0.018689632415771484\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jrVXitpLGMk_1.mid\n",
      "0.033568620681762695\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1A9Hh2GrDTs_0.mid\n",
      "0.02774977684020996\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0c2dTJTDUR4_0.mid\n",
      "0.00830531120300293\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5J_zI7QE9W8_0.mid\n",
      "0.02368617057800293\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kMHiU0fhWVw_0.mid\n",
      "0.015734434127807617\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_78C_TpQDvVE_0.mid\n",
      "0.011498212814331055\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_x4B0raxVODA_3.mid\n",
      "0.009598255157470703\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_1.mid\n",
      "0.014501810073852539\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_k4dxAlI5N-k_0.mid\n",
      "0.04578137397766113\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ADJ_PDauy-g_1.mid\n",
      "0.02239060401916504\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_fuCxYrru2S4_0.mid\n",
      "0.01812148094177246\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_VCSDjQxAJzc_2.mid\n",
      "0.01081538200378418\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_4.mid\n",
      "0.016141653060913086\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_VXgRfsVd_o0_0.mid\n",
      "0.013820409774780273\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_sEQf5lcnj_o_0.mid\n",
      "0.0386502742767334\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cm6E860vDjY_0.mid\n",
      "0.03328657150268555\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_UuLTvhERcnk_0.mid\n",
      "0.013363838195800781\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_k4dxAlI5N-k_1.mid\n",
      "0.06588459014892578\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_egYSmNuIFGk_0.mid\n",
      "0.0209348201751709\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_QmK_SND2jAw_1.mid\n",
      "0.06478118896484375\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_I2MrA-o5H8I_2.mid\n",
      "0.03482317924499512\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Adil-zpJdEs_0.mid\n",
      "0.034360408782958984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltNK_MY1HkM_1.mid\n",
      "0.0071506500244140625\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_170KC2CbJ7Y_1.mid\n",
      "0.013208627700805664\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_NGE9ynTJABg_2.mid\n",
      "0.02311420440673828\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_g15aRCHUJEI_1.mid\n",
      "0.012773275375366211\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_0.mid\n",
      "0.00947117805480957\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_GAvPwG2wYZM_1.mid\n",
      "0.015593290328979492\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_3.mid\n",
      "0.013123035430908203\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_1.mid\n",
      "0.013418436050415039\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_8c7kcmsnf-s_0.mid\n",
      "0.03287005424499512\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_gwmVjvR-sVs_0.mid\n",
      "0.027647733688354492\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_dfNdpy8TUzA_0.mid\n",
      "0.01278996467590332\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OyaY4213c2A_0.mid\n",
      "0.024085044860839844\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Gcbk0GPT3-g_1.mid\n",
      "0.015568733215332031\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_77z6Ep3aOmg_1.mid\n",
      "0.026188373565673828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zHwJG8Rrx6c_3.mid\n",
      "0.021946191787719727\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_z5ewpQwGDNw_1.mid\n",
      "0.01685619354248047\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_biROWEwkDQQ_2.mid\n",
      "0.015094518661499023\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_uqRLEByE6pU_0.mid\n",
      "0.04594254493713379\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_gvWDOIiocuE_2.mid\n",
      "0.013097047805786133\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jTPXwbDtIpA_1.mid\n",
      "0.04708147048950195\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_iFgSjUqI7iM_0.mid\n",
      "0.02452707290649414\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_NP0lwB-_-og_1.mid\n",
      "0.03286576271057129\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_5NW0zDu6IYM_1.mid\n",
      "0.027527809143066406\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_16OaOpfOPZ0_0.mid\n",
      "0.013387918472290039\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_B3aRl8iTEKw_0.mid\n",
      "0.020896434783935547\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0J7lX-Tcx-w_0.mid\n",
      "0.02270221710205078\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_veG92Oi-DlU_2.mid\n",
      "0.015514850616455078\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_nOIBJHkqrE8_1.mid\n",
      "0.02452373504638672\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wxXpvnmq_-E_0.mid\n",
      "0.015325069427490234\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_bfopzItCYrE_1.mid\n",
      "0.020537137985229492\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ivCNV47tsRw_3.mid\n",
      "0.03278303146362305\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JMt4m608s3k_1.mid\n",
      "0.03183698654174805\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wlOa1jkTn_U_2.mid\n",
      "0.13344383239746094\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_MT2_mXn-vGU_1.mid\n",
      "0.01976943016052246\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_0c2dTJTDUR4_1.mid\n",
      "0.013144493103027344\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_RiQMuhk_SuQ_3.mid\n",
      "0.0521092414855957\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_VCSDjQxAJzc_0.mid\n",
      "0.018809080123901367\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_1.mid\n",
      "0.013777017593383789\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_PdwxeMPXOCk_0.mid\n",
      "0.033158302307128906\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_sA9ac1rod84_1.mid\n",
      "0.02472853660583496\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_4.mid\n",
      "0.026583433151245117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_e838BE_MH6s_0.mid\n",
      "0.024491310119628906\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_j8Ir-ssM-AA_1.mid\n",
      "0.016978025436401367\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_RiQMuhk_SuQ_1.mid\n",
      "0.030753135681152344\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GbUV3TXUzeQ_1.mid\n",
      "0.027626991271972656\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5DqIntcmdRI_0.mid\n",
      "0.029799461364746094\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_IH2KrGjKXw0_2.mid\n",
      "0.013635635375976562\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_mlHheZbblT0_0.mid\n",
      "0.028269052505493164\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_5.mid\n",
      "0.026208877563476562\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_4Er-eFHSHA4_0.mid\n",
      "0.014126062393188477\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_8TYY0qG-KOw_1.mid\n",
      "0.025681257247924805\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_3ZnxqCZ7qGg_1.mid\n",
      "0.015520095825195312\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_heBmBQDWj-M_1.mid\n",
      "0.02987957000732422\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yhIncZ_Ue4E_2.mid\n",
      "0.018602371215820312\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ItGNJM6skM4_1.mid\n",
      "0.04881095886230469\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_16OaOpfOPZ0_2.mid\n",
      "0.02794623374938965\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_V_jbWvQNh5c_0.mid\n",
      "0.009451627731323242\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zjr_-ql5Avk_0.mid\n",
      "0.00600433349609375\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_OCqMDeD6Fmc_3.mid\n",
      "0.06113386154174805\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_02t1bj7ZABY_2.mid\n",
      "0.023281574249267578\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_MbvPxCUMSek_2.mid\n",
      "0.008538246154785156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UpHutdJvZMI_1.mid\n",
      "0.02173161506652832\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_4.mid\n",
      "0.01923680305480957\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D5kyjnlDNZs_2.mid\n",
      "0.05743670463562012\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rDhbGjFlKF8_0.mid\n",
      "0.018430471420288086\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_im4Qxn3GQvo_2.mid\n",
      "0.025140047073364258\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1fdxsFbnsX4_1.mid\n",
      "0.015892982482910156\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_MbvPxCUMSek_0.mid\n",
      "0.012070178985595703\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_7.mid\n",
      "0.03486752510070801\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_g-yM0Lsp4lc_1.mid\n",
      "0.008113622665405273\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ufRISSD28XA_0.mid\n",
      "0.01932215690612793\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltxNPJda7zE_3.mid\n",
      "0.016002416610717773\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_3.mid\n",
      "0.014271974563598633\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_BaHHHgDd0BU_1.mid\n",
      "0.02517986297607422\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_J6X3rVU1H-c_0.mid\n",
      "0.009757757186889648\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_HY9vPoHbgaI_3.mid\n",
      "0.01262044906616211\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e838BE_MH6s_1.mid\n",
      "0.018123865127563477\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_biROWEwkDQQ_3.mid\n",
      "0.02204275131225586\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3TYeU9idRGI_1.mid\n",
      "0.007727861404418945\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Wy2-my19YnY_1.mid\n",
      "0.026041507720947266\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UE0y8MHqT-g_1.mid\n",
      "0.04378509521484375\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_1Q3MoBFh6eU_0.mid\n",
      "0.018387317657470703\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_QJlnTN7HRwE_3.mid\n",
      "0.012977123260498047\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_r6laJv1-HMg_0.mid\n",
      "0.025283336639404297\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3As1t6JySDE_0.mid\n",
      "0.021416187286376953\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nBIls0laAAU_0.mid\n",
      "0.02004837989807129\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_f2BXXa7lPuE_2.mid\n",
      "0.04218006134033203\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_30.mid\n",
      "0.024530410766601562\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_By3JCii1k3w_1.mid\n",
      "0.01537775993347168\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_NGE9ynTJABg_0.mid\n",
      "0.0410921573638916\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_OCqMDeD6Fmc_1.mid\n",
      "0.03128528594970703\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JxSU49jFKwM_0.mid\n",
      "0.01674056053161621\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wxXpvnmq_-E_1.mid\n",
      "0.013288736343383789\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_4.mid\n",
      "0.011100292205810547\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltNK_MY1HkM_0.mid\n",
      "0.01019144058227539\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FH28sPhm9Dc_0.mid\n",
      "0.017821073532104492\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_rEz0D3VohFA_1.mid\n",
      "0.03652834892272949\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yrvKReuwVlY_1.mid\n",
      "0.012613773345947266\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_QwsQ8ejbMKg_1.mid\n",
      "0.021291732788085938\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_S1T3UF1vhSk_0.mid\n",
      "0.03600335121154785\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HQ8ISDX6PiI_0.mid\n",
      "0.022121667861938477\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JT1XJnVmABo_5.mid\n",
      "0.01857161521911621\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_9eMxCs-LXCE_1.mid\n",
      "0.011736392974853516\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_YhXRyOl5pi0_0.mid\n",
      "0.02434682846069336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kfYaGryaGzI_1.mid\n",
      "0.006018400192260742\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GY3f6ckBVkA_3.mid\n",
      "0.021244287490844727\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iXiSFSGws-c_2.mid\n",
      "0.016444683074951172\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_WQrPcuy50aA_0.mid\n",
      "0.028095245361328125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Dg935IbDggo_2.mid\n",
      "0.029151439666748047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Dg935IbDggo_3.mid\n",
      "0.04963874816894531\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_wnB2cjd6zbE_0.mid\n",
      "0.035624027252197266\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_8c7kcmsnf-s_2.mid\n",
      "0.03349471092224121\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bIx4DwkZxFY_1.mid\n",
      "0.022831439971923828\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_08t73Qgjkt4_0.mid\n",
      "0.021741628646850586\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cm6E860vDjY_1.mid\n",
      "0.04186439514160156\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_5NW0zDu6IYM_0.mid\n",
      "0.024781227111816406\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JYVXM0qNQAg_2.mid\n",
      "0.02097606658935547\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_v3Nl5rUxLqE_0.mid\n",
      "0.013953208923339844\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ijfxkQPAQdE_1.mid\n",
      "0.07175016403198242\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UaYYMRkHMYc_2.mid\n",
      "0.02153325080871582\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1vjy9oMFa8c_0.mid\n",
      "0.02155900001525879\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__FVzelKlBFs_1.mid\n",
      "0.05067110061645508\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_MT2_mXn-vGU_2.mid\n",
      "0.015241622924804688\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_vVTP0DOL_2Q_2.mid\n",
      "0.020231008529663086\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6Uf9XBUD3wE_1.mid\n",
      "0.04822897911071777\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_4ydjOX3pWds_1.mid\n",
      "0.019487380981445312\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_28.mid\n",
      "0.02052164077758789\n",
      "data/emopia/EMOPIA_2.2/midis/Q3__S991V8N-8s_0.mid\n",
      "0.02550673484802246\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iXiSFSGws-c_0.mid\n",
      "0.01779937744140625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zmZHNy9T8Pg_1.mid\n",
      "0.03923177719116211\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3ahg_eQZhxs_0.mid\n",
      "0.02854323387145996\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__FVzelKlBFs_0.mid\n",
      "0.039861440658569336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_27.mid\n",
      "0.025951385498046875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_biROWEwkDQQ_0.mid\n",
      "0.017516136169433594\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_8.mid\n",
      "0.14680075645446777\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_sZe3IB1OVfw_1.mid\n",
      "0.020822525024414062\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_PXOWy7NiZhk_1.mid\n",
      "0.013731718063354492\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_REq37pDAm3A_2.mid\n",
      "0.014383554458618164\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tjno89OVuRI_0.mid\n",
      "0.014991998672485352\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_8c7kcmsnf-s_1.mid\n",
      "0.04032158851623535\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_2.mid\n",
      "0.025382041931152344\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_veG92Oi-DlU_1.mid\n",
      "0.017907381057739258\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3N2G21U7guk_6.mid\n",
      "0.02903604507446289\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_2v6gJi03LlA_1.mid\n",
      "0.024415969848632812\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_bfopzItCYrE_0.mid\n",
      "0.011821746826171875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_6oLmO9ZSJt0_0.mid\n",
      "0.03463459014892578\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_x4B0raxVODA_0.mid\n",
      "0.007539510726928711\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k4lT-sXg3iI_0.mid\n",
      "0.020870208740234375\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_5Ju9q1N2x0E_2.mid\n",
      "0.04367852210998535\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_0.mid\n",
      "0.01373434066772461\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_fuCxYrru2S4_2.mid\n",
      "0.0328977108001709\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_14.mid\n",
      "0.01700615882873535\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_d_49EtXDMFE_0.mid\n",
      "0.013979434967041016\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jTPXwbDtIpA_2.mid\n",
      "0.0426945686340332\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vpTguZtJAFA_0.mid\n",
      "0.014428377151489258\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_08t73Qgjkt4_1.mid\n",
      "0.01685190200805664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_22S3w4idugs_0.mid\n",
      "0.012080907821655273\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_TOXg4-ZGb-g_1.mid\n",
      "0.011046409606933594\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_13.mid\n",
      "0.05341386795043945\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_7JIdJLkJ0S4_0.mid\n",
      "0.02112269401550293\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_nGkpcWNAxDU_0.mid\n",
      "0.020182132720947266\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_-_FjI4bT2Wo_1.mid\n",
      "0.01947784423828125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_kDGmND1BgmA_0.mid\n",
      "0.007149696350097656\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_1.mid\n",
      "0.025638341903686523\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_9v2WSpn4FCw_9.mid\n",
      "0.01709747314453125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_G4rL_OtfFAU_0.mid\n",
      "0.033204078674316406\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ANZf1QXsNrY_6.mid\n",
      "0.022518157958984375\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rW1I58_lMEg_0.mid\n",
      "0.018039226531982422\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_48EYLEAgaBc_1.mid\n",
      "0.005792856216430664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Dw7M69CidJ8_2.mid\n",
      "0.03516077995300293\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UbKAl4roB8k_0.mid\n",
      "0.024247407913208008\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_2.mid\n",
      "0.015199899673461914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6kRPHamGDSo_1.mid\n",
      "0.017173051834106445\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_7.mid\n",
      "0.03626441955566406\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_f2BXXa7lPuE_1.mid\n",
      "0.0388493537902832\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_PK8YIUaV3Xw_0.mid\n",
      "0.017415761947631836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_prUUays30Mg_0.mid\n",
      "0.013278961181640625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_0vLPYiPN7qY_2.mid\n",
      "0.030718088150024414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FUAK5TBaNY8_3.mid\n",
      "0.014498710632324219\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zHwJG8Rrx6c_0.mid\n",
      "0.014072418212890625\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KxlqB3j0zys_3.mid\n",
      "0.024818897247314453\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0lEL_XHyhuU_1.mid\n",
      "0.012062311172485352\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_NGE9ynTJABg_1.mid\n",
      "0.019211530685424805\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pkz8OkWhwnk_0.mid\n",
      "0.013630151748657227\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_TOXg4-ZGb-g_0.mid\n",
      "0.01627516746520996\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_1.mid\n",
      "0.01328730583190918\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zmZHNy9T8Pg_2.mid\n",
      "0.021634340286254883\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_11.mid\n",
      "0.048171043395996094\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_2.mid\n",
      "0.018943309783935547\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_FfwKrQyQ7WU_0.mid\n",
      "0.024201154708862305\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_02t1bj7ZABY_0.mid\n",
      "0.006687164306640625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_REq37pDAm3A_4.mid\n",
      "0.02265167236328125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_0.mid\n",
      "0.01633429527282715\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ADJ_PDauy-g_2.mid\n",
      "0.01624464988708496\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_IH2KrGjKXw0_0.mid\n",
      "0.013032197952270508\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZTrEoB8T9YA_1.mid\n",
      "0.018305063247680664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_7yW9c7t8Hq0_0.mid\n",
      "0.010822296142578125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_YAAxPW1GB7w_0.mid\n",
      "0.012215137481689453\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_2.mid\n",
      "0.014312028884887695\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D-gDPh9ZpFk_0.mid\n",
      "0.026535987854003906\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OyaY4213c2A_1.mid\n",
      "0.01460719108581543\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_QmK_SND2jAw_0.mid\n",
      "0.025162458419799805\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_3.mid\n",
      "0.02069377899169922\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_XC_SiJszQx0_3.mid\n",
      "0.03205513954162598\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_NTI9ode6bRk_0.mid\n",
      "0.015911340713500977\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8rupdevqfuI_0.mid\n",
      "0.026017427444458008\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_8.mid\n",
      "0.019956111907958984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vJ77eDxHezE_0.mid\n",
      "0.028368234634399414\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_KxlqB3j0zys_0.mid\n",
      "0.015409231185913086\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_rEz0D3VohFA_0.mid\n",
      "0.007824897766113281\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_BzqX-9TA-GY_1.mid\n",
      "0.011504888534545898\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_fnqb8zqHqdY_2.mid\n",
      "0.016157865524291992\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_aYe-2Glruu4_1.mid\n",
      "0.0379488468170166\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_PdwxeMPXOCk_2.mid\n",
      "0.030513525009155273\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_DX1IK3z1w10_1.mid\n",
      "0.028864622116088867\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_By3JCii1k3w_0.mid\n",
      "0.018015384674072266\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_2.mid\n",
      "0.015273571014404297\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rW1I58_lMEg_3.mid\n",
      "0.02477431297302246\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UAm0aWvzFI8_0.mid\n",
      "0.04458761215209961\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_4.mid\n",
      "0.02116227149963379\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_sZe3IB1OVfw_0.mid\n",
      "0.020400285720825195\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_XfA2KXodrOE_1.mid\n",
      "0.03364896774291992\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_15.mid\n",
      "0.029819011688232422\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_0.mid\n",
      "0.040435791015625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_qlbazHayULg_8.mid\n",
      "0.04277157783508301\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_7JIdJLkJ0S4_1.mid\n",
      "0.028766155242919922\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FoTXpYZXxJs_1.mid\n",
      "0.011702775955200195\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_--2B4d4lQhs_0.mid\n",
      "0.04055523872375488\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Y5JcZQ0xg4Y_2.mid\n",
      "0.02646493911743164\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rDhbGjFlKF8_1.mid\n",
      "0.012852668762207031\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_4.mid\n",
      "0.0282595157623291\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ldCQ6N9G6Mk_0.mid\n",
      "0.005883216857910156\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_TNoaOTrTkTQ_0.mid\n",
      "0.03590559959411621\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_38i12IPkL5c_0.mid\n",
      "0.02545166015625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_X1p8xcarVu0_1.mid\n",
      "0.015951156616210938\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UpHutdJvZMI_2.mid\n",
      "0.01971578598022461\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_V3Y9L4UOcpk_0.mid\n",
      "0.01637125015258789\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_20.mid\n",
      "0.019965171813964844\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_osxmQReE_2o_0.mid\n",
      "0.026683568954467773\n",
      "data/emopia/EMOPIA_2.2/midis/Q4__BK2o77sTc0_2.mid\n",
      "0.025283098220825195\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_4dXC1cC7crw_0.mid\n",
      "0.023073911666870117\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_QJlnTN7HRwE_2.mid\n",
      "0.01004648208618164\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pRuwHN-lI44_1.mid\n",
      "0.016243934631347656\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_q4T8Znozvkk_0.mid\n",
      "0.012303829193115234\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UaYYMRkHMYc_1.mid\n",
      "0.0409550666809082\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_4.mid\n",
      "0.01256704330444336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_-jJVb0xvbdg_1.mid\n",
      "0.030969619750976562\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_23.mid\n",
      "0.020420551300048828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_94ROf10d1iA_3.mid\n",
      "0.028017282485961914\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_6.mid\n",
      "0.02620410919189453\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FSzOgraSKhs_0.mid\n",
      "0.011304616928100586\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lTxVVdhFE6Q_1.mid\n",
      "0.018702268600463867\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_4.mid\n",
      "0.017719268798828125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_170KC2CbJ7Y_0.mid\n",
      "0.020656108856201172\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zHwJG8Rrx6c_2.mid\n",
      "0.02992558479309082\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_4.mid\n",
      "0.04010939598083496\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_yC0fAQxGgr0_1.mid\n",
      "0.16623926162719727\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zMa78n8ULtE_0.mid\n",
      "0.011265993118286133\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UaYYMRkHMYc_0.mid\n",
      "0.04286026954650879\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_FfwKrQyQ7WU_2.mid\n",
      "0.017569780349731445\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cQp1BYDGcRo_0.mid\n",
      "0.036467552185058594\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_xgtwQGeB6_0_0.mid\n",
      "0.020773887634277344\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_hoPp_GLXQis_0.mid\n",
      "0.02497124671936035\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_RaUSISlnhKw_1.mid\n",
      "0.03759193420410156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ury1cdB79s0_1.mid\n",
      "0.024326324462890625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zvWX_dwQPtU_2.mid\n",
      "0.02547430992126465\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_IH2KrGjKXw0_1.mid\n",
      "0.019875526428222656\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iHPKusssXzk_0.mid\n",
      "0.020337581634521484\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_kKFwiXKlhC8_0.mid\n",
      "0.022918224334716797\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k4lT-sXg3iI_1.mid\n",
      "0.020982980728149414\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltxNPJda7zE_0.mid\n",
      "0.008591651916503906\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XWk5XUEBXmg_1.mid\n",
      "0.017377376556396484\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_yC0fAQxGgr0_0.mid\n",
      "0.015224695205688477\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tjno89OVuRI_1.mid\n",
      "0.01910567283630371\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ldCQ6N9G6Mk_3.mid\n",
      "0.017802000045776367\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_3ZnxqCZ7qGg_2.mid\n",
      "0.02301168441772461\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_biROWEwkDQQ_1.mid\n",
      "0.022293806076049805\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_6.mid\n",
      "0.032105207443237305\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_cXxGBDgFCs8_1.mid\n",
      "0.013193845748901367\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_E5qEloUO3SM_1.mid\n",
      "0.016746997833251953\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_uqRLEByE6pU_1.mid\n",
      "0.015479564666748047\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_aYe-2Glruu4_3.mid\n",
      "0.021929264068603516\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_48EYLEAgaBc_0.mid\n",
      "0.007839441299438477\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_yFw_kO7DF-Y_2.mid\n",
      "0.04207277297973633\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_k6aLLVX1D7Y_2.mid\n",
      "0.017728567123413086\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_bfopzItCYrE_2.mid\n",
      "0.016879558563232422\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_29.mid\n",
      "0.00724029541015625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ItGNJM6skM4_0.mid\n",
      "0.03922390937805176\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JP3QKZlyQz4_1.mid\n",
      "0.011263608932495117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_GbUV3TXUzeQ_0.mid\n",
      "0.02058887481689453\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_T92R7xjce34_0.mid\n",
      "0.018323421478271484\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D5kyjnlDNZs_1.mid\n",
      "0.03426933288574219\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jIKX3ShvLxo_2.mid\n",
      "0.046334266662597656\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_26.mid\n",
      "0.02079033851623535\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_REq37pDAm3A_1.mid\n",
      "0.019489288330078125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_iRu9KQvbtVw_0.mid\n",
      "0.020598173141479492\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_2.mid\n",
      "0.05038619041442871\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Y1F0c3zgMJo_0.mid\n",
      "0.015941619873046875\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_BIRDDxz0E4c_0.mid\n",
      "0.01422119140625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_pouxqiySdI8_0.mid\n",
      "0.026469707489013672\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_3.mid\n",
      "0.04094099998474121\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_0.mid\n",
      "0.02400374412536621\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FOcdHIhI0_s_0.mid\n",
      "0.010102510452270508\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ijfxkQPAQdE_0.mid\n",
      "0.06112265586853027\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_uUtnyA6tLnI_0.mid\n",
      "0.025580167770385742\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_aQ4PIaRMLwE_2.mid\n",
      "0.028672456741333008\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_SQDuF0qxGQw_0.mid\n",
      "0.021081924438476562\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_k6aLLVX1D7Y_0.mid\n",
      "0.025002241134643555\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8rupdevqfuI_2.mid\n",
      "0.017187118530273438\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_94ROf10d1iA_1.mid\n",
      "0.014952421188354492\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yZGBxiNPu3k_0.mid\n",
      "0.030650854110717773\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_pbVGv_g4n50_0.mid\n",
      "0.007449150085449219\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6kRPHamGDSo_0.mid\n",
      "0.017357826232910156\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1Qc15G0ZHIg_2.mid\n",
      "0.031012773513793945\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_JNzqL24ZcZ8_1.mid\n",
      "0.019648313522338867\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_a5QCcwEjxAk_1.mid\n",
      "0.012943506240844727\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_heBmBQDWj-M_0.mid\n",
      "0.01933741569519043\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_UE0y8MHqT-g_0.mid\n",
      "0.016744136810302734\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JYVXM0qNQAg_0.mid\n",
      "0.021421432495117188\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_DYBBfpEx-JI_4.mid\n",
      "0.01763749122619629\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bIx4DwkZxFY_2.mid\n",
      "0.016993284225463867\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S7Bo4-NCEDk_0.mid\n",
      "0.04433608055114746\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Uu-oRTRT6uQ_2.mid\n",
      "0.023729801177978516\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_--2B4d4lQhs_3.mid\n",
      "0.016470670700073242\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8izVTDgBQPc_1.mid\n",
      "0.023166894912719727\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_o5AIp2Yc01M_0.mid\n",
      "0.02954721450805664\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_9Xg69XrVaYU_0.mid\n",
      "0.020586729049682617\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_OO7zYVeK814_0.mid\n",
      "0.01334691047668457\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_nGkpcWNAxDU_1.mid\n",
      "0.026541948318481445\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_NzJjMGJg1wE_0.mid\n",
      "0.016768693923950195\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jO2zX6Ul8GM_2.mid\n",
      "0.025255680084228516\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TonQX8XbvX8_3.mid\n",
      "0.015757322311401367\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_1.mid\n",
      "0.026082515716552734\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_bbU31JLtlug_0.mid\n",
      "0.02829718589782715\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e838BE_MH6s_2.mid\n",
      "0.03133988380432129\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Wy2-my19YnY_0.mid\n",
      "0.02477288246154785\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_0vLPYiPN7qY_0.mid\n",
      "0.014719724655151367\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HYVmgq5Y93g_1.mid\n",
      "0.01787281036376953\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yhIncZ_Ue4E_1.mid\n",
      "0.016263246536254883\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_3.mid\n",
      "0.018945932388305664\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_18.mid\n",
      "0.01832294464111328\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5Ju9q1N2x0E_0.mid\n",
      "0.024570941925048828\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_G4rL_OtfFAU_1.mid\n",
      "0.061107635498046875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_6kRPHamGDSo_2.mid\n",
      "0.01684284210205078\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zjr_-ql5Avk_2.mid\n",
      "0.006360292434692383\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_2uLw9Zs60A4_0.mid\n",
      "0.022872209548950195\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_14.mid\n",
      "0.015725374221801758\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_yFw_kO7DF-Y_0.mid\n",
      "0.03177237510681152\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_egYSmNuIFGk_1.mid\n",
      "0.018740415573120117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vJ77eDxHezE_1.mid\n",
      "0.025709152221679688\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_5.mid\n",
      "0.03055286407470703\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_4.mid\n",
      "0.03182053565979004\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_RL_cmmNVLfs_0.mid\n",
      "0.014027595520019531\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1Q3MoBFh6eU_1.mid\n",
      "0.03161025047302246\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Iq6g_4AwUWs_1.mid\n",
      "0.02314138412475586\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JT1XJnVmABo_4.mid\n",
      "0.017687559127807617\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ANZf1QXsNrY_7.mid\n",
      "0.039252519607543945\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_xIsvaT20pZ0_0.mid\n",
      "0.017690181732177734\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_gvWDOIiocuE_1.mid\n",
      "0.028208255767822266\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_9v2WSpn4FCw_1.mid\n",
      "0.013762950897216797\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zmZHNy9T8Pg_0.mid\n",
      "0.021767616271972656\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JT1XJnVmABo_0.mid\n",
      "0.01803445816040039\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_iFgSjUqI7iM_1.mid\n",
      "0.021699905395507812\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zMa78n8ULtE_1.mid\n",
      "0.009125709533691406\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_2.mid\n",
      "0.017414093017578125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jSWItJI-Gmk_0.mid\n",
      "0.016196012496948242\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__8v0MFBZoco_1.mid\n",
      "0.03833746910095215\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_6n8HgIcJ6vo_0.mid\n",
      "0.013530731201171875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_3.mid\n",
      "0.04034113883972168\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1vjy9oMFa8c_1.mid\n",
      "0.009788751602172852\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_4.mid\n",
      "0.01784968376159668\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3N2G21U7guk_3.mid\n",
      "0.03365206718444824\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wS0RzrBL9UI_1.mid\n",
      "0.013926506042480469\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0vLPYiPN7qY_3.mid\n",
      "0.032720327377319336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S1T3UF1vhSk_2.mid\n",
      "0.020815372467041016\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_JT1XJnVmABo_1.mid\n",
      "0.01982712745666504\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_1.mid\n",
      "0.010056257247924805\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s6-SbDSZzEU_1.mid\n",
      "0.02230691909790039\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ItGNJM6skM4_2.mid\n",
      "0.05176997184753418\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_lFznCt5kvXM_0.mid\n",
      "0.17113542556762695\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_aYe-2Glruu4_0.mid\n",
      "0.02773737907409668\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_fey-8bOR95E_3.mid\n",
      "0.033780813217163086\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1kny88W533Q_0.mid\n",
      "0.011656522750854492\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_a5QCcwEjxAk_0.mid\n",
      "0.015618085861206055\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FUAK5TBaNY8_2.mid\n",
      "0.018277883529663086\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e838BE_MH6s_4.mid\n",
      "0.03477215766906738\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_u_7b9CwyM8Q_1.mid\n",
      "0.012969017028808594\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_REq37pDAm3A_0.mid\n",
      "0.01067352294921875\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_0.mid\n",
      "0.018640995025634766\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_WpZ1rWHOCAQ_1.mid\n",
      "0.015071868896484375\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_3.mid\n",
      "0.01659989356994629\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S1T3UF1vhSk_1.mid\n",
      "0.013263225555419922\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_3.mid\n",
      "0.020903587341308594\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_4.mid\n",
      "0.07279086112976074\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_-vAz_HTFEXs_1.mid\n",
      "0.018204689025878906\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_fey-8bOR95E_2.mid\n",
      "0.027713537216186523\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_aYe-2Glruu4_2.mid\n",
      "0.03206801414489746\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_sEQf5lcnj_o_3.mid\n",
      "0.05372810363769531\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_mGYKWCVnMwQ_0.mid\n",
      "0.019495487213134766\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_J6X3rVU1H-c_2.mid\n",
      "0.033284902572631836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_32.mid\n",
      "0.016774415969848633\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JT1XJnVmABo_2.mid\n",
      "0.01141810417175293\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_oTi57hZfArE_2.mid\n",
      "0.013158082962036133\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Y5JcZQ0xg4Y_0.mid\n",
      "0.00972604751586914\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HQ8ISDX6PiI_1.mid\n",
      "0.017040014266967773\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iXiSFSGws-c_1.mid\n",
      "0.018665552139282227\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Dw7M69CidJ8_3.mid\n",
      "0.007706403732299805\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3N2G21U7guk_0.mid\n",
      "0.008187294006347656\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_pNwQ9Tu_bCs_0.mid\n",
      "0.02018260955810547\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bQS8eAXAhyE_1.mid\n",
      "0.016230106353759766\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_P-We4q3goKU_0.mid\n",
      "0.016858339309692383\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jNzZCplNNyY_1.mid\n",
      "0.023369550704956055\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltxNPJda7zE_4.mid\n",
      "0.0074427127838134766\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ii1Jw1-7Ka4_0.mid\n",
      "0.0058557987213134766\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UOSlDydo94E_2.mid\n",
      "0.026472806930541992\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Cir1kZyB7QM_1.mid\n",
      "0.01000356674194336\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_11.mid\n",
      "0.017725706100463867\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_vVTP0DOL_2Q_0.mid\n",
      "0.013685464859008789\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_HY9vPoHbgaI_0.mid\n",
      "0.015749454498291016\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__SJQaaRzD-A_0.mid\n",
      "0.016425609588623047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_lalnGhxT3PQ_1.mid\n",
      "0.03780388832092285\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_10.mid\n",
      "0.03444099426269531\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_1.mid\n",
      "0.021108627319335938\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_9Xg69XrVaYU_1.mid\n",
      "0.02050042152404785\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__BK2o77sTc0_0.mid\n",
      "0.02559685707092285\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_gSwv8hZGM-s_1.mid\n",
      "0.0233156681060791\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_OCqMDeD6Fmc_2.mid\n",
      "0.04792904853820801\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_MbvPxCUMSek_1.mid\n",
      "0.008222579956054688\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_DvIH5yUrboc_2.mid\n",
      "0.025022506713867188\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3N2G21U7guk_2.mid\n",
      "0.00776219367980957\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_kKFwiXKlhC8_1.mid\n",
      "0.04657626152038574\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_lalnGhxT3PQ_0.mid\n",
      "0.03518414497375488\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_QBJ6YYYpIyk_0.mid\n",
      "0.014401912689208984\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_sEQf5lcnj_o_1.mid\n",
      "0.04932594299316406\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_UuLTvhERcnk_1.mid\n",
      "0.020733356475830078\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_epX33OVpkmA_0.mid\n",
      "0.04284834861755371\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_fnqb8zqHqdY_0.mid\n",
      "0.01438760757446289\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_kopwU6zpS4k_0.mid\n",
      "0.010619401931762695\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_WpZ1rWHOCAQ_2.mid\n",
      "0.026778697967529297\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Q5b5unyP8BM_1.mid\n",
      "0.049842119216918945\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jIKX3ShvLxo_0.mid\n",
      "0.027041196823120117\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_AWNbcxXDmt0_0.mid\n",
      "0.030852317810058594\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_gSwv8hZGM-s_0.mid\n",
      "0.039288997650146484\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S7Bo4-NCEDk_2.mid\n",
      "0.019518613815307617\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_I2MrA-o5H8I_0.mid\n",
      "0.025005340576171875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GY3f6ckBVkA_2.mid\n",
      "0.029027938842773438\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FyK_c-TIcCA_1.mid\n",
      "0.028798818588256836\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_3_MxhSS86oU_1.mid\n",
      "0.04244661331176758\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0J7lX-Tcx-w_1.mid\n",
      "0.03827667236328125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_2eIsQtm4YNs_0.mid\n",
      "0.016964435577392578\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_GAvPwG2wYZM_0.mid\n",
      "0.010647296905517578\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Fc1qk52SaKY_1.mid\n",
      "0.027898550033569336\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_mX-xs3OVhTs_0.mid\n",
      "0.01615619659423828\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__S991V8N-8s_1.mid\n",
      "0.026959896087646484\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_--2B4d4lQhs_2.mid\n",
      "0.048056840896606445\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_yFw_kO7DF-Y_1.mid\n",
      "0.028357982635498047\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_1.mid\n",
      "0.01896977424621582\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_gwmVjvR-sVs_2.mid\n",
      "0.008741378784179688\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KxlqB3j0zys_2.mid\n",
      "0.02000260353088379\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_25.mid\n",
      "0.02339649200439453\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s5b8viFsVJE_0.mid\n",
      "0.03052496910095215\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_miqLU2739dk_1.mid\n",
      "0.04010510444641113\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_0vLPYiPN7qY_1.mid\n",
      "0.03676104545593262\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_V3Y9L4UOcpk_2.mid\n",
      "0.028831005096435547\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_gvWDOIiocuE_0.mid\n",
      "0.017772436141967773\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_nOIBJHkqrE8_0.mid\n",
      "0.021120071411132812\n"
     ]
    }
   ],
   "source": [
    "encoded_sequences_path = \"data/encoded_sequences.pkl\"\n",
    "encoded_sequences = midi_encoder.encode_midi_list(midi_files_list, pkl_path=encoded_sequences_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the dataset and save it in a NumPy file\n",
    "dataset_path = \"data/datasets/\"\n",
    "midi_encoder_remi.save_dataset(midi_files_list, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:696: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset as a single file\n",
    "single_file_dataset_path = \"data/single_file_dataset.npz\"\n",
    "midi_encoder_remi.save_dataset_as_single_file(glob.glob(os.path.join(dataset_path, '*.npy')), single_file_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ece661-final-proj2/data/dataset.py:170: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  self.sequences = torch.Tensor(self.sequences)\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 256\n",
    "dataset = TransformerDatasetREMI(single_file_dataset_path, seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': tensor([0]), 'input': tensor([  2,   3,   4,   5,  49, 162,  85, 123,  49, 163,  18,  61,  49, 163,\n",
      "         21, 151,  49, 163, 142,  83,   6, 174,  18,  61,   6, 174, 142,  19,\n",
      "         12, 148, 142,  15,  16, 146,  18,  15,  20, 163, 142, 141,  39, 163,\n",
      "         18,  15,  43, 176,  18,  15,  46, 176,  18,  72,  48, 146,  51, 136,\n",
      "         48, 100,  35, 179,   2,  62, 163,  18,  61,   6, 146,  18,  15,  12,\n",
      "        163,  18,  15,  39, 176,  18,  15,  57, 148, 142, 157,  43, 146,  18,\n",
      "         72,  26, 176,  51, 135,  46, 154,  85, 143,  46, 154,  21, 141,  46,\n",
      "        146, 115,  32,   2,   3, 162,  18,  15,  49, 176, 122,  32,  62, 163,\n",
      "         18,  61,   6, 162,  18,  15,  16, 176,  18,  61,  39, 176,  18,  61,\n",
      "         57, 176,  51, 116,  26, 162,  18,  83,  26, 176, 102,  32,  26, 100,\n",
      "         35, 173,  48, 146,  18,  15,   2,  49, 163,  18,  61,  49, 148, 115,\n",
      "         32,  81, 163,  18,  15,  81, 148,  51,  72,  12, 174,  18,  61,  20,\n",
      "        176,  18,  61,  20, 148,  51,  83,  20, 174, 115, 137,  57, 174, 142,\n",
      "         69,  43, 162,  18,  83,  43, 149,  85, 133,  43, 149,  21,  83,  43,\n",
      "        176, 142,  72,  43, 146,  51, 135,  59, 162,  18,  15,  59, 163,  21,\n",
      "         72,  48, 148, 142,  72,   2,   3, 176,  18,  61,  62, 146,  18,  15,\n",
      "         81, 174,  21,  80,  81, 174, 115,  50,   6, 148, 142,  83,  34, 162,\n",
      "         18,  15,  16, 100,  35,  24,  16, 176, 142,  64,  16, 146,  18,  83,\n",
      "         39, 146,  51, 161]), 'target': tensor([  3,   4,   5,  49, 162,  85, 123,  49, 163,  18,  61,  49, 163,  21,\n",
      "        151,  49, 163, 142,  83,   6, 174,  18,  61,   6, 174, 142,  19,  12,\n",
      "        148, 142,  15,  16, 146,  18,  15,  20, 163, 142, 141,  39, 163,  18,\n",
      "         15,  43, 176,  18,  15,  46, 176,  18,  72,  48, 146,  51, 136,  48,\n",
      "        100,  35, 179,   2,  62, 163,  18,  61,   6, 146,  18,  15,  12, 163,\n",
      "         18,  15,  39, 176,  18,  15,  57, 148, 142, 157,  43, 146,  18,  72,\n",
      "         26, 176,  51, 135,  46, 154,  85, 143,  46, 154,  21, 141,  46, 146,\n",
      "        115,  32,   2,   3, 162,  18,  15,  49, 176, 122,  32,  62, 163,  18,\n",
      "         61,   6, 162,  18,  15,  16, 176,  18,  61,  39, 176,  18,  61,  57,\n",
      "        176,  51, 116,  26, 162,  18,  83,  26, 176, 102,  32,  26, 100,  35,\n",
      "        173,  48, 146,  18,  15,   2,  49, 163,  18,  61,  49, 148, 115,  32,\n",
      "         81, 163,  18,  15,  81, 148,  51,  72,  12, 174,  18,  61,  20, 176,\n",
      "         18,  61,  20, 148,  51,  83,  20, 174, 115, 137,  57, 174, 142,  69,\n",
      "         43, 162,  18,  83,  43, 149,  85, 133,  43, 149,  21,  83,  43, 176,\n",
      "        142,  72,  43, 146,  51, 135,  59, 162,  18,  15,  59, 163,  21,  72,\n",
      "         48, 148, 142,  72,   2,   3, 176,  18,  61,  62, 146,  18,  15,  81,\n",
      "        174,  21,  80,  81, 174, 115,  50,   6, 148, 142,  83,  34, 162,  18,\n",
      "         15,  16, 100,  35,  24,  16, 176, 142,  64,  16, 146,  18,  83,  39,\n",
      "        146,  51, 161,  57]), 'input_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'target_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "for data in dataset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))\n",
    "valid_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  3507\n",
      "Validation dataset size:  751\n",
      "Test dataset size:  753\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size: \", len(train_dataset))\n",
    "print(\"Validation dataset size: \", len(valid_dataset))\n",
    "print(\"Test dataset size: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  54\n",
      "Validation dataset size:  11\n",
      "Test dataset size:  11\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "print(\"Train dataset size: \", len(train_dataloader))\n",
    "print(\"Validation dataset size: \", len(valid_dataloader))\n",
    "print(\"Test dataset size: \", len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = set()\n",
    "for dic in train_dataset:\n",
    "    ipt = dic['input'].numpy()\n",
    "    vocab_set = vocab_set.union(set(ipt))\n",
    "vocab_size = len(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.trainer import TransformerTrainer\n",
    "from model.transformer import Generator, Discriminator, PatchDiscriminator\n",
    "from utils.losses import MultiCrossEntropyLoss, TransfoCrossEntropyLoss,TransfoL1Loss, wgan_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(vocab_size, max_seq_len, dim=256)\n",
    "discriminator = Discriminator(vocab_size, max_seq_len, dim=256)\n",
    "patch_discriminator = PatchDiscriminator(vocab_size, max_seq_len, dim=256)\n",
    "\n",
    "ce_loss = TransfoCrossEntropyLoss()\n",
    "gan_loss = wgan_loss\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "patch_discriminator.to(device)\n",
    "\n",
    "g_lr = 1e-4\n",
    "d_lr = 1e-4\n",
    "\n",
    "EPOCHS = 10\n",
    "checkpoint_dir = \"checkpoints/model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TransformerTrainer(generator, patch_discriminator, train_dataloader, train_dataloader, test_dataloader, ce_loss,\n",
    "               gan_loss, device, g_lr, d_lr, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/ece661-final-proj2/utils/trainer.py:375\u001b[0m, in \u001b[0;36mTransformerTrainer.train\u001b[0;34m(self, EPOCHS, checkpoint_dir, validate, log_interval, load, save, train_gan)\u001b[0m\n\u001b[1;32m    373\u001b[0m   train_acc, train_loss, train_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_epoch(log_interval\u001b[38;5;241m=\u001b[39mlog_interval) \n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 375\u001b[0m   train_acc, train_loss, train_losses, d_losses, g_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_acc)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "File \u001b[0;32m/workspaces/ece661-final-proj2/utils/trainer.py:286\u001b[0m, in \u001b[0;36mTransformerTrainer.train_epoch_gan\u001b[0;34m(self, log_interval)\u001b[0m\n\u001b[1;32m    280\u001b[0m inverse_temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_inverse_temperature()\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m######\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m#MLE\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m######     \u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m fake,_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_mle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconds_mle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_temperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minverse_temperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_mask_mle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m mle_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mce_loss(fake, target_mle, loss_mask\u001b[38;5;241m=\u001b[39mtarget_mask_mle)  \n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m#mle_grads = torch.autograd.grad(mle_loss, self.generator.get_last_layer(), retain_graph=True)[0]\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[38;5;66;03m#FP16       \u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/ece661-final-proj2/model/transformer.py:143\u001b[0m, in \u001b[0;36mGenerator.forward\u001b[0;34m(self, inputs, cond, inverse_temperature, input_mask)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cond_layer, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcond_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer):\n\u001b[1;32m    138\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m  if cond != None:\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    cond_proj = cond_layer(cond_emb).unsqueeze(1)\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    #x = x + cond_proj  \u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m  '''\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlength_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, pos_emb = layer_pos_emb, **kwargs)\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# norm and to logits\u001b[39;00m\n\u001b[1;32m    146\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x, cond)\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/ece661-final-proj2/model/attention.py:323\u001b[0m, in \u001b[0;36mRelativeTransformerEncoderLayer.forward\u001b[0;34m(self, x, attn_mask, length_mask, rotary, cond)\u001b[0m\n\u001b[1;32m    318\u001b[0m length_mask \u001b[38;5;241m=\u001b[39m length_mask \u001b[38;5;129;01mor\u001b[39;00m \\\n\u001b[1;32m    319\u001b[0m     LengthMask(x\u001b[38;5;241m.\u001b[39mnew_full((N,), L, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64))\n\u001b[1;32m    322\u001b[0m \u001b[38;5;66;03m# Run self attention and add it to the input\u001b[39;00m\n\u001b[0;32m--> 323\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrotary\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrotary\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# Run the fully connected part of the layer\u001b[39;00m\n\u001b[1;32m    332\u001b[0m y \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x) \u001b[38;5;28;01mif\u001b[39;00m cond \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x, cond)\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/ece661-final-proj2/model/attention.py:250\u001b[0m, in \u001b[0;36mRelativeAttentionLayerGen.forward\u001b[0;34m(self, queries, keys, values, attn_mask, query_lengths, key_lengths, rotary)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevent_dispatcher\u001b[38;5;241m.\u001b[39mdispatch(QKVEvent(\u001b[38;5;28mself\u001b[39m, queries, keys, values))\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# Compute the attention\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_lengths\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(N, L, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# Project the output and return\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_projection(new_values)\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/fast_transformers/attention/causal_linear_attention.py:98\u001b[0m, in \u001b[0;36mCausalLinearAttention.forward\u001b[0;34m(self, queries, keys, values, attn_mask, query_lengths, key_lengths)\u001b[0m\n\u001b[1;32m     95\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlhi,nlhi->nlh\u001b[39m\u001b[38;5;124m\"\u001b[39m, Q, K\u001b[38;5;241m.\u001b[39mcumsum(\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Compute the unnormalized result\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m V \u001b[38;5;241m=\u001b[39m \u001b[43mcausal_linear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m V \u001b[38;5;241m*\u001b[39m Z[:, :, :, \u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/fast_transformers/attention/causal_linear_attention.py:23\u001b[0m, in \u001b[0;36mcausal_linear\u001b[0;34m(Q, K, V)\u001b[0m\n\u001b[1;32m     21\u001b[0m K \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m     22\u001b[0m V \u001b[38;5;241m=\u001b[39m V\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m---> 23\u001b[0m V_new \u001b[38;5;241m=\u001b[39m \u001b[43mcausal_dot_product\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m V_new\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/torch/autograd/function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m     )\n",
      "File \u001b[0;32m~/venv/lib/python3.8/site-packages/fast_transformers/causal_product/__init__.py:44\u001b[0m, in \u001b[0;36mCausalDotProduct.forward\u001b[0;34m(ctx, Q, K, V)\u001b[0m\n\u001b[1;32m     41\u001b[0m product \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((N, H, L, M), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Actually perform the dot product\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mCausalDotProduct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mQ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproduct\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m product\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "hist = trainer.train( EPOCHS, checkpoint_dir, validate = False, log_interval=20, load=False, save=True, train_gan=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's\n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "\n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and put it into features\n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, :len(row)] = np.array(row)[:seq_length]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length, dropout=0.1):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, max_seq_length: int, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_seq_length, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if src_mask is None:\n",
    "            \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
    "            Unmasked positions are filled with float(0.0).\n",
    "            \"\"\"\n",
    "            src_mask = nn.Transformer.generate_square_subsequent_mask(len(src)).to(device)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/venv/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "ntokens = vocab_size  # size of vocabulary\n",
    "emsize = 256  # embedding dimension\n",
    "d_hid = 512  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 6  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 8  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.1  # dropout probability\n",
    "max_seq_length = max_seq_len\n",
    "model = TransformerModel(max_seq_len, ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (embedding): Embedding(198, 256)\n",
      "  (linear): Linear(in_features=256, out_features=198, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001  # learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "epochs = 100  # The number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stopping(val_loss, epoch,best_loss,epochs_no_improve, patience=10):\n",
    "    if epoch == 0:\n",
    "        torch.save(model.state_dict(), 'checkpoints/transformer_v3.pt')\n",
    "        best_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        return False, best_loss, epochs_no_improve\n",
    "    else:\n",
    "        if val_loss < best_loss:\n",
    "            torch.save(model.state_dict(), 'checkpoints/transformer_v3.pt')\n",
    "            print(f\"Saved model at epoch { epoch } with validation loss of {val_loss}\")\n",
    "            best_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            return False, best_loss, epochs_no_improve\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print('Early stopping!')\n",
    "                return True, best_loss, epochs_no_improve\n",
    "            else:\n",
    "                return False, best_loss, epochs_no_improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0 / 100 ]; TrainLoss: 4.52584; ValidLoss: 4.20107\n",
      "Epoch: [ 1 / 100 ]; TrainLoss: 4.14059; ValidLoss: 3.39065\n",
      "Saved model at epoch 1 with validation loss of 3.390649448741566\n",
      "Epoch: [ 2 / 100 ]; TrainLoss: 3.02736; ValidLoss: 2.94471\n",
      "Saved model at epoch 2 with validation loss of 2.944707675413652\n",
      "Epoch: [ 3 / 100 ]; TrainLoss: 2.94839; ValidLoss: 2.91572\n",
      "Saved model at epoch 3 with validation loss of 2.915718750520186\n",
      "Epoch: [ 4 / 100 ]; TrainLoss: 2.93372; ValidLoss: 2.91148\n",
      "Saved model at epoch 4 with validation loss of 2.9114806868813257\n",
      "Epoch: [ 5 / 100 ]; TrainLoss: 2.92010; ValidLoss: 2.89715\n",
      "Saved model at epoch 5 with validation loss of 2.897148002277721\n",
      "Epoch: [ 6 / 100 ]; TrainLoss: 2.91655; ValidLoss: 2.89655\n",
      "Saved model at epoch 6 with validation loss of 2.8965542316436768\n",
      "Epoch: [ 7 / 100 ]; TrainLoss: 2.91568; ValidLoss: 2.89617\n",
      "Saved model at epoch 7 with validation loss of 2.896171049638228\n",
      "Epoch: [ 8 / 100 ]; TrainLoss: 2.91481; ValidLoss: 2.89574\n",
      "Saved model at epoch 8 with validation loss of 2.895742416381836\n",
      "Epoch: [ 9 / 100 ]; TrainLoss: 2.91405; ValidLoss: 2.89542\n",
      "Saved model at epoch 9 with validation loss of 2.8954169750213623\n",
      "Epoch: [ 10 / 100 ]; TrainLoss: 2.91241; ValidLoss: 2.89388\n",
      "Saved model at epoch 10 with validation loss of 2.893877376209606\n",
      "Epoch: [ 11 / 100 ]; TrainLoss: 2.91167; ValidLoss: 2.89367\n",
      "Saved model at epoch 11 with validation loss of 2.8936675028367476\n",
      "Epoch: [ 12 / 100 ]; TrainLoss: 2.91156; ValidLoss: 2.89358\n",
      "Saved model at epoch 12 with validation loss of 2.8935806534507056\n",
      "Epoch: [ 13 / 100 ]; TrainLoss: 2.91125; ValidLoss: 2.89353\n",
      "Saved model at epoch 13 with validation loss of 2.893526315689087\n",
      "Epoch: [ 14 / 100 ]; TrainLoss: 2.91128; ValidLoss: 2.89348\n",
      "Saved model at epoch 14 with validation loss of 2.8934763344851406\n",
      "Epoch: [ 15 / 100 ]; TrainLoss: 2.91109; ValidLoss: 2.89348\n",
      "Epoch: [ 16 / 100 ]; TrainLoss: 2.91107; ValidLoss: 2.89348\n",
      "Epoch: [ 17 / 100 ]; TrainLoss: 2.91084; ValidLoss: 2.89348\n",
      "Epoch: [ 18 / 100 ]; TrainLoss: 2.91098; ValidLoss: 2.89348\n",
      "Epoch: [ 19 / 100 ]; TrainLoss: 2.91104; ValidLoss: 2.89348\n",
      "Epoch: [ 20 / 100 ]; TrainLoss: 2.91100; ValidLoss: 2.89348\n",
      "Epoch: [ 21 / 100 ]; TrainLoss: 2.91069; ValidLoss: 2.89348\n",
      "Epoch: [ 22 / 100 ]; TrainLoss: 2.91093; ValidLoss: 2.89348\n",
      "Epoch: [ 23 / 100 ]; TrainLoss: 2.91110; ValidLoss: 2.89348\n",
      "Epoch: [ 24 / 100 ]; TrainLoss: 2.91094; ValidLoss: 2.89348\n",
      "Early stopping!\n",
      "Training complete!\n",
      "Best loss:  2.8934763344851406\n"
     ]
    }
   ],
   "source": [
    "# save the train valid losses for each epoch, and print them after epoch ends\n",
    "best_loss = 50\n",
    "epochs_no_improve = 0\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        src_data = batch['input'].to(device)\n",
    "        tgt_data = batch['target'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src_data)\n",
    "        loss = criterion(output.view(-1, vocab_size), tgt_data.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.item()\n",
    "    train_losses.append(train_loss/len(train_dataloader))\n",
    "\n",
    "    # evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dataloader:\n",
    "            src_data = batch['input'].to(device)\n",
    "            tgt_data = batch['target'].to(device)\n",
    "            output = model(src_data)\n",
    "            loss = criterion(output.view(-1, vocab_size), tgt_data.view(-1))\n",
    "            valid_loss+=loss.item()\n",
    "            \n",
    "    valid_losses.append(valid_loss/len(valid_dataloader))\n",
    "\n",
    "    print(\"Epoch: [ {} / {} ]; TrainLoss: {:.5f}; ValidLoss: {:.5f}\".format(\n",
    "        epoch, epochs, train_loss/len(train_dataloader), valid_loss/len(valid_dataloader)\n",
    "    ))\n",
    "\n",
    "\n",
    "    cond, best_loss, epochs_no_improve = early_stopping(valid_loss/len(valid_dataloader), epoch, best_loss,epochs_no_improve, patience=10)\n",
    "    if cond:\n",
    "        break\n",
    "    scheduler.step()\n",
    "print(\"Training complete!\")\n",
    "print(\"Best loss: \", best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TransformerModel(max_seq_len, ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
    "model.load_state_dict(torch.load(\"checkpoints/transformer_v3.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200\n",
    "temperature = 1.0\n",
    "end_token = 1\n",
    "\n",
    "model.eval()\n",
    "# current_token = start_token\n",
    "generated_musics = []\n",
    "original_musics = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input = batch['input'].to(device)\n",
    "        target = batch['target'].to(device)\n",
    "        for i in range(len(input)):\n",
    "            generated_tokens = []\n",
    "            output = model(input[i])\n",
    "            # Apply temperature to the output probabilities for diversity\n",
    "            probabilities = softmax(output.squeeze() / temperature, dim=-1)\n",
    "            for j in range(max_length):\n",
    "                current_token = torch.multinomial(probabilities[j], 1).item()\n",
    "                # current_token = torch.argmax(probabilities[j]).item()\n",
    "                generated_tokens.append(current_token)\n",
    "\n",
    "                if current_token == end_token:\n",
    "                    break\n",
    "            generated_musics.append(generated_tokens)\n",
    "            original_musics.append(target[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(generated_musics)):\n",
    "    midi_encoder_remi.words_to_midi(generated_musics[i],f'generated_musics/transformer_3/transformer{i}.mid')\n",
    "    midi_encoder_remi.words_to_midi(original_musics[i],f'generated_musics/original/original{i}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(198, 512)\n",
       "  (decoder_embedding): Embedding(198, 512)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-5): 6 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-5): 6 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=198, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab_size = vocab_size\n",
    "tgt_vocab_size = vocab_size\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 256\n",
    "max_seq_length = max_seq_len\n",
    "dropout = 0.2\n",
    "epochs = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0 / 100 ]; TrainLoss: 4.08913; ValidLoss: 3.45500\n",
      "Epoch: [ 1 / 100 ]; TrainLoss: 3.01872; ValidLoss: 2.59253\n",
      "Epoch: [ 2 / 100 ]; TrainLoss: 2.54995; ValidLoss: 2.32727\n",
      "Epoch: [ 3 / 100 ]; TrainLoss: 2.24609; ValidLoss: 2.04385\n",
      "Epoch: [ 4 / 100 ]; TrainLoss: 2.04664; ValidLoss: 1.91219\n",
      "Epoch: [ 5 / 100 ]; TrainLoss: 1.89928; ValidLoss: 1.74542\n",
      "Epoch: [ 6 / 100 ]; TrainLoss: 1.76858; ValidLoss: 1.62827\n",
      "Epoch: [ 7 / 100 ]; TrainLoss: 1.67304; ValidLoss: 1.52908\n",
      "Epoch: [ 8 / 100 ]; TrainLoss: 1.57958; ValidLoss: 1.42564\n",
      "Epoch: [ 9 / 100 ]; TrainLoss: 1.48593; ValidLoss: 1.31262\n",
      "Epoch: [ 10 / 100 ]; TrainLoss: 1.39581; ValidLoss: 1.19450\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 11 / 100 ]; TrainLoss: 1.30003; ValidLoss: 1.08030\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 12 / 100 ]; TrainLoss: 1.21314; ValidLoss: 1.02053\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 13 / 100 ]; TrainLoss: 1.12528; ValidLoss: 0.87475\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 14 / 100 ]; TrainLoss: 1.04501; ValidLoss: 0.77578\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 15 / 100 ]; TrainLoss: 0.96367; ValidLoss: 0.66510\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 16 / 100 ]; TrainLoss: 0.89372; ValidLoss: 0.61062\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 17 / 100 ]; TrainLoss: 0.80896; ValidLoss: 0.49461\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 18 / 100 ]; TrainLoss: 0.72713; ValidLoss: 0.42553\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 19 / 100 ]; TrainLoss: 0.63838; ValidLoss: 0.31837\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 20 / 100 ]; TrainLoss: 0.54865; ValidLoss: 0.24592\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 21 / 100 ]; TrainLoss: 0.46955; ValidLoss: 0.16474\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 22 / 100 ]; TrainLoss: 0.38087; ValidLoss: 0.18058\n",
      "Epoch: [ 23 / 100 ]; TrainLoss: 0.31029; ValidLoss: 0.08226\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 24 / 100 ]; TrainLoss: 0.24590; ValidLoss: 0.05673\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 25 / 100 ]; TrainLoss: 0.19889; ValidLoss: 0.04860\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 26 / 100 ]; TrainLoss: 0.15491; ValidLoss: 0.03181\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 27 / 100 ]; TrainLoss: 0.12560; ValidLoss: 0.02512\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 28 / 100 ]; TrainLoss: 0.10164; ValidLoss: 0.02118\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 29 / 100 ]; TrainLoss: 0.08287; ValidLoss: 0.01462\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 30 / 100 ]; TrainLoss: 0.07018; ValidLoss: 0.01283\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 31 / 100 ]; TrainLoss: 0.05736; ValidLoss: 0.01137\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 32 / 100 ]; TrainLoss: 0.04881; ValidLoss: 0.00958\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 33 / 100 ]; TrainLoss: 0.04110; ValidLoss: 0.00988\n",
      "Epoch: [ 34 / 100 ]; TrainLoss: 0.03702; ValidLoss: 0.00951\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 35 / 100 ]; TrainLoss: 0.03114; ValidLoss: 0.00828\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 36 / 100 ]; TrainLoss: 0.02640; ValidLoss: 0.00831\n",
      "Epoch: [ 37 / 100 ]; TrainLoss: 0.02629; ValidLoss: 0.00800\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 38 / 100 ]; TrainLoss: 0.03003; ValidLoss: 0.00801\n",
      "Epoch: [ 39 / 100 ]; TrainLoss: 0.01835; ValidLoss: 0.00764\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 40 / 100 ]; TrainLoss: 0.01751; ValidLoss: 0.00759\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 41 / 100 ]; TrainLoss: 0.01785; ValidLoss: 0.00759\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 42 / 100 ]; TrainLoss: 0.01695; ValidLoss: 0.00772\n",
      "Epoch: [ 43 / 100 ]; TrainLoss: 0.02820; ValidLoss: 0.15356\n",
      "Epoch: [ 44 / 100 ]; TrainLoss: 0.03276; ValidLoss: 0.00718\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 45 / 100 ]; TrainLoss: 0.01153; ValidLoss: 0.00715\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 46 / 100 ]; TrainLoss: 0.01128; ValidLoss: 0.00712\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 47 / 100 ]; TrainLoss: 0.01154; ValidLoss: 0.00709\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 48 / 100 ]; TrainLoss: 0.01328; ValidLoss: 0.00729\n",
      "Epoch: [ 49 / 100 ]; TrainLoss: 0.06616; ValidLoss: 0.00729\n",
      "Epoch: [ 50 / 100 ]; TrainLoss: 0.01093; ValidLoss: 0.00697\n",
      "Saving...\n",
      "Model saved!\n",
      "Epoch: [ 51 / 100 ]; TrainLoss: 0.00962; ValidLoss: 0.00701\n",
      "Epoch: [ 52 / 100 ]; TrainLoss: 0.00915; ValidLoss: 0.00715\n",
      "Epoch: [ 53 / 100 ]; TrainLoss: 0.00928; ValidLoss: 0.00721\n",
      "Epoch: [ 54 / 100 ]; TrainLoss: 0.01109; ValidLoss: 0.00743\n",
      "Epoch: [ 55 / 100 ]; TrainLoss: 0.01000; ValidLoss: 0.00737\n",
      "Epoch: [ 56 / 100 ]; TrainLoss: 0.00962; ValidLoss: 0.00740\n",
      "Epoch: [ 57 / 100 ]; TrainLoss: 0.03081; ValidLoss: 0.00783\n",
      "Epoch: [ 58 / 100 ]; TrainLoss: 0.01133; ValidLoss: 0.00703\n",
      "Epoch: [ 59 / 100 ]; TrainLoss: 0.00706; ValidLoss: 0.00712\n",
      "Epoch: [ 60 / 100 ]; TrainLoss: 0.00702; ValidLoss: 0.00741\n",
      "Epoch: [ 61 / 100 ]; TrainLoss: 0.00726; ValidLoss: 0.00739\n",
      "Epoch: [ 62 / 100 ]; TrainLoss: 0.00788; ValidLoss: 0.00738\n",
      "Epoch: [ 63 / 100 ]; TrainLoss: 0.00779; ValidLoss: 0.00759\n",
      "Epoch: [ 64 / 100 ]; TrainLoss: 0.00807; ValidLoss: 0.00751\n",
      "Epoch: [ 65 / 100 ]; TrainLoss: 0.00772; ValidLoss: 0.00759\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "best_loss = 50\n",
    "\n",
    "# save the train valid losses for each epoch, and print them after epoch ends\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    transformer.train()\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        src_data = batch['input'].to(device)\n",
    "        tgt_data = batch['target'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = transformer(src_data, tgt_data[:, :-1])\n",
    "        loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.item()\n",
    "    train_losses.append(train_loss/len(train_dataloader))\n",
    "\n",
    "    # evaluate on validation set\n",
    "    transformer.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dataloader:\n",
    "            src_data = batch['input'].to(device)\n",
    "            tgt_data = batch['target'].to(device)\n",
    "            output = transformer(src_data, tgt_data[:, :-1])\n",
    "            loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "            valid_loss+=loss.item()\n",
    "            \n",
    "    valid_losses.append(valid_loss/len(valid_dataloader))\n",
    "\n",
    "    print(\"Epoch: [ {} / {} ]; TrainLoss: {:.5f}; ValidLoss: {:.5f}\".format(\n",
    "        epoch, epochs, train_loss/len(train_dataloader), valid_loss/len(valid_dataloader)\n",
    "    ))\n",
    "\n",
    "    if epoch>=10:\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            print(\"Saving...\")\n",
    "            torch.save(transformer.state_dict(), \"checkpoints/transformer.pt\")\n",
    "            print(\"Model saved!\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Best loss: \", best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a sequence from the transformer model using test dataloader from the best model\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "transformer.to(device)\n",
    "transformer.load_state_dict(torch.load(\"checkpoints/transformer.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200\n",
    "temperature = 1.0\n",
    "end_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200\n",
    "temperature = 1.0\n",
    "end_token = 1\n",
    "\n",
    "transformer.eval()\n",
    "# current_token = start_token\n",
    "generated_musics = []\n",
    "original_musics = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input = batch['input'].to(device)\n",
    "        target = batch['target'].to(device)\n",
    "        for i in range(len(input)):\n",
    "            generated_tokens = []\n",
    "            output = transformer(input[i].unsqueeze(0), target[i].unsqueeze(0))\n",
    "            # Apply temperature to the output probabilities for diversity\n",
    "            probabilities = softmax(output.squeeze() / temperature, dim=-1)\n",
    "\n",
    "            for j in range(max_length):\n",
    "                current_token = torch.multinomial(probabilities[j], 1).item()\n",
    "                generated_tokens.append(current_token)\n",
    "\n",
    "                if current_token == end_token:\n",
    "                    break\n",
    "                if len(generated_tokens) == max_length:\n",
    "                    break\n",
    "            generated_musics.append(generated_tokens)\n",
    "            original_musics.append(target[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_name = \"generated_musics/transformer\"\n",
    "test = os.listdir(dir_name)\n",
    "\n",
    "for item in test:\n",
    "    if item.endswith(\".mid\"):\n",
    "        os.remove(os.path.join(dir_name, item))\n",
    "\n",
    "dir_name = \"generated_musics/original\"\n",
    "test = os.listdir(dir_name)\n",
    "\n",
    "for item in test:\n",
    "    if item.endswith(\".mid\"):\n",
    "        os.remove(os.path.join(dir_name, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(generated_musics)):\n",
    "    midi_encoder_remi.words_to_midi(generated_musics[i],f'generated_musics/transformer/transformer{i}.mid')\n",
    "    midi_encoder_remi.words_to_midi(original_musics[i],f'generated_musics/original/original{i}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, emsize, d_hid, nhead, nlayers, dropout):\n",
    "        super(Generator, self).__init__()\n",
    "        # TransformerModel(max_seq_len, ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
    "        self.transformer = TransformerModel(max_seq_len, vocab_size, emsize, nhead, d_hid, nlayers, dropout)\n",
    "        # self.fc = nn.Linear(dim, vocab_size)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        output = self.transformer(src)\n",
    "        # output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel_classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, max_seq_length: int, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_seq_length, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, ntoken)\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        # if src_mask is None:\n",
    "        #     \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
    "        #     Unmasked positions are filled with float(0.0).\n",
    "        #     \"\"\"\n",
    "        #     src_mask = nn.Transformer.generate_square_subsequent_mask(len(src)).to(device)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output,_ = torch.max(output, dim=1)              # x has shape (Batch, Embd_dim)\n",
    "        output = self.fc(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, emsize, d_hid, nhead, nlayers, dropout):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.transformer = TransformerModel_classifier(max_seq_len, vocab_size, emsize, nhead, d_hid, nlayers, dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        output = self.transformer(src)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/venv/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Create the generator\n",
    "\n",
    "netG = Generator(vocab_size, max_seq_len, emsize, d_hid, nhead, nlayers, dropout).to(device)\n",
    "# Create the Discriminator\n",
    "netD = Discriminator(vocab_size, max_seq_len, emsize, d_hid, nhead, nlayers, dropout).to(device)\n",
    "\n",
    "# Initialize the ``BCELoss`` function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "nz = 100\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0/10][63/54]\tLoss_D: 2.5818\tLoss_G: 0.7634\tD(x): 0.9212\tD(G(z)): 0.9173 / 0.4670\n",
      "[0/10][63/54]\tLoss_D: 0.0061\tLoss_G: 5.5889\tD(x): 0.9975\tD(G(z)): 0.0036 / 0.0038\n",
      "[1/10][63/54]\tLoss_D: 0.0046\tLoss_G: 5.8237\tD(x): 0.9987\tD(G(z)): 0.0033 / 0.0030\n",
      "[1/10][63/54]\tLoss_D: 0.0024\tLoss_G: 6.7856\tD(x): 0.9989\tD(G(z)): 0.0012 / 0.0011\n",
      "[2/10][63/54]\tLoss_D: 0.0014\tLoss_G: 6.9213\tD(x): 0.9996\tD(G(z)): 0.0010 / 0.0010\n",
      "[2/10][63/54]\tLoss_D: 0.0012\tLoss_G: 7.2411\tD(x): 0.9995\tD(G(z)): 0.0007 / 0.0007\n",
      "[3/10][63/54]\tLoss_D: 0.0009\tLoss_G: 7.2844\tD(x): 0.9998\tD(G(z)): 0.0007 / 0.0007\n",
      "[3/10][63/54]\tLoss_D: 0.0009\tLoss_G: 7.6672\tD(x): 0.9996\tD(G(z)): 0.0005 / 0.0005\n",
      "[4/10][63/54]\tLoss_D: 0.0008\tLoss_G: 7.4583\tD(x): 0.9999\tD(G(z)): 0.0007 / 0.0006\n",
      "[4/10][63/54]\tLoss_D: 0.0007\tLoss_G: 8.1205\tD(x): 0.9996\tD(G(z)): 0.0003 / 0.0003\n",
      "[5/10][63/54]\tLoss_D: 0.0004\tLoss_G: 8.1176\tD(x): 0.9999\tD(G(z)): 0.0003 / 0.0003\n",
      "[5/10][63/54]\tLoss_D: 0.0006\tLoss_G: 8.2127\tD(x): 0.9997\tD(G(z)): 0.0003 / 0.0003\n",
      "[6/10][63/54]\tLoss_D: 0.0003\tLoss_G: 8.3407\tD(x): 0.9999\tD(G(z)): 0.0002 / 0.0002\n",
      "[6/10][63/54]\tLoss_D: 0.0005\tLoss_G: 8.3097\tD(x): 0.9997\tD(G(z)): 0.0002 / 0.0003\n",
      "[7/10][63/54]\tLoss_D: 0.0003\tLoss_G: 8.4975\tD(x): 0.9999\tD(G(z)): 0.0002 / 0.0002\n",
      "[7/10][63/54]\tLoss_D: 0.0004\tLoss_G: 8.5186\tD(x): 0.9998\tD(G(z)): 0.0002 / 0.0002\n",
      "[8/10][63/54]\tLoss_D: 0.0003\tLoss_G: 8.4031\tD(x): 1.0000\tD(G(z)): 0.0003 / 0.0002\n",
      "[8/10][63/54]\tLoss_D: 0.0003\tLoss_G: 8.9589\tD(x): 0.9998\tD(G(z)): 0.0001 / 0.0001\n",
      "[9/10][63/54]\tLoss_D: 0.0002\tLoss_G: 8.8803\tD(x): 1.0000\tD(G(z)): 0.0001 / 0.0001\n",
      "[9/10][63/54]\tLoss_D: 0.0003\tLoss_G: 9.1438\tD(x): 0.9998\tD(G(z)): 0.0001 / 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "# Lists to keep track of progress\n",
    "txt_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for k, data in enumerate(train_dataloader):\n",
    "        input = data['input']\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = input.to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        # noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(real_cpu)\n",
    "        fake_probabilities = softmax(fake.squeeze() / temperature, dim=-1)\n",
    "        fake_mat = torch.zeros((b_size, max_seq_length), dtype=torch.long).to(device)\n",
    "        for i in range(b_size):\n",
    "            for j in range(max_seq_length):\n",
    "                fake_mat[i][j] = torch.multinomial(fake_probabilities[i][j], 1).item()\n",
    "        \n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake_mat).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        output = netD(fake_mat).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        errG = criterion(output, label)\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if k % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(train_dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(real_cpu).detach().cpu()\n",
    "            fake_probabilities = softmax(fake.squeeze() / temperature, dim=-1)\n",
    "            fake_mat = torch.zeros((b_size, max_seq_length), dtype=torch.long).to(device)\n",
    "            for i in range(b_size):\n",
    "                for j in range(max_seq_length):\n",
    "                    fake_mat[i][j] = torch.multinomial(fake_probabilities[i][j], 1).item()\n",
    "            txt_list.append(fake_mat)\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 200\n",
    "temperature = 1.0\n",
    "end_token = 1\n",
    "\n",
    "model.eval()\n",
    "# current_token = start_token\n",
    "generated_musics = []\n",
    "original_musics = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input = batch['input'].to(device)\n",
    "        target = batch['target'].to(device)\n",
    "        for i in range(len(input)):\n",
    "            generated_tokens = []\n",
    "            output = netG(input[i])\n",
    "            # Apply temperature to the output probabilities for diversity\n",
    "            probabilities = softmax(output.squeeze() / temperature, dim=-1)\n",
    "            for j in range(max_length):\n",
    "                current_token = torch.multinomial(probabilities[j], 1).item()\n",
    "                # current_token = torch.argmax(probabilities[j]).item()\n",
    "                generated_tokens.append(current_token)\n",
    "\n",
    "                if current_token == end_token:\n",
    "                    break\n",
    "            generated_musics.append(generated_tokens)\n",
    "            # original_musics.append(target[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(generated_musics)):\n",
    "    midi_encoder_remi.words_to_midi(generated_musics[i],f'generated_musics/gan/gan{i}.mid')\n",
    "    # midi_encoder_remi.words_to_midi(original_musics[i],f'generated_musics/original/original{i}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have your model, dataloaders, loss function, device, learning rate, vocabulary size, etc. defined\n",
    "\n",
    "# Instantiate your ClassifierTrainer\n",
    "classifier_model = PatchClassifier()  # Replace with your actual classifier model\n",
    "train_dataloader = train_dataset  # Replace with your actual training dataloader\n",
    "valid_dataloader = test_dataset  # Replace with your actual validation dataloader\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()  # Replace with your actual loss function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available, else use CPU\n",
    "\n",
    "vocab_size = 10000  # Replace with your actual vocabulary size\n",
    "learning_rate = 0.001  # Replace with your actual learning rate\n",
    "\n",
    "# Instantiate the ClassifierTrainer\n",
    "classifier_trainer = ClassifierTrainer(\n",
    "    model=classifier_model,\n",
    "    dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    ce_loss=cross_entropy_loss,\n",
    "    device=device,\n",
    "    lr=learning_rate,\n",
    "    vocab_size=vocab_size,\n",
    "    warmup_steps=1000,  # Replace with your desired warmup steps\n",
    "    total_iters=30000,  # Replace with your desired total iterations\n",
    "    schedule='cosine_with_warmup'  # Replace with your desired learning rate schedule\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your MidiEncoder\n",
    "midi_encoder = MidiEncoder(steps_per_sec=100, num_vel_bins=32, min_pitch=21, max_pitch=108)\n",
    "\n",
    "# Define a list of MIDI files to encode\n",
    "\n",
    "midi_files_list = [os.path.join(path_to_midi, file) for file in os.listdir(path_to_midi) if file.endswith(\".midi\")]\n",
    "\n",
    "# Encode the MIDI files and save the encoded sequences to a pickle file\n",
    "encoded_sequences_path = \"/workspaces/Transformers_sentiment/data/pickle/encoded_sequences.pkl\"\n",
    "encoded_sequences = midi_encoder.encode_midi_list(midi_files_list, pkl_path=encoded_sequences_path)\n",
    "\n",
    "# Load the encoded sequences from the pickle file (optional)\n",
    "with open(encoded_sequences_path, 'rb') as handle:\n",
    "    loaded_encoded_sequences = pkl.load(handle)\n",
    "\n",
    "# Instantiate your MIDIEncoderREMI\n",
    "midi_encoder_remi = MIDIEncoderREMI(dict_path=\"midi_transcribed/src_001\", midi_files_list=midi_files_list)\n",
    "\n",
    "# Convert MIDI files to REMI words and save the dataset\n",
    "dataset_dir = \"data/train_data\"\n",
    "midi_encoder_remi.save_dataset(midi_files_list, dataset_dir)\n",
    "\n",
    "# Save the dataset as a single file\n",
    "single_file_dataset_path = \"data/npz_midi/single_file_dataset.npz\"\n",
    "midi_encoder_remi.save_dataset_as_single_file(glob.glob(os.path.join(dataset_dir, '*.npy')), single_file_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from the single file (optional)\n",
    "loaded_dataset = np.load(single_file_dataset_path)\n",
    "loaded_sequences = loaded_dataset['sequences']\n",
    "loaded_ids = loaded_dataset['ids']\n",
    "\n",
    "# Convert REMI words back to MIDI and save\n",
    "output_midi_path = \"path/to/save/output_midi.mid\"\n",
    "midi_encoder_remi.words_to_midi(loaded_sequences[0], output_midi_path)\n",
    "\n",
    "# Calculate scores for a MIDI file using MidiEncoder\n",
    "midi_file_to_score = \"path/to/midi/file1.mid\"\n",
    "scores = midi_encoder.calculate_scores(midi_file_to_score)\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
