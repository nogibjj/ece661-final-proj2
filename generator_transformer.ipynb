{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import muspy\n",
    "\n",
    "# emopia = muspy.EMOPIADataset(\"data/emopia/\", download_and_extract=True)\n",
    "# emopia.convert()\n",
    "# music = emopia[0]\n",
    "# print(music.annotations[0].annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb3e6706070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from data.process_data import MidiEncoder, MIDIEncoderREMI\n",
    "import pickle as pkl\n",
    "from torch.utils.data import DataLoader\n",
    "from data.dataset import TransformerDatasetREMI\n",
    "import numpy as np\n",
    "import glob\n",
    "import torch\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_midi = \"data/emopia/EMOPIA_2.2/midis/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your MidiEncoder and MidiEncoderREMI\n",
    "midi_files_list = [os.path.join(path_to_midi, file) for file in os.listdir(path_to_midi) if file.endswith(\".mid\")]\n",
    "midi_encoder = MidiEncoder(steps_per_sec=100, num_vel_bins=32, min_pitch=21, max_pitch=108)\n",
    "midi_encoder_remi = MIDIEncoderREMI(dict_path=\"data/encoder_dict.pkl\", midi_files_list=midi_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/emopia/EMOPIA_2.2/midis/Q1_9v2WSpn4FCw_10.mid\n",
      "0.030449867248535156\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_1.mid\n",
      "0.04412698745727539\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_3ZnxqCZ7qGg_0.mid\n",
      "0.008766889572143555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vpTguZtJAFA_2.mid\n",
      "0.021343469619750977\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_5.mid\n",
      "0.014074563980102539\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JP3QKZlyQz4_0.mid\n",
      "0.01133418083190918\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Y5JcZQ0xg4Y_3.mid\n",
      "0.035741329193115234\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1Qc15G0ZHIg_3.mid\n",
      "0.02382659912109375\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ZgT7yq2jsBk_0.mid\n",
      "0.029172420501708984\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1kny88W533Q_4.mid\n",
      "0.0311434268951416\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_xIsvaT20pZ0_1.mid\n",
      "0.022684335708618164\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k-FNDbK6Qhg_2.mid\n",
      "0.15050482749938965\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_YAAxPW1GB7w_1.mid\n",
      "0.013643264770507812\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Q5b5unyP8BM_0.mid\n",
      "0.03647494316101074\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JxSU49jFKwM_1.mid\n",
      "0.012349843978881836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_PK8YIUaV3Xw_1.mid\n",
      "0.013489961624145508\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Jn9r0avp0fY_3.mid\n",
      "0.034368038177490234\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TonQX8XbvX8_2.mid\n",
      "0.016167879104614258\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iHPKusssXzk_2.mid\n",
      "0.02071094512939453\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_POaIGvLsp5M_1.mid\n",
      "0.01757526397705078\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_eVMSeElk81Q_2.mid\n",
      "0.014438629150390625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1vjy9oMFa8c_2.mid\n",
      "0.01666259765625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_1Q3MoBFh6eU_2.mid\n",
      "0.020199298858642578\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_HY9vPoHbgaI_1.mid\n",
      "0.019449710845947266\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_f2b4kpdw7_c_0.mid\n",
      "0.014526128768920898\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3ahg_eQZhxs_1.mid\n",
      "0.022111892700195312\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_f2b4kpdw7_c_1.mid\n",
      "0.018737077713012695\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_oTi57hZfArE_1.mid\n",
      "0.010858774185180664\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0H4rq0L9OSw_0.mid\n",
      "0.04752659797668457\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_3.mid\n",
      "0.02488875389099121\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_3.mid\n",
      "0.040407419204711914\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_2.mid\n",
      "0.0193326473236084\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1EDThWjNxOI_1.mid\n",
      "0.014483928680419922\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_xrhWli_R98g_0.mid\n",
      "0.0211944580078125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_fey-8bOR95E_0.mid\n",
      "0.03307080268859863\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_4.mid\n",
      "0.0245516300201416\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6Uf9XBUD3wE_0.mid\n",
      "0.0174713134765625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zvWX_dwQPtU_0.mid\n",
      "0.017741680145263672\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_38i12IPkL5c_2.mid\n",
      "0.03558349609375\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ivCNV47tsRw_0.mid\n",
      "0.037322044372558594\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_7JIdJLkJ0S4_3.mid\n",
      "0.025992393493652344\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_9v2WSpn4FCw_2.mid\n",
      "0.022709369659423828\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_10.mid\n",
      "0.023794889450073242\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Dg935IbDggo_0.mid\n",
      "0.0332183837890625\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kMHiU0fhWVw_1.mid\n",
      "0.021727561950683594\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_wzSr6qR3Ra0_0.mid\n",
      "0.017552614212036133\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lQCrA2TE-fo_0.mid\n",
      "0.013910770416259766\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_SQDuF0qxGQw_1.mid\n",
      "0.031116485595703125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_jTPXwbDtIpA_0.mid\n",
      "0.01553034782409668\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Cg2u_Ldjv8g_0.mid\n",
      "0.02282428741455078\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DhnX54kOW8U_0.mid\n",
      "0.030811548233032227\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_2.mid\n",
      "0.03491973876953125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jO2zX6Ul8GM_0.mid\n",
      "0.018054962158203125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_im4Qxn3GQvo_1.mid\n",
      "0.021598100662231445\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_9Yb9OEVwups_0.mid\n",
      "0.017811298370361328\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_XC_SiJszQx0_1.mid\n",
      "0.027875185012817383\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_3.mid\n",
      "0.020135164260864258\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UJcnNfeCN1c_1.mid\n",
      "0.015472173690795898\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0wRQRwnQiqY_0.mid\n",
      "0.02495265007019043\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_AacIP9mDLw8_1.mid\n",
      "0.02279829978942871\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_2.mid\n",
      "0.028279781341552734\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_im4Qxn3GQvo_0.mid\n",
      "0.033480167388916016\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pRuwHN-lI44_0.mid\n",
      "0.025847911834716797\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_CxFXrYgdSSI_0.mid\n",
      "0.014653205871582031\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_4Er-eFHSHA4_3.mid\n",
      "0.02082037925720215\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ii1Jw1-7Ka4_1.mid\n",
      "0.02572941780090332\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_4.mid\n",
      "0.02385687828063965\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_fuCxYrru2S4_1.mid\n",
      "0.02132582664489746\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lTxVVdhFE6Q_0.mid\n",
      "0.019968032836914062\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0lEL_XHyhuU_2.mid\n",
      "0.012397289276123047\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_7gifuoofgpk_1.mid\n",
      "0.01132965087890625\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_DX1IK3z1w10_0.mid\n",
      "0.020211458206176758\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ZvD8QSO7NPw_2.mid\n",
      "0.04894089698791504\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_aYe-2Glruu4_4.mid\n",
      "0.04094815254211426\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UbKAl4roB8k_1.mid\n",
      "0.024594545364379883\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_2.mid\n",
      "0.00477290153503418\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_qlbazHayULg_3.mid\n",
      "0.032903432846069336\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_9Xg69XrVaYU_2.mid\n",
      "0.02149200439453125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jNzZCplNNyY_0.mid\n",
      "0.02303147315979004\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_fOYX0uH8mSQ_0.mid\n",
      "0.024852752685546875\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_X1p8xcarVu0_0.mid\n",
      "0.013849973678588867\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bQS8eAXAhyE_2.mid\n",
      "0.02983379364013672\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_3.mid\n",
      "0.031032800674438477\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_K6OFDxBU370_1.mid\n",
      "0.019968271255493164\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ADJ_PDauy-g_0.mid\n",
      "0.00976252555847168\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TonQX8XbvX8_1.mid\n",
      "0.015418291091918945\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yrvKReuwVlY_3.mid\n",
      "0.024342060089111328\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_VXh4IaR5C6s_0.mid\n",
      "0.020602703094482422\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_9eMxCs-LXCE_2.mid\n",
      "0.021535634994506836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_I2MrA-o5H8I_1.mid\n",
      "0.031458377838134766\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wlOa1jkTn_U_0.mid\n",
      "0.0260007381439209\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0v2N1ROvEI0_1.mid\n",
      "0.017716407775878906\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_tw_lArYiHTo_0.mid\n",
      "0.030086278915405273\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_8TYY0qG-KOw_0.mid\n",
      "0.020906925201416016\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_2.mid\n",
      "0.014351367950439453\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_eVMSeElk81Q_0.mid\n",
      "0.01734614372253418\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e838BE_MH6s_3.mid\n",
      "0.03490781784057617\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_4ydjOX3pWds_0.mid\n",
      "0.026118993759155273\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_By3JCii1k3w_2.mid\n",
      "0.01414942741394043\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Jn9r0avp0fY_1.mid\n",
      "0.04374051094055176\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_5.mid\n",
      "0.02813577651977539\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__kJtgm1OUNA_2.mid\n",
      "0.016696453094482422\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HYVmgq5Y93g_0.mid\n",
      "0.02006053924560547\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ldCQ6N9G6Mk_2.mid\n",
      "0.008973360061645508\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_1.mid\n",
      "0.013234853744506836\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_EtAbPc20mn8_0.mid\n",
      "0.019285917282104492\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_12.mid\n",
      "0.023435115814208984\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_xrhWli_R98g_3.mid\n",
      "0.018349170684814453\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Iq6g_4AwUWs_0.mid\n",
      "0.03530454635620117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XPLYvpyfKUM_0.mid\n",
      "0.013129949569702148\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_miqLU2739dk_0.mid\n",
      "0.028657197952270508\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_TcFVq0leii4_0.mid\n",
      "0.015098810195922852\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cFWdWpyvwag_0.mid\n",
      "0.02142930030822754\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_BaHHHgDd0BU_0.mid\n",
      "0.023029327392578125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ISCVfmBvYoM_0.mid\n",
      "0.02162027359008789\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_7.mid\n",
      "0.01916980743408203\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KxlqB3j0zys_4.mid\n",
      "0.013307332992553711\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_1.mid\n",
      "0.03224039077758789\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nBIls0laAAU_2.mid\n",
      "0.030840396881103516\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_VXgRfsVd_o0_2.mid\n",
      "0.026717424392700195\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pzeHffxmdcE_0.mid\n",
      "0.02478933334350586\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_FfwKrQyQ7WU_3.mid\n",
      "0.02112293243408203\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_AjN_5CdVUdw_0.mid\n",
      "0.015930652618408203\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OgkB7PfqWzA_1.mid\n",
      "0.009531497955322266\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_1.mid\n",
      "0.012614727020263672\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jO2zX6Ul8GM_1.mid\n",
      "0.013861894607543945\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UbKAl4roB8k_2.mid\n",
      "0.018689870834350586\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8izVTDgBQPc_0.mid\n",
      "0.023560285568237305\n",
      "data/emopia/EMOPIA_2.2/midis/Q3__vZOEQCYSaY_2.mid\n",
      "0.027861595153808594\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ZvD8QSO7NPw_0.mid\n",
      "0.01432943344116211\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Jn9r0avp0fY_2.mid\n",
      "0.03427290916442871\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Q49PWE0RJLY_0.mid\n",
      "0.02412271499633789\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_D8Ed5PZXfF4_0.mid\n",
      "0.01613926887512207\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_E6MARl3zjnQ_0.mid\n",
      "0.026572227478027344\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_pouxqiySdI8_1.mid\n",
      "0.024129867553710938\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_JNzqL24ZcZ8_2.mid\n",
      "0.02199411392211914\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_rrD7XMtPs0Q_0.mid\n",
      "0.017107009887695312\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_eGQUZ9FlUJ4_0.mid\n",
      "0.03663754463195801\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rW1I58_lMEg_1.mid\n",
      "0.016339540481567383\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_KxlqB3j0zys_1.mid\n",
      "0.012518644332885742\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_4.mid\n",
      "0.013746976852416992\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_7n32BtYb4d4_0.mid\n",
      "0.15736031532287598\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_08t73Qgjkt4_2.mid\n",
      "0.04084920883178711\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_V3Y9L4UOcpk_1.mid\n",
      "0.022202253341674805\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_7n32BtYb4d4_2.mid\n",
      "0.03358769416809082\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_HY9vPoHbgaI_2.mid\n",
      "0.020334720611572266\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UYh88SRZC24_0.mid\n",
      "0.03127884864807129\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0lEL_XHyhuU_3.mid\n",
      "0.009036064147949219\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_qlbazHayULg_9.mid\n",
      "0.014760971069335938\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GY3f6ckBVkA_0.mid\n",
      "0.017350435256958008\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jrVXitpLGMk_2.mid\n",
      "0.04366016387939453\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_tfuul78deOs_1.mid\n",
      "0.016504526138305664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_1.mid\n",
      "0.014423847198486328\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Hwd6l9jK7bo_1.mid\n",
      "0.011866092681884766\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_0.mid\n",
      "0.01967906951904297\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_3.mid\n",
      "0.02051401138305664\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UJcnNfeCN1c_2.mid\n",
      "0.01561284065246582\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XPLYvpyfKUM_1.mid\n",
      "0.01781010627746582\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DYBBfpEx-JI_0.mid\n",
      "0.030301570892333984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rW1I58_lMEg_2.mid\n",
      "0.01719808578491211\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_gwmVjvR-sVs_1.mid\n",
      "0.017564773559570312\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Uu-oRTRT6uQ_0.mid\n",
      "0.03722214698791504\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FSzOgraSKhs_1.mid\n",
      "0.016396045684814453\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pRuwHN-lI44_3.mid\n",
      "0.015335321426391602\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TYkTOwBfFB8_0.mid\n",
      "0.02191638946533203\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_TNoaOTrTkTQ_2.mid\n",
      "0.019438982009887695\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_2.mid\n",
      "0.02325725555419922\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UJcnNfeCN1c_3.mid\n",
      "0.012063026428222656\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_NP0lwB-_-og_0.mid\n",
      "0.014678239822387695\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_5NW0zDu6IYM_2.mid\n",
      "0.05810427665710449\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_2.mid\n",
      "0.015262126922607422\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lvfNo4KOTmM_1.mid\n",
      "0.014082193374633789\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ZvD8QSO7NPw_1.mid\n",
      "0.026752233505249023\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_4.mid\n",
      "0.05118274688720703\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UYh88SRZC24_1.mid\n",
      "0.035070180892944336\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_yZGBxiNPu3k_2.mid\n",
      "0.024782657623291016\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_6.mid\n",
      "0.10433006286621094\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_AacIP9mDLw8_0.mid\n",
      "0.02130126953125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_PZN7XLKzLDI_0.mid\n",
      "0.027271032333374023\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_5.mid\n",
      "0.03362083435058594\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_1.mid\n",
      "0.04326629638671875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Hwd6l9jK7bo_0.mid\n",
      "0.013392925262451172\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_OO7zYVeK814_1.mid\n",
      "0.01750659942626953\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_0.mid\n",
      "0.014050006866455078\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_hoPp_GLXQis_1.mid\n",
      "0.014143228530883789\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_2Z9SjI131jA_6.mid\n",
      "0.01958489418029785\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Ie5koh4qvJc_12.mid\n",
      "0.07259416580200195\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3N2G21U7guk_1.mid\n",
      "0.013873100280761719\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_D3onzY4MNxE_0.mid\n",
      "0.013950109481811523\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_9v2WSpn4FCw_0.mid\n",
      "0.016568422317504883\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_aQ4PIaRMLwE_0.mid\n",
      "0.010430097579956055\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_0.mid\n",
      "0.0614781379699707\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lvfNo4KOTmM_0.mid\n",
      "0.015567302703857422\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_heBmBQDWj-M_2.mid\n",
      "0.01902174949645996\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_p2qihp_PnLY_1.mid\n",
      "0.025435209274291992\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Xsn9zT-05ns_1.mid\n",
      "0.04071378707885742\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_0.mid\n",
      "0.02261829376220703\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__vZOEQCYSaY_1.mid\n",
      "0.017947673797607422\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_6oLmO9ZSJt0_1.mid\n",
      "0.0076754093170166016\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_61EA0xRX8gE_2.mid\n",
      "0.028138160705566406\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ezoAduuCkUs_0.mid\n",
      "0.04657292366027832\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_jziI_cuN_H8_1.mid\n",
      "0.031557321548461914\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_7.mid\n",
      "0.031156301498413086\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_TcFVq0leii4_2.mid\n",
      "0.04044699668884277\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_f2BXXa7lPuE_3.mid\n",
      "0.03885006904602051\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_1kny88W533Q_1.mid\n",
      "0.01492929458618164\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JT1XJnVmABo_6.mid\n",
      "0.033417463302612305\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yrvKReuwVlY_2.mid\n",
      "0.04914450645446777\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_prUUays30Mg_1.mid\n",
      "0.011748790740966797\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Xsn9zT-05ns_0.mid\n",
      "0.03297996520996094\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bIx4DwkZxFY_0.mid\n",
      "0.013950586318969727\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_k6aLLVX1D7Y_1.mid\n",
      "0.031716346740722656\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Cg2u_Ldjv8g_1.mid\n",
      "0.13509035110473633\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0J7lX-Tcx-w_2.mid\n",
      "0.028469562530517578\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_1.mid\n",
      "0.07550954818725586\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_CxFXrYgdSSI_2.mid\n",
      "0.03916740417480469\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kfYaGryaGzI_0.mid\n",
      "0.01438450813293457\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vpTguZtJAFA_1.mid\n",
      "0.010011911392211914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_SQDuF0qxGQw_2.mid\n",
      "0.02965998649597168\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ltxNPJda7zE_2.mid\n",
      "0.017856836318969727\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_RiQMuhk_SuQ_0.mid\n",
      "0.008610248565673828\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_3.mid\n",
      "0.015364408493041992\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_CxFXrYgdSSI_1.mid\n",
      "0.03674197196960449\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_K6OFDxBU370_0.mid\n",
      "0.01932501792907715\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zjr_-ql5Avk_1.mid\n",
      "0.008403301239013672\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_x4B0raxVODA_2.mid\n",
      "0.013185501098632812\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FOcdHIhI0_s_1.mid\n",
      "0.014339685440063477\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_PLfFWFZflQU_0.mid\n",
      "0.018670320510864258\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_bbU31JLtlug_1.mid\n",
      "0.03495359420776367\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__kJtgm1OUNA_0.mid\n",
      "0.02038717269897461\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_-_FjI4bT2Wo_0.mid\n",
      "0.02212047576904297\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_77z6Ep3aOmg_0.mid\n",
      "0.019312381744384766\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_g15aRCHUJEI_0.mid\n",
      "0.012698888778686523\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5J_zI7QE9W8_2.mid\n",
      "0.020539283752441406\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lQCrA2TE-fo_1.mid\n",
      "0.014130353927612305\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_WBxql6cuU7c_0.mid\n",
      "0.039739370346069336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pRuwHN-lI44_2.mid\n",
      "0.012619972229003906\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_-jJVb0xvbdg_0.mid\n",
      "0.01853632926940918\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_jziI_cuN_H8_2.mid\n",
      "0.04196953773498535\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_1.mid\n",
      "0.011663436889648438\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_-vAz_HTFEXs_0.mid\n",
      "0.014755487442016602\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TYkTOwBfFB8_1.mid\n",
      "0.025144338607788086\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_qRceKZtwRWA_0.mid\n",
      "0.011582612991333008\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_sUJ4a74Skk8_0.mid\n",
      "0.016784191131591797\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_1cgO42sh-ZY_0.mid\n",
      "0.008679628372192383\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_X1p8xcarVu0_2.mid\n",
      "0.012729406356811523\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e8NQ2NH0nc8_1.mid\n",
      "0.020444631576538086\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_0.mid\n",
      "0.01349639892578125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wS0RzrBL9UI_0.mid\n",
      "0.01350545883178711\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_iwxwLEvqeD8_0.mid\n",
      "0.009910821914672852\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_b8HVQtIoBYU_1.mid\n",
      "0.028861522674560547\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_7n32BtYb4d4_3.mid\n",
      "0.029079675674438477\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_kDGmND1BgmA_1.mid\n",
      "0.0065937042236328125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UAm0aWvzFI8_1.mid\n",
      "0.04013490676879883\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_DvIH5yUrboc_1.mid\n",
      "0.02950596809387207\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_r_sD61KeUQU_0.mid\n",
      "0.018433570861816406\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_8.mid\n",
      "0.0527186393737793\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_g-yM0Lsp4lc_0.mid\n",
      "0.01497197151184082\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cQp1BYDGcRo_1.mid\n",
      "0.03465437889099121\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_PLfFWFZflQU_1.mid\n",
      "0.027688026428222656\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DYBBfpEx-JI_3.mid\n",
      "0.03331637382507324\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ury1cdB79s0_0.mid\n",
      "0.01121830940246582\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_15.mid\n",
      "0.014206171035766602\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_0.mid\n",
      "0.025646686553955078\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_vVTP0DOL_2Q_1.mid\n",
      "0.014369964599609375\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Kk60F8a7-Jw_0.mid\n",
      "0.023793697357177734\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__FVzelKlBFs_2.mid\n",
      "0.022042036056518555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_0.mid\n",
      "0.011541366577148438\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_2.mid\n",
      "0.041335105895996094\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_UJcnNfeCN1c_0.mid\n",
      "0.01231527328491211\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_02t1bj7ZABY_1.mid\n",
      "0.015556573867797852\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_12tDlCQVRtA_1.mid\n",
      "0.01631927490234375\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xf2fox7zhCQ_0.mid\n",
      "0.015962600708007812\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6kRPHamGDSo_3.mid\n",
      "0.018567562103271484\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KRlAez34QfE_1.mid\n",
      "0.016409635543823242\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_-_FjI4bT2Wo_2.mid\n",
      "0.011699199676513672\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Uu-oRTRT6uQ_1.mid\n",
      "0.041670799255371094\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_12.mid\n",
      "0.032843828201293945\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_RiQMuhk_SuQ_2.mid\n",
      "0.08213472366333008\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_2.mid\n",
      "0.020877838134765625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_VXgRfsVd_o0_1.mid\n",
      "0.04030656814575195\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Dg935IbDggo_1.mid\n",
      "0.036437273025512695\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_T92R7xjce34_1.mid\n",
      "0.017621994018554688\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_x4B0raxVODA_1.mid\n",
      "0.008521080017089844\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5DqIntcmdRI_1.mid\n",
      "0.020050048828125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_epX33OVpkmA_1.mid\n",
      "0.042200326919555664\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_9.mid\n",
      "0.03957176208496094\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltxNPJda7zE_1.mid\n",
      "0.013641119003295898\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_d_49EtXDMFE_1.mid\n",
      "0.012140274047851562\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_94ROf10d1iA_0.mid\n",
      "0.011698007583618164\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_2.mid\n",
      "0.017789840698242188\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_VrWAZLRdQO8_0.mid\n",
      "0.008124351501464844\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_xrhWli_R98g_1.mid\n",
      "0.027804136276245117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iGHgeUCPotc_0.mid\n",
      "0.014092683792114258\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Y5JcZQ0xg4Y_1.mid\n",
      "0.021541833877563477\n",
      "data/emopia/EMOPIA_2.2/midis/Q3__vZOEQCYSaY_0.mid\n",
      "0.01938152313232422\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_0.mid\n",
      "0.04133462905883789\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_78C_TpQDvVE_1.mid\n",
      "0.02201986312866211\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XC_SiJszQx0_0.mid\n",
      "0.010827064514160156\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_veG92Oi-DlU_0.mid\n",
      "0.019621610641479492\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_dfNdpy8TUzA_1.mid\n",
      "0.017320632934570312\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_fShAWhXIits_1.mid\n",
      "0.015950441360473633\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZTrEoB8T9YA_0.mid\n",
      "0.031697988510131836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_17.mid\n",
      "0.011566638946533203\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_TNoaOTrTkTQ_1.mid\n",
      "0.02276301383972168\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yhIncZ_Ue4E_0.mid\n",
      "0.018503665924072266\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_7yW9c7t8Hq0_3.mid\n",
      "0.04162096977233887\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_31.mid\n",
      "0.016511201858520508\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_XfA2KXodrOE_0.mid\n",
      "0.03226947784423828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_BGf5nCdzPOc_0.mid\n",
      "0.04373621940612793\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bQS8eAXAhyE_0.mid\n",
      "0.015851259231567383\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DYBBfpEx-JI_2.mid\n",
      "0.03459787368774414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zvWX_dwQPtU_1.mid\n",
      "0.023101091384887695\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_mX-xs3OVhTs_1.mid\n",
      "0.01759171485900879\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_QwsQ8ejbMKg_0.mid\n",
      "0.035076141357421875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3N2G21U7guk_5.mid\n",
      "0.0224149227142334\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_QJlnTN7HRwE_0.mid\n",
      "0.0092926025390625\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ldCQ6N9G6Mk_5.mid\n",
      "0.03456997871398926\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_4Er-eFHSHA4_1.mid\n",
      "0.017681360244750977\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_DvIH5yUrboc_0.mid\n",
      "0.02563929557800293\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_L3_TadjSQQ0_0.mid\n",
      "0.15304851531982422\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UOSlDydo94E_0.mid\n",
      "0.019126415252685547\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__SJQaaRzD-A_1.mid\n",
      "0.0245206356048584\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_b8HVQtIoBYU_0.mid\n",
      "0.01866006851196289\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1EDThWjNxOI_0.mid\n",
      "0.012102842330932617\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_0.mid\n",
      "0.0053479671478271484\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_2w5XkAt_3WU_0.mid\n",
      "0.012418746948242188\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Dw7M69CidJ8_0.mid\n",
      "0.011407613754272461\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_WQrPcuy50aA_1.mid\n",
      "0.025440454483032227\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_vVTP0DOL_2Q_3.mid\n",
      "0.016208887100219727\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_mlHheZbblT0_1.mid\n",
      "0.02302098274230957\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1Qc15G0ZHIg_1.mid\n",
      "0.025513410568237305\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1vjy9oMFa8c_4.mid\n",
      "0.012964010238647461\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_L3_TadjSQQ0_1.mid\n",
      "0.03943276405334473\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_4.mid\n",
      "0.025415420532226562\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_AacIP9mDLw8_2.mid\n",
      "0.023210763931274414\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_4.mid\n",
      "0.0402674674987793\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GY3f6ckBVkA_1.mid\n",
      "0.013986349105834961\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_f2BXXa7lPuE_0.mid\n",
      "0.02122020721435547\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KRlAez34QfE_2.mid\n",
      "0.015540122985839844\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_JNzqL24ZcZ8_0.mid\n",
      "0.022863388061523438\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_epX33OVpkmA_2.mid\n",
      "0.03115534782409668\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s6-SbDSZzEU_0.mid\n",
      "0.020589351654052734\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_fnqb8zqHqdY_1.mid\n",
      "0.010529279708862305\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pkz8OkWhwnk_1.mid\n",
      "0.01683187484741211\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FH28sPhm9Dc_1.mid\n",
      "0.0279538631439209\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_POaIGvLsp5M_0.mid\n",
      "0.01644611358642578\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_WpZ1rWHOCAQ_0.mid\n",
      "0.014462471008300781\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_cXxGBDgFCs8_0.mid\n",
      "0.021124601364135742\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_7yW9c7t8Hq0_2.mid\n",
      "0.021338462829589844\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_fShAWhXIits_0.mid\n",
      "0.034261226654052734\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_dfNdpy8TUzA_2.mid\n",
      "0.017740488052368164\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UTo7E0evQWw_0.mid\n",
      "0.027486801147460938\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_1.mid\n",
      "0.03345179557800293\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_94ROf10d1iA_2.mid\n",
      "0.006361722946166992\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_snfsc7pEzlk_1.mid\n",
      "0.038491249084472656\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_z5ewpQwGDNw_0.mid\n",
      "0.015137434005737305\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_FUAK5TBaNY8_1.mid\n",
      "0.021654844284057617\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0H4rq0L9OSw_1.mid\n",
      "0.05151200294494629\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S7Bo4-NCEDk_1.mid\n",
      "0.045301198959350586\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_REq37pDAm3A_3.mid\n",
      "0.0251157283782959\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltNK_MY1HkM_2.mid\n",
      "0.006123542785644531\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_yZGBxiNPu3k_1.mid\n",
      "0.016730785369873047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZdyiXIlKe_Y_1.mid\n",
      "0.02132439613342285\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_BzqX-9TA-GY_0.mid\n",
      "0.004584550857543945\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_sA9ac1rod84_0.mid\n",
      "0.020375728607177734\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_PdwxeMPXOCk_1.mid\n",
      "0.027348756790161133\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_cCfEDTkuMvg_0.mid\n",
      "0.010593891143798828\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_d_49EtXDMFE_2.mid\n",
      "0.010915994644165039\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OoxI6k0Qsno_0.mid\n",
      "0.011106014251708984\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_TcFVq0leii4_1.mid\n",
      "0.035271644592285156\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0lEL_XHyhuU_0.mid\n",
      "0.008337020874023438\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wxXpvnmq_-E_2.mid\n",
      "0.012614011764526367\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JT1XJnVmABo_3.mid\n",
      "0.01124882698059082\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KRlAez34QfE_0.mid\n",
      "0.015778303146362305\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_0.mid\n",
      "0.013695478439331055\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D-gDPh9ZpFk_2.mid\n",
      "0.03994488716125488\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D5kyjnlDNZs_0.mid\n",
      "0.03575468063354492\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tc684nD8CEA_4.mid\n",
      "0.014305830001831055\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_4dXC1cC7crw_1.mid\n",
      "0.033231258392333984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OUb9uaOlWAM_0.mid\n",
      "0.013195276260375977\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cFWdWpyvwag_1.mid\n",
      "0.05638742446899414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_4Er-eFHSHA4_2.mid\n",
      "0.021045207977294922\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e8NQ2NH0nc8_0.mid\n",
      "0.02669811248779297\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_V_jbWvQNh5c_1.mid\n",
      "0.011687755584716797\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_snfsc7pEzlk_0.mid\n",
      "0.020508527755737305\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yrvKReuwVlY_0.mid\n",
      "0.019654512405395508\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_9eMxCs-LXCE_0.mid\n",
      "0.009726285934448242\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ldCQ6N9G6Mk_4.mid\n",
      "0.022509336471557617\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0EWWyyV7RJA_0.mid\n",
      "0.032147884368896484\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UpHutdJvZMI_0.mid\n",
      "0.014913797378540039\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__8v0MFBZoco_0.mid\n",
      "0.06474661827087402\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_v3Nl5rUxLqE_1.mid\n",
      "0.007311582565307617\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OoxI6k0Qsno_1.mid\n",
      "0.01283121109008789\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_1.mid\n",
      "0.019885778427124023\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_pNwQ9Tu_bCs_1.mid\n",
      "0.03687262535095215\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5J_zI7QE9W8_1.mid\n",
      "0.015147686004638672\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ijfxkQPAQdE_2.mid\n",
      "0.053813934326171875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_MT2_mXn-vGU_0.mid\n",
      "0.01455235481262207\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_VCSDjQxAJzc_1.mid\n",
      "0.016990184783935547\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6wFJhmhNeeg_0.mid\n",
      "0.05141639709472656\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_xYZ8n8ULaNo_1.mid\n",
      "0.01743626594543457\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_3.mid\n",
      "0.015192747116088867\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3TYeU9idRGI_0.mid\n",
      "0.008931398391723633\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xlv4PPGrRRs_1.mid\n",
      "0.0167391300201416\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JMt4m608s3k_0.mid\n",
      "0.0254058837890625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1TAKQK3s6qQ_0.mid\n",
      "0.04426383972167969\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_3.mid\n",
      "0.03496193885803223\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kMHiU0fhWVw_2.mid\n",
      "0.015864133834838867\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Jn9r0avp0fY_0.mid\n",
      "0.03296995162963867\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_cXxGBDgFCs8_2.mid\n",
      "0.015436410903930664\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_x5ibvz38jOs_0.mid\n",
      "0.023100614547729492\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_xYZ8n8ULaNo_0.mid\n",
      "0.012390851974487305\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3N2G21U7guk_4.mid\n",
      "0.014658927917480469\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_o20YCzej5_s_0.mid\n",
      "0.048148155212402344\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FyK_c-TIcCA_0.mid\n",
      "0.028456449508666992\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_mGYKWCVnMwQ_1.mid\n",
      "0.024465084075927734\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Fc1qk52SaKY_0.mid\n",
      "0.029410123825073242\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_BzqX-9TA-GY_2.mid\n",
      "0.014384984970092773\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_OCqMDeD6Fmc_0.mid\n",
      "0.023893117904663086\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s5b8viFsVJE_1.mid\n",
      "0.037213802337646484\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Cir1kZyB7QM_0.mid\n",
      "0.016627073287963867\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_21.mid\n",
      "0.03452754020690918\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1kny88W533Q_2.mid\n",
      "0.03444194793701172\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_wfXSdMsd4q8_5.mid\n",
      "0.029216766357421875\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jSWItJI-Gmk_1.mid\n",
      "0.01554417610168457\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_7n32BtYb4d4_1.mid\n",
      "0.01880788803100586\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_eGQUZ9FlUJ4_1.mid\n",
      "0.03980851173400879\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_E5qEloUO3SM_0.mid\n",
      "0.020045995712280273\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wlOa1jkTn_U_1.mid\n",
      "0.02251911163330078\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_TOXg4-ZGb-g_2.mid\n",
      "0.011457681655883789\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_pNwQ9Tu_bCs_2.mid\n",
      "0.02391982078552246\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_tfuul78deOs_0.mid\n",
      "0.01519918441772461\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_5.mid\n",
      "0.03336930274963379\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_k-FNDbK6Qhg_1.mid\n",
      "0.023375511169433594\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XWk5XUEBXmg_0.mid\n",
      "0.014141559600830078\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zHwJG8Rrx6c_1.mid\n",
      "0.018199682235717773\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_qlbazHayULg_13.mid\n",
      "0.03573870658874512\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_6.mid\n",
      "0.15624165534973145\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_RaUSISlnhKw_2.mid\n",
      "0.034317731857299805\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_16.mid\n",
      "0.00609278678894043\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_24.mid\n",
      "0.024428129196166992\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FoTXpYZXxJs_0.mid\n",
      "0.017807483673095703\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_gxsdWKc1QaM_0.mid\n",
      "0.0259244441986084\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_BIRDDxz0E4c_1.mid\n",
      "0.012272357940673828\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_12tDlCQVRtA_0.mid\n",
      "0.010408163070678711\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_aQ4PIaRMLwE_1.mid\n",
      "0.01823735237121582\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_SlsXsqotUis_0.mid\n",
      "0.03730463981628418\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Y1F0c3zgMJo_1.mid\n",
      "0.012150049209594727\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_--2B4d4lQhs_1.mid\n",
      "0.06814432144165039\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s5b8viFsVJE_2.mid\n",
      "0.03382396697998047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1kny88W533Q_3.mid\n",
      "0.031855106353759766\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_38i12IPkL5c_1.mid\n",
      "0.03125905990600586\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xlv4PPGrRRs_0.mid\n",
      "0.013846397399902344\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_FfwKrQyQ7WU_1.mid\n",
      "0.02249932289123535\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_eVMSeElk81Q_1.mid\n",
      "0.039769649505615234\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_oTi57hZfArE_0.mid\n",
      "0.01271963119506836\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jIKX3ShvLxo_1.mid\n",
      "0.05311131477355957\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Gcbk0GPT3-g_0.mid\n",
      "0.015297412872314453\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JYVXM0qNQAg_1.mid\n",
      "0.039681196212768555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1fdxsFbnsX4_0.mid\n",
      "0.012491464614868164\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_IgpNyJVWcBo_0.mid\n",
      "0.023072481155395508\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_X1p8xcarVu0_3.mid\n",
      "0.012142658233642578\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5Ju9q1N2x0E_1.mid\n",
      "0.034401655197143555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_u_7b9CwyM8Q_0.mid\n",
      "0.016244888305664062\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_7.mid\n",
      "0.03654932975769043\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_cB-Xh8H_7-Q_0.mid\n",
      "0.04004263877868652\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_16OaOpfOPZ0_1.mid\n",
      "0.023479938507080078\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TonQX8XbvX8_0.mid\n",
      "0.00841069221496582\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_egYSmNuIFGk_2.mid\n",
      "0.02071547508239746\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_J6X3rVU1H-c_1.mid\n",
      "0.025017738342285156\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_D3onzY4MNxE_1.mid\n",
      "0.013454914093017578\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_rEz0D3VohFA_2.mid\n",
      "0.05353832244873047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0v2N1ROvEI0_0.mid\n",
      "0.08132123947143555\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_f0NbGeyJYms_0.mid\n",
      "0.025072336196899414\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Dw7M69CidJ8_1.mid\n",
      "0.02064681053161621\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_iwxwLEvqeD8_1.mid\n",
      "0.014129638671875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_60LLKmpgzRM_0.mid\n",
      "0.007406949996948242\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_9.mid\n",
      "0.020111799240112305\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_2.mid\n",
      "0.05728268623352051\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XC_SiJszQx0_2.mid\n",
      "0.011379480361938477\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_3.mid\n",
      "0.042104244232177734\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_v2an-9szi8M_0.mid\n",
      "0.014761209487915039\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_3.mid\n",
      "0.012646913528442383\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0qYNvMCEwaw_0.mid\n",
      "0.0309906005859375\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_8.mid\n",
      "0.029763460159301758\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_K84TcgjCRt4_0.mid\n",
      "0.010340213775634766\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_16OaOpfOPZ0_3.mid\n",
      "0.021269559860229492\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UE0y8MHqT-g_2.mid\n",
      "0.03587532043457031\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Q49PWE0RJLY_1.mid\n",
      "0.017433881759643555\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_OO7zYVeK814_2.mid\n",
      "0.010085344314575195\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_fey-8bOR95E_1.mid\n",
      "0.037822723388671875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_13.mid\n",
      "0.025014162063598633\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_3.mid\n",
      "0.04861640930175781\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_BGf5nCdzPOc_1.mid\n",
      "0.0376739501953125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZdyiXIlKe_Y_0.mid\n",
      "0.024628162384033203\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_snfsc7pEzlk_2.mid\n",
      "0.03662729263305664\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_7yW9c7t8Hq0_1.mid\n",
      "0.03669095039367676\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_xrhWli_R98g_2.mid\n",
      "0.015718698501586914\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k-FNDbK6Qhg_0.mid\n",
      "0.04132866859436035\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_g15aRCHUJEI_2.mid\n",
      "0.013218402862548828\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FyK_c-TIcCA_2.mid\n",
      "0.09002947807312012\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_B3aRl8iTEKw_1.mid\n",
      "0.025449275970458984\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ufRISSD28XA_1.mid\n",
      "0.022040367126464844\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iHPKusssXzk_1.mid\n",
      "0.018135786056518555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ldCQ6N9G6Mk_1.mid\n",
      "0.014123678207397461\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZTrEoB8T9YA_2.mid\n",
      "0.025147438049316406\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_0.mid\n",
      "0.014514684677124023\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_4.mid\n",
      "0.0204617977142334\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_uqRLEByE6pU_2.mid\n",
      "0.04891681671142578\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nFunbdBrukY_0.mid\n",
      "0.013976573944091797\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nBao46YGZDg_0.mid\n",
      "0.010372161865234375\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_K84TcgjCRt4_2.mid\n",
      "0.022667884826660156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xf2fox7zhCQ_2.mid\n",
      "0.020735502243041992\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_nGkpcWNAxDU_2.mid\n",
      "0.024784564971923828\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_PZN7XLKzLDI_1.mid\n",
      "0.023442983627319336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k4lT-sXg3iI_2.mid\n",
      "0.027015209197998047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cm6E860vDjY_2.mid\n",
      "0.03292131423950195\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ivCNV47tsRw_1.mid\n",
      "0.033980607986450195\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_IH2KrGjKXw0_3.mid\n",
      "0.1478252410888672\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1vjy9oMFa8c_5.mid\n",
      "0.04109907150268555\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kMHiU0fhWVw_3.mid\n",
      "0.01859903335571289\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_GwdQliEv6Z0_0.mid\n",
      "0.031525373458862305\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_19.mid\n",
      "0.013532638549804688\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__kJtgm1OUNA_1.mid\n",
      "0.030110836029052734\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_GwdQliEv6Z0_1.mid\n",
      "0.022111892700195312\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_2eIsQtm4YNs_1.mid\n",
      "0.019547462463378906\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JP3QKZlyQz4_2.mid\n",
      "0.009412288665771484\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_qRceKZtwRWA_1.mid\n",
      "0.01780557632446289\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D-gDPh9ZpFk_1.mid\n",
      "0.03798174858093262\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Ie5koh4qvJc_6.mid\n",
      "0.03587055206298828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_RaUSISlnhKw_0.mid\n",
      "0.019093036651611328\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_3_MxhSS86oU_0.mid\n",
      "0.04151630401611328\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_0.mid\n",
      "0.025985002517700195\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_o5AIp2Yc01M_1.mid\n",
      "0.04452252388000488\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HYVmgq5Y93g_2.mid\n",
      "0.015625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FUAK5TBaNY8_0.mid\n",
      "0.02423882484436035\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_2.mid\n",
      "0.008340597152709961\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Xf2fox7zhCQ_1.mid\n",
      "0.014073848724365234\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_epMOLn5Axw0_0.mid\n",
      "0.0222628116607666\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_7gifuoofgpk_0.mid\n",
      "0.014078140258789062\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nBIls0laAAU_1.mid\n",
      "0.020016193389892578\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_4.mid\n",
      "0.030517101287841797\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OgkB7PfqWzA_0.mid\n",
      "0.009566068649291992\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_p2qihp_PnLY_0.mid\n",
      "0.027297019958496094\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_2v6gJi03LlA_0.mid\n",
      "0.01792454719543457\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_dCoUuknChhE_0.mid\n",
      "0.009417533874511719\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UOSlDydo94E_1.mid\n",
      "0.016775131225585938\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1Qc15G0ZHIg_0.mid\n",
      "0.013472795486450195\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_7JIdJLkJ0S4_2.mid\n",
      "0.015445947647094727\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_x5ibvz38jOs_1.mid\n",
      "0.030140399932861328\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__BK2o77sTc0_1.mid\n",
      "0.023846864700317383\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_z5ewpQwGDNw_2.mid\n",
      "0.023941993713378906\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_5CEAeMiXKaA_0.mid\n",
      "0.018035888671875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_sEQf5lcnj_o_2.mid\n",
      "0.05834841728210449\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_VrWAZLRdQO8_1.mid\n",
      "0.008023977279663086\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_11.mid\n",
      "0.044374704360961914\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_j8Ir-ssM-AA_0.mid\n",
      "0.03489828109741211\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_1.mid\n",
      "0.006755352020263672\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_jziI_cuN_H8_0.mid\n",
      "0.027240991592407227\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_3.mid\n",
      "0.017592191696166992\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_10.mid\n",
      "0.013721942901611328\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ivCNV47tsRw_2.mid\n",
      "0.057219505310058594\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_PXOWy7NiZhk_0.mid\n",
      "0.022324323654174805\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wS0RzrBL9UI_2.mid\n",
      "0.027457237243652344\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_2Z9SjI131jA_5.mid\n",
      "0.014015913009643555\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_0.mid\n",
      "0.022786855697631836\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_DYBBfpEx-JI_1.mid\n",
      "0.02450704574584961\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GbUV3TXUzeQ_2.mid\n",
      "0.035696983337402344\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JMt4m608s3k_2.mid\n",
      "0.038904666900634766\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8rupdevqfuI_1.mid\n",
      "0.015262603759765625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ii1Jw1-7Ka4_2.mid\n",
      "0.028357267379760742\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_QJlnTN7HRwE_1.mid\n",
      "0.01005101203918457\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1vjy9oMFa8c_3.mid\n",
      "0.010043144226074219\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_K84TcgjCRt4_1.mid\n",
      "0.016854524612426758\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_tLmXAWfbGqs_0.mid\n",
      "0.016414880752563477\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_12tDlCQVRtA_2.mid\n",
      "0.021146297454833984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_CkjAksZstEA_1.mid\n",
      "0.013422250747680664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_CkjAksZstEA_0.mid\n",
      "0.009911298751831055\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_5.mid\n",
      "0.04311180114746094\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_22.mid\n",
      "0.014794111251831055\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jrVXitpLGMk_0.mid\n",
      "0.02146434783935547\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_NTI9ode6bRk_1.mid\n",
      "0.01885080337524414\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jrVXitpLGMk_1.mid\n",
      "0.03359699249267578\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1A9Hh2GrDTs_0.mid\n",
      "0.022245168685913086\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0c2dTJTDUR4_0.mid\n",
      "0.008485555648803711\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5J_zI7QE9W8_0.mid\n",
      "0.02288651466369629\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kMHiU0fhWVw_0.mid\n",
      "0.015607357025146484\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_78C_TpQDvVE_0.mid\n",
      "0.011572837829589844\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_x4B0raxVODA_3.mid\n",
      "0.009707927703857422\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_1.mid\n",
      "0.01466989517211914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_k4dxAlI5N-k_0.mid\n",
      "0.043706417083740234\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ADJ_PDauy-g_1.mid\n",
      "0.022203445434570312\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_fuCxYrru2S4_0.mid\n",
      "0.018248796463012695\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_VCSDjQxAJzc_2.mid\n",
      "0.010303020477294922\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_4.mid\n",
      "0.007424831390380859\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_VXgRfsVd_o0_0.mid\n",
      "0.013797998428344727\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_sEQf5lcnj_o_0.mid\n",
      "0.03960847854614258\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cm6E860vDjY_0.mid\n",
      "0.0342555046081543\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_UuLTvhERcnk_0.mid\n",
      "0.014050006866455078\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_k4dxAlI5N-k_1.mid\n",
      "0.06702494621276855\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_egYSmNuIFGk_0.mid\n",
      "0.021567821502685547\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_QmK_SND2jAw_1.mid\n",
      "0.04622793197631836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_I2MrA-o5H8I_2.mid\n",
      "0.03447222709655762\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Adil-zpJdEs_0.mid\n",
      "0.034802913665771484\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltNK_MY1HkM_1.mid\n",
      "0.006646156311035156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_170KC2CbJ7Y_1.mid\n",
      "0.013718605041503906\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_NGE9ynTJABg_2.mid\n",
      "0.023447513580322266\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_g15aRCHUJEI_1.mid\n",
      "0.012830257415771484\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_0.mid\n",
      "0.009518861770629883\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_GAvPwG2wYZM_1.mid\n",
      "0.01629328727722168\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_3.mid\n",
      "0.014696836471557617\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_1.mid\n",
      "0.014683008193969727\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_8c7kcmsnf-s_0.mid\n",
      "0.0322568416595459\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_gwmVjvR-sVs_0.mid\n",
      "0.027750492095947266\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_dfNdpy8TUzA_0.mid\n",
      "0.013269186019897461\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OyaY4213c2A_0.mid\n",
      "0.023331403732299805\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Gcbk0GPT3-g_1.mid\n",
      "0.01562047004699707\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_77z6Ep3aOmg_1.mid\n",
      "0.02645707130432129\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zHwJG8Rrx6c_3.mid\n",
      "0.02015399932861328\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_z5ewpQwGDNw_1.mid\n",
      "0.01673746109008789\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_biROWEwkDQQ_2.mid\n",
      "0.013431549072265625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_uqRLEByE6pU_0.mid\n",
      "0.04012131690979004\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_gvWDOIiocuE_2.mid\n",
      "0.012455224990844727\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jTPXwbDtIpA_1.mid\n",
      "0.048122406005859375\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_iFgSjUqI7iM_0.mid\n",
      "0.02449822425842285\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_NP0lwB-_-og_1.mid\n",
      "0.03317546844482422\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_5NW0zDu6IYM_1.mid\n",
      "0.03842806816101074\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_16OaOpfOPZ0_0.mid\n",
      "0.018910646438598633\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_B3aRl8iTEKw_0.mid\n",
      "0.022763729095458984\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0J7lX-Tcx-w_0.mid\n",
      "0.023058652877807617\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_veG92Oi-DlU_2.mid\n",
      "0.015486001968383789\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_nOIBJHkqrE8_1.mid\n",
      "0.023743391036987305\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wxXpvnmq_-E_0.mid\n",
      "0.0159609317779541\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_bfopzItCYrE_1.mid\n",
      "0.02057623863220215\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ivCNV47tsRw_3.mid\n",
      "0.03311729431152344\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_JMt4m608s3k_1.mid\n",
      "0.034125566482543945\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wlOa1jkTn_U_2.mid\n",
      "0.012993335723876953\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_MT2_mXn-vGU_1.mid\n",
      "0.018244504928588867\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_0c2dTJTDUR4_1.mid\n",
      "0.012831687927246094\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_RiQMuhk_SuQ_3.mid\n",
      "0.16171932220458984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_VCSDjQxAJzc_0.mid\n",
      "0.018818378448486328\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_1.mid\n",
      "0.012292146682739258\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_PdwxeMPXOCk_0.mid\n",
      "0.03264164924621582\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_sA9ac1rod84_1.mid\n",
      "0.024938583374023438\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_4.mid\n",
      "0.026513338088989258\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_e838BE_MH6s_0.mid\n",
      "0.023938417434692383\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_j8Ir-ssM-AA_1.mid\n",
      "0.017017364501953125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_RiQMuhk_SuQ_1.mid\n",
      "0.03998160362243652\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GbUV3TXUzeQ_1.mid\n",
      "0.028690099716186523\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5DqIntcmdRI_0.mid\n",
      "0.03265190124511719\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_IH2KrGjKXw0_2.mid\n",
      "0.01373434066772461\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_mlHheZbblT0_0.mid\n",
      "0.03111410140991211\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_5.mid\n",
      "0.030667781829833984\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_4Er-eFHSHA4_0.mid\n",
      "0.015171051025390625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_8TYY0qG-KOw_1.mid\n",
      "0.02677154541015625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_3ZnxqCZ7qGg_1.mid\n",
      "0.018042802810668945\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_heBmBQDWj-M_1.mid\n",
      "0.021021127700805664\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yhIncZ_Ue4E_2.mid\n",
      "0.020343303680419922\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ItGNJM6skM4_1.mid\n",
      "0.05486297607421875\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_16OaOpfOPZ0_2.mid\n",
      "0.029381513595581055\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_V_jbWvQNh5c_0.mid\n",
      "0.009491682052612305\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zjr_-ql5Avk_0.mid\n",
      "0.0063092708587646484\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_OCqMDeD6Fmc_3.mid\n",
      "0.04684758186340332\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_02t1bj7ZABY_2.mid\n",
      "0.018793821334838867\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_MbvPxCUMSek_2.mid\n",
      "0.008587837219238281\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UpHutdJvZMI_1.mid\n",
      "0.021586179733276367\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_4.mid\n",
      "0.01985025405883789\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D5kyjnlDNZs_2.mid\n",
      "0.05713701248168945\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rDhbGjFlKF8_0.mid\n",
      "0.01846909523010254\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_im4Qxn3GQvo_2.mid\n",
      "0.02508234977722168\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1fdxsFbnsX4_1.mid\n",
      "0.01599717140197754\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_MbvPxCUMSek_0.mid\n",
      "0.01207876205444336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_7.mid\n",
      "0.03484201431274414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_g-yM0Lsp4lc_1.mid\n",
      "0.007976293563842773\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ufRISSD28XA_0.mid\n",
      "0.019537687301635742\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltxNPJda7zE_3.mid\n",
      "0.016598939895629883\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_3.mid\n",
      "0.01460886001586914\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_BaHHHgDd0BU_1.mid\n",
      "0.025866270065307617\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_J6X3rVU1H-c_0.mid\n",
      "0.009698867797851562\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_HY9vPoHbgaI_3.mid\n",
      "0.01299142837524414\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e838BE_MH6s_1.mid\n",
      "0.01822638511657715\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_biROWEwkDQQ_3.mid\n",
      "0.022170305252075195\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3TYeU9idRGI_1.mid\n",
      "0.007778167724609375\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Wy2-my19YnY_1.mid\n",
      "0.026107072830200195\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UE0y8MHqT-g_1.mid\n",
      "0.04338383674621582\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_1Q3MoBFh6eU_0.mid\n",
      "0.018227577209472656\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_QJlnTN7HRwE_3.mid\n",
      "0.013860702514648438\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_r6laJv1-HMg_0.mid\n",
      "0.025954246520996094\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3As1t6JySDE_0.mid\n",
      "0.020559072494506836\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_nBIls0laAAU_0.mid\n",
      "0.01949286460876465\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_f2BXXa7lPuE_2.mid\n",
      "0.04210376739501953\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_30.mid\n",
      "0.02478504180908203\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_By3JCii1k3w_1.mid\n",
      "0.014813423156738281\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_NGE9ynTJABg_0.mid\n",
      "0.04018735885620117\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_OCqMDeD6Fmc_1.mid\n",
      "0.031141996383666992\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JxSU49jFKwM_0.mid\n",
      "0.016210556030273438\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wxXpvnmq_-E_1.mid\n",
      "0.01314997673034668\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_4.mid\n",
      "0.011052846908569336\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltNK_MY1HkM_0.mid\n",
      "0.00890803337097168\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FH28sPhm9Dc_0.mid\n",
      "0.017635107040405273\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_rEz0D3VohFA_1.mid\n",
      "0.036473989486694336\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yrvKReuwVlY_1.mid\n",
      "0.012639760971069336\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_QwsQ8ejbMKg_1.mid\n",
      "0.020775318145751953\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_S1T3UF1vhSk_0.mid\n",
      "0.035547494888305664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HQ8ISDX6PiI_0.mid\n",
      "0.022357940673828125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JT1XJnVmABo_5.mid\n",
      "0.019643545150756836\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_9eMxCs-LXCE_1.mid\n",
      "0.011913776397705078\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_YhXRyOl5pi0_0.mid\n",
      "0.02594137191772461\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_kfYaGryaGzI_1.mid\n",
      "0.005980491638183594\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GY3f6ckBVkA_3.mid\n",
      "0.020920753479003906\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iXiSFSGws-c_2.mid\n",
      "0.01628899574279785\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_WQrPcuy50aA_0.mid\n",
      "0.027982711791992188\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Dg935IbDggo_2.mid\n",
      "0.02905726432800293\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Dg935IbDggo_3.mid\n",
      "0.04644632339477539\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_wnB2cjd6zbE_0.mid\n",
      "0.035355567932128906\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_8c7kcmsnf-s_2.mid\n",
      "0.03483438491821289\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bIx4DwkZxFY_1.mid\n",
      "0.023009538650512695\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_08t73Qgjkt4_0.mid\n",
      "0.02200174331665039\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cm6E860vDjY_1.mid\n",
      "0.04129171371459961\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_5NW0zDu6IYM_0.mid\n",
      "0.025582075119018555\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JYVXM0qNQAg_2.mid\n",
      "0.021446943283081055\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_v3Nl5rUxLqE_0.mid\n",
      "0.012886285781860352\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ijfxkQPAQdE_1.mid\n",
      "0.07106757164001465\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UaYYMRkHMYc_2.mid\n",
      "0.021783113479614258\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1vjy9oMFa8c_0.mid\n",
      "0.020719051361083984\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__FVzelKlBFs_1.mid\n",
      "0.05076742172241211\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_MT2_mXn-vGU_2.mid\n",
      "0.015283584594726562\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_vVTP0DOL_2Q_2.mid\n",
      "0.017475366592407227\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6Uf9XBUD3wE_1.mid\n",
      "0.04710793495178223\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_4ydjOX3pWds_1.mid\n",
      "0.019295215606689453\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_28.mid\n",
      "0.02149176597595215\n",
      "data/emopia/EMOPIA_2.2/midis/Q3__S991V8N-8s_0.mid\n",
      "0.025908946990966797\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iXiSFSGws-c_0.mid\n",
      "0.017687320709228516\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zmZHNy9T8Pg_1.mid\n",
      "0.03915596008300781\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3ahg_eQZhxs_0.mid\n",
      "0.02893209457397461\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__FVzelKlBFs_0.mid\n",
      "0.03968524932861328\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_27.mid\n",
      "0.025271177291870117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_biROWEwkDQQ_0.mid\n",
      "0.01755046844482422\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_8.mid\n",
      "0.031232357025146484\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_sZe3IB1OVfw_1.mid\n",
      "0.020543813705444336\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_PXOWy7NiZhk_1.mid\n",
      "0.013751983642578125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_REq37pDAm3A_2.mid\n",
      "0.014049768447875977\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tjno89OVuRI_0.mid\n",
      "0.016102313995361328\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_8c7kcmsnf-s_1.mid\n",
      "0.15314960479736328\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_2.mid\n",
      "0.026445627212524414\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_veG92Oi-DlU_1.mid\n",
      "0.018141746520996094\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3N2G21U7guk_6.mid\n",
      "0.03122568130493164\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_2v6gJi03LlA_1.mid\n",
      "0.026453495025634766\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_bfopzItCYrE_0.mid\n",
      "0.011415958404541016\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_6oLmO9ZSJt0_0.mid\n",
      "0.03549456596374512\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_x4B0raxVODA_0.mid\n",
      "0.007146358489990234\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k4lT-sXg3iI_0.mid\n",
      "0.02086615562438965\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_5Ju9q1N2x0E_2.mid\n",
      "0.04533529281616211\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_dtS02mrDMsM_0.mid\n",
      "0.013941764831542969\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_fuCxYrru2S4_2.mid\n",
      "0.032999515533447266\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_14.mid\n",
      "0.015038728713989258\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_d_49EtXDMFE_0.mid\n",
      "0.014189958572387695\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jTPXwbDtIpA_2.mid\n",
      "0.04248642921447754\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vpTguZtJAFA_0.mid\n",
      "0.014455795288085938\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_08t73Qgjkt4_1.mid\n",
      "0.016355276107788086\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_22S3w4idugs_0.mid\n",
      "0.011944293975830078\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_TOXg4-ZGb-g_1.mid\n",
      "0.011169672012329102\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_13.mid\n",
      "0.05463981628417969\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_7JIdJLkJ0S4_0.mid\n",
      "0.021318912506103516\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_nGkpcWNAxDU_0.mid\n",
      "0.02041339874267578\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_-_FjI4bT2Wo_1.mid\n",
      "0.019663095474243164\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_kDGmND1BgmA_0.mid\n",
      "0.007371425628662109\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_1.mid\n",
      "0.025811195373535156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_9v2WSpn4FCw_9.mid\n",
      "0.0178830623626709\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_G4rL_OtfFAU_0.mid\n",
      "0.03156280517578125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ANZf1QXsNrY_6.mid\n",
      "0.02226710319519043\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rW1I58_lMEg_0.mid\n",
      "0.017757892608642578\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_48EYLEAgaBc_1.mid\n",
      "0.005673408508300781\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Dw7M69CidJ8_2.mid\n",
      "0.04173135757446289\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UbKAl4roB8k_0.mid\n",
      "0.0245511531829834\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_2.mid\n",
      "0.015348434448242188\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6kRPHamGDSo_1.mid\n",
      "0.017706632614135742\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_7.mid\n",
      "0.03670072555541992\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_f2BXXa7lPuE_1.mid\n",
      "0.0385434627532959\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_PK8YIUaV3Xw_0.mid\n",
      "0.017747163772583008\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_prUUays30Mg_0.mid\n",
      "0.013361454010009766\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_0vLPYiPN7qY_2.mid\n",
      "0.0307769775390625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FUAK5TBaNY8_3.mid\n",
      "0.015024900436401367\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zHwJG8Rrx6c_0.mid\n",
      "0.014362573623657227\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KxlqB3j0zys_3.mid\n",
      "0.024919986724853516\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0lEL_XHyhuU_1.mid\n",
      "0.01213216781616211\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_NGE9ynTJABg_1.mid\n",
      "0.019473791122436523\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pkz8OkWhwnk_0.mid\n",
      "0.013709545135498047\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_TOXg4-ZGb-g_0.mid\n",
      "0.015529155731201172\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_1.mid\n",
      "0.013131380081176758\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zmZHNy9T8Pg_2.mid\n",
      "0.021057605743408203\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_11.mid\n",
      "0.048050880432128906\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_2.mid\n",
      "0.019168853759765625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_FfwKrQyQ7WU_0.mid\n",
      "0.02481532096862793\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_02t1bj7ZABY_0.mid\n",
      "0.006941080093383789\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_REq37pDAm3A_4.mid\n",
      "0.023721933364868164\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_0.mid\n",
      "0.016498804092407227\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ADJ_PDauy-g_2.mid\n",
      "0.016162872314453125\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_IH2KrGjKXw0_0.mid\n",
      "0.013135671615600586\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ZTrEoB8T9YA_1.mid\n",
      "0.021418094635009766\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_7yW9c7t8Hq0_0.mid\n",
      "0.010939359664916992\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_YAAxPW1GB7w_0.mid\n",
      "0.011691570281982422\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jCLgDtk695I_2.mid\n",
      "0.014198780059814453\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D-gDPh9ZpFk_0.mid\n",
      "0.0270845890045166\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_OyaY4213c2A_1.mid\n",
      "0.016461849212646484\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_QmK_SND2jAw_0.mid\n",
      "0.025519371032714844\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_3.mid\n",
      "0.022513866424560547\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_XC_SiJszQx0_3.mid\n",
      "0.03350520133972168\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_NTI9ode6bRk_0.mid\n",
      "0.01600503921508789\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8rupdevqfuI_0.mid\n",
      "0.02580404281616211\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_8.mid\n",
      "0.020154476165771484\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vJ77eDxHezE_0.mid\n",
      "0.027971744537353516\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_KxlqB3j0zys_0.mid\n",
      "0.015444278717041016\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_rEz0D3VohFA_0.mid\n",
      "0.008049964904785156\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_BzqX-9TA-GY_1.mid\n",
      "0.012157917022705078\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_fnqb8zqHqdY_2.mid\n",
      "0.01634693145751953\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_aYe-2Glruu4_1.mid\n",
      "0.045812129974365234\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_PdwxeMPXOCk_2.mid\n",
      "0.03144645690917969\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_DX1IK3z1w10_1.mid\n",
      "0.028702259063720703\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_By3JCii1k3w_0.mid\n",
      "0.01830911636352539\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_2.mid\n",
      "0.015561819076538086\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rW1I58_lMEg_3.mid\n",
      "0.027094125747680664\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_UAm0aWvzFI8_0.mid\n",
      "0.04784560203552246\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wfXSdMsd4q8_4.mid\n",
      "0.022722244262695312\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_sZe3IB1OVfw_0.mid\n",
      "0.021393299102783203\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_XfA2KXodrOE_1.mid\n",
      "0.034783124923706055\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_15.mid\n",
      "0.02396559715270996\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_0.mid\n",
      "0.040018558502197266\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_qlbazHayULg_8.mid\n",
      "0.04101133346557617\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_7JIdJLkJ0S4_1.mid\n",
      "0.028780698776245117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FoTXpYZXxJs_1.mid\n",
      "0.011516809463500977\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_--2B4d4lQhs_0.mid\n",
      "0.040921688079833984\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Y5JcZQ0xg4Y_2.mid\n",
      "0.02683258056640625\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_rDhbGjFlKF8_1.mid\n",
      "0.012804508209228516\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_ANZf1QXsNrY_4.mid\n",
      "0.028556108474731445\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ldCQ6N9G6Mk_0.mid\n",
      "0.005682945251464844\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_TNoaOTrTkTQ_0.mid\n",
      "0.03531765937805176\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_38i12IPkL5c_0.mid\n",
      "0.024992942810058594\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_X1p8xcarVu0_1.mid\n",
      "0.0161283016204834\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UpHutdJvZMI_2.mid\n",
      "0.020484209060668945\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_V3Y9L4UOcpk_0.mid\n",
      "0.0165712833404541\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_20.mid\n",
      "0.02137470245361328\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_osxmQReE_2o_0.mid\n",
      "0.028037309646606445\n",
      "data/emopia/EMOPIA_2.2/midis/Q4__BK2o77sTc0_2.mid\n",
      "0.026222944259643555\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_4dXC1cC7crw_0.mid\n",
      "0.023981094360351562\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_QJlnTN7HRwE_2.mid\n",
      "0.010531187057495117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_pRuwHN-lI44_1.mid\n",
      "0.016714096069335938\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_q4T8Znozvkk_0.mid\n",
      "0.012818098068237305\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UaYYMRkHMYc_1.mid\n",
      "0.04290771484375\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_4.mid\n",
      "0.012509822845458984\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_-jJVb0xvbdg_1.mid\n",
      "0.043816328048706055\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_23.mid\n",
      "0.021607637405395508\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_94ROf10d1iA_3.mid\n",
      "0.02634739875793457\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_uj3Gif77SYM_6.mid\n",
      "0.02593708038330078\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FSzOgraSKhs_0.mid\n",
      "0.011385917663574219\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_lTxVVdhFE6Q_1.mid\n",
      "0.01869058609008789\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wqc8iqbDsGM_4.mid\n",
      "0.01789069175720215\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_170KC2CbJ7Y_0.mid\n",
      "0.02056598663330078\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zHwJG8Rrx6c_2.mid\n",
      "0.0291140079498291\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_4.mid\n",
      "0.04053831100463867\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_yC0fAQxGgr0_1.mid\n",
      "0.028002500534057617\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zMa78n8ULtE_0.mid\n",
      "0.010989189147949219\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_UaYYMRkHMYc_0.mid\n",
      "0.04303455352783203\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_FfwKrQyQ7WU_2.mid\n",
      "0.017770051956176758\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_cQp1BYDGcRo_0.mid\n",
      "0.03661012649536133\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_xgtwQGeB6_0_0.mid\n",
      "0.0195162296295166\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_hoPp_GLXQis_0.mid\n",
      "0.02509284019470215\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_RaUSISlnhKw_1.mid\n",
      "0.03824019432067871\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ury1cdB79s0_1.mid\n",
      "0.024415016174316406\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zvWX_dwQPtU_2.mid\n",
      "0.13769245147705078\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_IH2KrGjKXw0_1.mid\n",
      "0.02017664909362793\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iHPKusssXzk_0.mid\n",
      "0.02047133445739746\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_kKFwiXKlhC8_0.mid\n",
      "0.023561477661132812\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_k4lT-sXg3iI_1.mid\n",
      "0.022405147552490234\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltxNPJda7zE_0.mid\n",
      "0.008642435073852539\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_XWk5XUEBXmg_1.mid\n",
      "0.018098831176757812\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_yC0fAQxGgr0_0.mid\n",
      "0.015779733657836914\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Tjno89OVuRI_1.mid\n",
      "0.01933431625366211\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ldCQ6N9G6Mk_3.mid\n",
      "0.017486572265625\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_3ZnxqCZ7qGg_2.mid\n",
      "0.022606611251831055\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_biROWEwkDQQ_1.mid\n",
      "0.02213883399963379\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_P-We4q3goKU_6.mid\n",
      "0.03252243995666504\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_cXxGBDgFCs8_1.mid\n",
      "0.012979507446289062\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_E5qEloUO3SM_1.mid\n",
      "0.017228364944458008\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_uqRLEByE6pU_1.mid\n",
      "0.016815185546875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_aYe-2Glruu4_3.mid\n",
      "0.022054672241210938\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_48EYLEAgaBc_0.mid\n",
      "0.007827043533325195\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_yFw_kO7DF-Y_2.mid\n",
      "0.0424196720123291\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_k6aLLVX1D7Y_2.mid\n",
      "0.017677783966064453\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_bfopzItCYrE_2.mid\n",
      "0.016717910766601562\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_29.mid\n",
      "0.0070743560791015625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ItGNJM6skM4_0.mid\n",
      "0.040973663330078125\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JP3QKZlyQz4_1.mid\n",
      "0.011215925216674805\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_GbUV3TXUzeQ_0.mid\n",
      "0.01986980438232422\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_T92R7xjce34_0.mid\n",
      "0.01929640769958496\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_D5kyjnlDNZs_1.mid\n",
      "0.037656545639038086\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jIKX3ShvLxo_2.mid\n",
      "0.04536771774291992\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Ie5koh4qvJc_26.mid\n",
      "0.020727157592773438\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_REq37pDAm3A_1.mid\n",
      "0.017111539840698242\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_iRu9KQvbtVw_0.mid\n",
      "0.019473791122436523\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_l-4Kce3YxxQ_2.mid\n",
      "0.04680585861206055\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Y1F0c3zgMJo_0.mid\n",
      "0.015765905380249023\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_BIRDDxz0E4c_0.mid\n",
      "0.01398777961730957\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_pouxqiySdI8_0.mid\n",
      "0.023932933807373047\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_3.mid\n",
      "0.039859771728515625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_doM_LWo-74A_0.mid\n",
      "0.02121567726135254\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FOcdHIhI0_s_0.mid\n",
      "0.00943303108215332\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ijfxkQPAQdE_0.mid\n",
      "0.0544581413269043\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_uUtnyA6tLnI_0.mid\n",
      "0.022555828094482422\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_aQ4PIaRMLwE_2.mid\n",
      "0.027657747268676758\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_SQDuF0qxGQw_0.mid\n",
      "0.021638154983520508\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_k6aLLVX1D7Y_0.mid\n",
      "0.025290489196777344\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8rupdevqfuI_2.mid\n",
      "0.01748514175415039\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_94ROf10d1iA_1.mid\n",
      "0.015517234802246094\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yZGBxiNPu3k_0.mid\n",
      "0.030757904052734375\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_pbVGv_g4n50_0.mid\n",
      "0.007882356643676758\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_6kRPHamGDSo_0.mid\n",
      "0.016803741455078125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_1Qc15G0ZHIg_2.mid\n",
      "0.03102254867553711\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_JNzqL24ZcZ8_1.mid\n",
      "0.01897120475769043\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_a5QCcwEjxAk_1.mid\n",
      "0.013047933578491211\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_heBmBQDWj-M_0.mid\n",
      "0.0195467472076416\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_UE0y8MHqT-g_0.mid\n",
      "0.016771554946899414\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JYVXM0qNQAg_0.mid\n",
      "0.0222017765045166\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_DYBBfpEx-JI_4.mid\n",
      "0.017510175704956055\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bIx4DwkZxFY_2.mid\n",
      "0.016980886459350586\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S7Bo4-NCEDk_0.mid\n",
      "0.041964054107666016\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Uu-oRTRT6uQ_2.mid\n",
      "0.028028249740600586\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_--2B4d4lQhs_3.mid\n",
      "0.016082763671875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_8izVTDgBQPc_1.mid\n",
      "0.023128032684326172\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_o5AIp2Yc01M_0.mid\n",
      "0.029787778854370117\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_9Xg69XrVaYU_0.mid\n",
      "0.021561622619628906\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_OO7zYVeK814_0.mid\n",
      "0.014461755752563477\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_nGkpcWNAxDU_1.mid\n",
      "0.026621580123901367\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_NzJjMGJg1wE_0.mid\n",
      "0.01695394515991211\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jO2zX6Ul8GM_2.mid\n",
      "0.016675233840942383\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_TonQX8XbvX8_3.mid\n",
      "0.015267133712768555\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_vv6nrZ2myXw_1.mid\n",
      "0.02652716636657715\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_bbU31JLtlug_0.mid\n",
      "0.027599096298217773\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e838BE_MH6s_2.mid\n",
      "0.031016111373901367\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Wy2-my19YnY_0.mid\n",
      "0.026191234588623047\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_0vLPYiPN7qY_0.mid\n",
      "0.01608586311340332\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HYVmgq5Y93g_1.mid\n",
      "0.018201589584350586\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_yhIncZ_Ue4E_1.mid\n",
      "0.016449928283691406\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ilCcZpD39HU_3.mid\n",
      "0.018121004104614258\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_18.mid\n",
      "0.018428325653076172\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_5Ju9q1N2x0E_0.mid\n",
      "0.02491617202758789\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_G4rL_OtfFAU_1.mid\n",
      "0.058621883392333984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_6kRPHamGDSo_2.mid\n",
      "0.01645636558532715\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zjr_-ql5Avk_2.mid\n",
      "0.006077289581298828\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_2uLw9Zs60A4_0.mid\n",
      "0.022823333740234375\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_14.mid\n",
      "0.016497373580932617\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_yFw_kO7DF-Y_0.mid\n",
      "0.031126976013183594\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_egYSmNuIFGk_1.mid\n",
      "0.01895618438720703\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vJ77eDxHezE_1.mid\n",
      "0.02652144432067871\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_5.mid\n",
      "0.03067922592163086\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_4.mid\n",
      "0.03203296661376953\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_RL_cmmNVLfs_0.mid\n",
      "0.013698101043701172\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1Q3MoBFh6eU_1.mid\n",
      "0.030938148498535156\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Iq6g_4AwUWs_1.mid\n",
      "0.023535728454589844\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_JT1XJnVmABo_4.mid\n",
      "0.018114805221557617\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ANZf1QXsNrY_7.mid\n",
      "0.038178443908691406\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_xIsvaT20pZ0_0.mid\n",
      "0.018393516540527344\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_gvWDOIiocuE_1.mid\n",
      "0.035239219665527344\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_9v2WSpn4FCw_1.mid\n",
      "0.0137481689453125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_zmZHNy9T8Pg_0.mid\n",
      "0.021750211715698242\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JT1XJnVmABo_0.mid\n",
      "0.017760038375854492\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_iFgSjUqI7iM_1.mid\n",
      "0.021390914916992188\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_zMa78n8ULtE_1.mid\n",
      "0.009026527404785156\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_2.mid\n",
      "0.01761603355407715\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jSWItJI-Gmk_0.mid\n",
      "0.01727747917175293\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__8v0MFBZoco_1.mid\n",
      "0.03844261169433594\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_6n8HgIcJ6vo_0.mid\n",
      "0.012995004653930664\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_61EA0xRX8gE_3.mid\n",
      "0.04086017608642578\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_1vjy9oMFa8c_1.mid\n",
      "0.009875059127807617\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_H6_7DjsbROQ_4.mid\n",
      "0.01785135269165039\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_3N2G21U7guk_3.mid\n",
      "0.033394575119018555\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_wS0RzrBL9UI_1.mid\n",
      "0.013902664184570312\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_0vLPYiPN7qY_3.mid\n",
      "0.032761573791503906\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S1T3UF1vhSk_2.mid\n",
      "0.021556615829467773\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_JT1XJnVmABo_1.mid\n",
      "0.020014047622680664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_vBHoSz8cJIE_1.mid\n",
      "0.01002359390258789\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s6-SbDSZzEU_1.mid\n",
      "0.02050638198852539\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_ItGNJM6skM4_2.mid\n",
      "0.05107474327087402\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_lFznCt5kvXM_0.mid\n",
      "0.049346923828125\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_aYe-2Glruu4_0.mid\n",
      "0.027573108673095703\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_fey-8bOR95E_3.mid\n",
      "0.16155529022216797\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_1kny88W533Q_0.mid\n",
      "0.011965513229370117\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_a5QCcwEjxAk_0.mid\n",
      "0.014034509658813477\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_FUAK5TBaNY8_2.mid\n",
      "0.01825690269470215\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_e838BE_MH6s_4.mid\n",
      "0.03394055366516113\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_u_7b9CwyM8Q_1.mid\n",
      "0.013124942779541016\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_REq37pDAm3A_0.mid\n",
      "0.01053619384765625\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_0.mid\n",
      "0.018734455108642578\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_WpZ1rWHOCAQ_1.mid\n",
      "0.015437602996826172\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Oku8sIpTMAE_3.mid\n",
      "0.016042470932006836\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S1T3UF1vhSk_1.mid\n",
      "0.012879610061645508\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_3.mid\n",
      "0.020756959915161133\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_9v2WSpn4FCw_4.mid\n",
      "0.0730276107788086\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_-vAz_HTFEXs_1.mid\n",
      "0.01842665672302246\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_fey-8bOR95E_2.mid\n",
      "0.0276947021484375\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_aYe-2Glruu4_2.mid\n",
      "0.03928232192993164\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_sEQf5lcnj_o_3.mid\n",
      "0.05230140686035156\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_mGYKWCVnMwQ_0.mid\n",
      "0.019385337829589844\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_J6X3rVU1H-c_2.mid\n",
      "0.03357863426208496\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Ie5koh4qvJc_32.mid\n",
      "0.01705622673034668\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_JT1XJnVmABo_2.mid\n",
      "0.011362075805664062\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_oTi57hZfArE_2.mid\n",
      "0.01345205307006836\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Y5JcZQ0xg4Y_0.mid\n",
      "0.010263204574584961\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_HQ8ISDX6PiI_1.mid\n",
      "0.02640223503112793\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_iXiSFSGws-c_1.mid\n",
      "0.019403696060180664\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Dw7M69CidJ8_3.mid\n",
      "0.0077702999114990234\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3N2G21U7guk_0.mid\n",
      "0.008243560791015625\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_pNwQ9Tu_bCs_0.mid\n",
      "0.01985478401184082\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_bQS8eAXAhyE_1.mid\n",
      "0.01638340950012207\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_P-We4q3goKU_0.mid\n",
      "0.016581296920776367\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_jNzZCplNNyY_1.mid\n",
      "0.0243072509765625\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_ltxNPJda7zE_4.mid\n",
      "0.007395029067993164\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_ii1Jw1-7Ka4_0.mid\n",
      "0.005931854248046875\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_UOSlDydo94E_2.mid\n",
      "0.026406288146972656\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_Cir1kZyB7QM_1.mid\n",
      "0.010077476501464844\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_11.mid\n",
      "0.01781773567199707\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_vVTP0DOL_2Q_0.mid\n",
      "0.013453245162963867\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_HY9vPoHbgaI_0.mid\n",
      "0.015659093856811523\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__SJQaaRzD-A_0.mid\n",
      "0.02113032341003418\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_lalnGhxT3PQ_1.mid\n",
      "0.03674936294555664\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_qlbazHayULg_10.mid\n",
      "0.03307294845581055\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_c6CwY8Gbw0c_1.mid\n",
      "0.01969122886657715\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_9Xg69XrVaYU_1.mid\n",
      "0.019379615783691406\n",
      "data/emopia/EMOPIA_2.2/midis/Q1__BK2o77sTc0_0.mid\n",
      "0.0235440731048584\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_gSwv8hZGM-s_1.mid\n",
      "0.02188563346862793\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_OCqMDeD6Fmc_2.mid\n",
      "0.04817390441894531\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_MbvPxCUMSek_1.mid\n",
      "0.008289098739624023\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_DvIH5yUrboc_2.mid\n",
      "0.028623104095458984\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_3N2G21U7guk_2.mid\n",
      "0.007923603057861328\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_kKFwiXKlhC8_1.mid\n",
      "0.04593372344970703\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_lalnGhxT3PQ_0.mid\n",
      "0.03400135040283203\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_QBJ6YYYpIyk_0.mid\n",
      "0.014148712158203125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_sEQf5lcnj_o_1.mid\n",
      "0.050452470779418945\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_UuLTvhERcnk_1.mid\n",
      "0.02118682861328125\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_epX33OVpkmA_0.mid\n",
      "0.04381752014160156\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_fnqb8zqHqdY_0.mid\n",
      "0.014894962310791016\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_kopwU6zpS4k_0.mid\n",
      "0.011057138442993164\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_WpZ1rWHOCAQ_2.mid\n",
      "0.026293039321899414\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_Q5b5unyP8BM_1.mid\n",
      "0.052095651626586914\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_jIKX3ShvLxo_0.mid\n",
      "0.03424572944641113\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_AWNbcxXDmt0_0.mid\n",
      "0.03218364715576172\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_gSwv8hZGM-s_0.mid\n",
      "0.04022932052612305\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_S7Bo4-NCEDk_2.mid\n",
      "0.019675254821777344\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_I2MrA-o5H8I_0.mid\n",
      "0.025026559829711914\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_GY3f6ckBVkA_2.mid\n",
      "0.028330326080322266\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_FyK_c-TIcCA_1.mid\n",
      "0.028917312622070312\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_3_MxhSS86oU_1.mid\n",
      "0.04178738594055176\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_0J7lX-Tcx-w_1.mid\n",
      "0.03826618194580078\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_2eIsQtm4YNs_0.mid\n",
      "0.016847848892211914\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_GAvPwG2wYZM_0.mid\n",
      "0.010319232940673828\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_Fc1qk52SaKY_1.mid\n",
      "0.027596712112426758\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_mX-xs3OVhTs_0.mid\n",
      "0.016206979751586914\n",
      "data/emopia/EMOPIA_2.2/midis/Q2__S991V8N-8s_1.mid\n",
      "0.026610851287841797\n",
      "data/emopia/EMOPIA_2.2/midis/Q2_--2B4d4lQhs_2.mid\n",
      "0.050870656967163086\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_yFw_kO7DF-Y_1.mid\n",
      "0.028487682342529297\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_2Z9SjI131jA_1.mid\n",
      "0.018571138381958008\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_gwmVjvR-sVs_2.mid\n",
      "0.00871729850769043\n",
      "data/emopia/EMOPIA_2.2/midis/Q4_KxlqB3j0zys_2.mid\n",
      "0.019926071166992188\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_Ie5koh4qvJc_25.mid\n",
      "0.023488759994506836\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_s5b8viFsVJE_0.mid\n",
      "0.029706716537475586\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_miqLU2739dk_1.mid\n",
      "0.036726951599121094\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_0vLPYiPN7qY_1.mid\n",
      "0.035039424896240234\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_V3Y9L4UOcpk_2.mid\n",
      "0.02931666374206543\n",
      "data/emopia/EMOPIA_2.2/midis/Q3_gvWDOIiocuE_0.mid\n",
      "0.017794132232666016\n",
      "data/emopia/EMOPIA_2.2/midis/Q1_nOIBJHkqrE8_0.mid\n",
      "0.02112436294555664\n"
     ]
    }
   ],
   "source": [
    "encoded_sequences_path = \"data/encoded_sequences.pkl\"\n",
    "encoded_sequences = midi_encoder.encode_midi_list(midi_files_list, pkl_path=encoded_sequences_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the dataset and save it in a NumPy file\n",
    "dataset_path = \"data/datasets/\"\n",
    "midi_encoder_remi.save_dataset(midi_files_list, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/venv/lib/python3.8/site-packages/numpy/lib/npyio.py:696: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val = np.asanyarray(val)\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset as a single file\n",
    "single_file_dataset_path = \"data/single_file_dataset.npz\"\n",
    "midi_encoder_remi.save_dataset_as_single_file(glob.glob(os.path.join(dataset_path, '*.npy')), single_file_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ece661-final-proj2/data/dataset.py:170: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  self.sequences = torch.Tensor(self.sequences)\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 256\n",
    "dataset = TransformerDatasetREMI(single_file_dataset_path, seq_len=max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))\n",
    "valid_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - valid_size\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  3507\n",
      "Validation dataset size:  751\n",
      "Test dataset size:  753\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset size: \", len(train_dataset))\n",
    "print(\"Validation dataset size: \", len(valid_dataset))\n",
    "print(\"Test dataset size: \", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size:  54\n",
      "Validation dataset size:  11\n",
      "Test dataset size:  11\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "print(\"Train dataset size: \", len(train_dataloader))\n",
    "print(\"Validation dataset size: \", len(valid_dataloader))\n",
    "print(\"Test dataset size: \", len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ids', 'input', 'target', 'input_mask', 'target_mask'])\n",
      "tensor([602])\n",
      "tensor([ 40,  94,  24,   3,  53,  76,  19,   3,  17,  84,  64,   3,   7, 112,\n",
      "         61,  49,  53,  76,  61,  81,  40,  74,  61,  81,  75, 112,  61,  81,\n",
      "         73, 113,  61,   6,  56,  94,  15,   6,  73,  76, 166,  34,   7,  82,\n",
      "        147,  34,  53,  25, 134,  34,   7, 112,  61,  20,  40, 112,  83,  20,\n",
      "          7,  74, 134,  43,  10, 112,  52,  43,   7,  27,  50,  59,   7,  88,\n",
      "        134,   2,   3,  44,  36, 127,   3,  10, 112,  61,   3,  37,  33, 127,\n",
      "         81,  10, 112,  61,  81,   7,  27,  52,  81,  44,  25,  80,  12,   7,\n",
      "        112,  64,  12,  17,  74,  52,  12,  53, 114,  64,  20,   7,  60,  72,\n",
      "         20,  10,  82,  83,  43,  40,  29,  61,  43,  10,  74, 127,  59,   7,\n",
      "         27, 137,  59,  53,  76, 127,  59,  42,  41,  61,   2,  49,  10,  84,\n",
      "        137,  49,  40,  41,  64,  81,   7,  90,  64,  12,   7,  74,  50,  12,\n",
      "          7,  28,  64,  12,   7,  41,  61,  20,  56,  41,  61,  20,  42,  27,\n",
      "         80,  39,  44,  90,  50,  43,  40,  28,   9,  43,   7,  41,  61,  43,\n",
      "         10,  84,  45,  59,  40,  74,  61,  59,  56,  41,  83,  48,  53,  28,\n",
      "         15,   2,  49,  56,  23, 123,  49,   7,  74,  50,  81,   7,  27,  61,\n",
      "         81,  42,  36,  52,  81,  44,  82,  61,  12,  40,  27, 131,  12,  56,\n",
      "         82,  61,  12,  42,  25,  61,  39,  10,  99,  32,  39,   7,  82,  61,\n",
      "         39,  17,  33, 103,  39,  44,  36,  64,  39,  53,  25,  61,  43,  10,\n",
      "         82,  72,  43,   7])\n"
     ]
    }
   ],
   "source": [
    "for test in test_dataloader:\n",
    "    print(test.keys())\n",
    "    print(test['ids'][0])\n",
    "    print(test['input'][0])\n",
    "    # print(test['input_mask'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = set()\n",
    "for dic in train_dataset:\n",
    "    ipt = dic['input'].numpy()\n",
    "    vocab_set = vocab_set.union(set(ipt))\n",
    "vocab_size = len(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import ClassifierDataset\n",
    "classifier_dataset = ClassifierDataset(single_file_dataset_path, seq_len=max_seq_len, labels_path=\"data/emopia/EMOPIA_2.2/label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1, Q2, Q3, Q4 = [], [], [], []\n",
    "for dic in classifier_dataset:\n",
    "    label = dic['target']\n",
    "    if label == 0:\n",
    "        Q1.append(dic)\n",
    "    elif label == 1:\n",
    "        Q2.append(dic)\n",
    "    elif label == 2:\n",
    "        Q3.append(dic)\n",
    "    elif label == 3:\n",
    "        Q4.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_valid = {'Q1': Q1, 'Q2': Q2, 'Q3': Q3, 'Q4': Q4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.trainer import TransformerTrainer\n",
    "# from model.transformer import Generator, Discriminator, PatchDiscriminator\n",
    "# from utils.losses import MultiCrossEntropyLoss, TransfoCrossEntropyLoss,TransfoL1Loss, wgan_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = Generator(vocab_size, max_seq_len, dim=256)\n",
    "# discriminator = Discriminator(vocab_size, max_seq_len, dim=256)\n",
    "# patch_discriminator = PatchDiscriminator(vocab_size, max_seq_len, dim=256)\n",
    "\n",
    "# ce_loss = TransfoCrossEntropyLoss()\n",
    "# gan_loss = wgan_loss\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# generator.to(device)\n",
    "# discriminator.to(device)\n",
    "# patch_discriminator.to(device)\n",
    "\n",
    "# g_lr = 1e-4\n",
    "# d_lr = 1e-4\n",
    "\n",
    "# EPOCHS = 10\n",
    "# checkpoint_dir = \"checkpoints/model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = TransformerTrainer(generator, patch_discriminator, train_dataloader, train_dataloader, test_dataloader, ce_loss,\n",
    "#                gan_loss, device, g_lr, d_lr, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist = trainer.train( EPOCHS, checkpoint_dir, validate = False, log_interval=20, load=False, save=True, train_gan=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length, dropout=0.1):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, max_seq_length: int, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_seq_length, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        if src_mask is None:\n",
    "            \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
    "            Unmasked positions are filled with float(0.0).\n",
    "            \"\"\"\n",
    "            src_mask = nn.Transformer.generate_square_subsequent_mask(len(src)).to(device)\n",
    "            # Add padding mask if provided\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.linear(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/venv/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "ntokens = vocab_size  # size of vocabulary\n",
    "emsize = 256  # embedding dimension\n",
    "d_hid = 512  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 6  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 8  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.1  # dropout probability\n",
    "max_seq_length = max_seq_len\n",
    "model = TransformerModel(max_seq_len, ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (embedding): Embedding(198, 256)\n",
      "  (linear): Linear(in_features=256, out_features=198, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.001  # learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "epochs = 100  # The number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stopping(val_loss, epoch,best_loss,epochs_no_improve, patience=10):\n",
    "    if epoch == 0:\n",
    "        torch.save(model.state_dict(), 'checkpoints/transformer_v3.pt')\n",
    "        best_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        return False, best_loss, epochs_no_improve\n",
    "    else:\n",
    "        if val_loss < best_loss:\n",
    "            torch.save(model.state_dict(), 'checkpoints/transformer_v3.pt')\n",
    "            print(f\"Saved model at epoch { epoch } with validation loss of {val_loss}\")\n",
    "            best_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            return False, best_loss, epochs_no_improve\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print('Early stopping!')\n",
    "                return True, best_loss, epochs_no_improve\n",
    "            else:\n",
    "                return False, best_loss, epochs_no_improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the train valid losses for each epoch, and print them after epoch ends\n",
    "best_loss = 50\n",
    "epochs_no_improve = 0\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        src_data = batch['input'].to(device)\n",
    "        tgt_data = batch['target'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src_data)\n",
    "        loss = criterion(output.view(-1, vocab_size), tgt_data.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.item()\n",
    "    train_losses.append(train_loss/len(train_dataloader))\n",
    "\n",
    "    # evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dataloader:\n",
    "            src_data = batch['input'].to(device)\n",
    "            tgt_data = batch['target'].to(device)\n",
    "            output = model(src_data)\n",
    "            loss = criterion(output.view(-1, vocab_size), tgt_data.view(-1))\n",
    "            valid_loss+=loss.item()\n",
    "            \n",
    "    valid_losses.append(valid_loss/len(valid_dataloader))\n",
    "\n",
    "    print(\"Epoch: [ {} / {} ]; TrainLoss: {:.5f}; ValidLoss: {:.5f}\".format(\n",
    "        epoch, epochs, train_loss/len(train_dataloader), valid_loss/len(valid_dataloader)\n",
    "    ))\n",
    "\n",
    "\n",
    "    cond, best_loss, epochs_no_improve = early_stopping(valid_loss/len(valid_dataloader), epoch, best_loss,epochs_no_improve, patience=10)\n",
    "    if cond:\n",
    "        break\n",
    "    scheduler.step()\n",
    "print(\"Training complete!\")\n",
    "print(\"Best loss: \", best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModel(max_seq_len, ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
    "model.load_state_dict(torch.load(\"checkpoints/transformer_v3.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(input, seq_length):\n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(input), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and put it into features\n",
    "    for i, row in enumerate(input):\n",
    "        features[i, :len(row)] = np.array(row)[:seq_length]\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_dataloader:\n",
    "    data = batch['input'].to(device)\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "temperature = 1.0\n",
    "end_token = 1\n",
    "\n",
    "model.eval()\n",
    "# current_token = start_token\n",
    "generated_musics = []\n",
    "original_musics = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input = batch['input'].to(device)\n",
    "        target = batch['target'].to(device)\n",
    "        for i in range(len(input)):\n",
    "            generated_tokens = [input[i][0]]\n",
    "            output = model(input[i])\n",
    "            # Apply temperature to the output probabilities for diversity\n",
    "            probabilities = softmax(output.squeeze() / temperature, dim=-1)\n",
    "            for j in range(max_length):\n",
    "                current_token = torch.multinomial(probabilities[j], 1).item()\n",
    "                # current_token = torch.argmax(probabilities[j]).item()\n",
    "                if current_token == end_token:\n",
    "                    break\n",
    "                else:\n",
    "                    generated_tokens.append(current_token)\n",
    "\n",
    "            generated_musics.append(generated_tokens)\n",
    "            original_musics.append(target[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(generated_musics)):\n",
    "    midi_encoder_remi.words_to_midi(generated_musics[i],f'generated_musics/transformer_1/transformer{i}.mid')\n",
    "    midi_encoder_remi.words_to_midi(original_musics[i],f'generated_musics/original/original{i}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "temperature = 1.0\n",
    "end_token = 1\n",
    "\n",
    "model.eval()\n",
    "# current_token = start_token\n",
    "generated_musics = {'Q1':[], 'Q2':[], 'Q3':[], 'Q4':[]}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for c in classifier_valid.keys():\n",
    "        print(c)\n",
    "        for batch in classifier_valid[c]:\n",
    "            input = batch['input'].to(device)\n",
    "            target = batch['target'].to(device)\n",
    "            generated_tokens = [input[0]]\n",
    "            output = model(input)\n",
    "            # Apply temperature to the output probabilities for diversity\n",
    "            probabilities = softmax(output.squeeze() / temperature, dim=-1)\n",
    "            for j in range(max_length):\n",
    "                current_token = torch.multinomial(probabilities[j], 1).item()\n",
    "                # current_token = torch.argmax(probabilities[j]).item()\n",
    "                if current_token == end_token:\n",
    "                    break\n",
    "                else:\n",
    "                    generated_tokens.append(current_token)\n",
    "\n",
    "            generated_musics[c].append(generated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in generated_musics.keys():\n",
    "    for i in range(len(generated_musics[c])):\n",
    "        midi_encoder_remi.words_to_midi(generated_musics[c][i],f'generated_musics/transformer_1_by_emotion/{c}/transformer{i}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool().to(device)\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(198, 512)\n",
       "  (decoder_embedding): Embedding(198, 512)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (encoder_layers): ModuleList(\n",
       "    (0-5): 6 x EncoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-5): 6 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (cross_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=198, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab_size = vocab_size\n",
    "tgt_vocab_size = vocab_size\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 256\n",
    "max_seq_length = max_seq_len\n",
    "dropout = 0.2\n",
    "epochs = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def early_stopping(val_loss, epoch,best_loss,epochs_no_improve, patience=10, checkpoint_dir=\"checkpoints/transformer.pt\"):\n",
    "    if epoch == 0:\n",
    "        torch.save(transformer.state_dict(), 'checkpoints/transformer_v3.pt')\n",
    "        best_loss = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        return False, best_loss, epochs_no_improve\n",
    "    else:\n",
    "        if val_loss < best_loss:\n",
    "            torch.save(transformer.state_dict(), checkpoint_dir)\n",
    "            print(f\"Saved model at epoch { epoch } with validation loss of {val_loss}\")\n",
    "            best_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            return False, best_loss, epochs_no_improve\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print('Early stopping!')\n",
    "                return True, best_loss, epochs_no_improve\n",
    "            else:\n",
    "                return False, best_loss, epochs_no_improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0 / 100 ]; TrainLoss: 4.09126; ValidLoss: 3.37086\n",
      "Epoch: [ 1 / 100 ]; TrainLoss: 2.92880; ValidLoss: 2.59726\n",
      "Saved model at epoch 1 with validation loss of 2.5972578525543213\n",
      "Epoch: [ 2 / 100 ]; TrainLoss: 2.44035; ValidLoss: 2.17220\n",
      "Saved model at epoch 2 with validation loss of 2.1721986423839224\n",
      "Epoch: [ 3 / 100 ]; TrainLoss: 2.11424; ValidLoss: 1.95878\n",
      "Saved model at epoch 3 with validation loss of 1.9587845693935046\n",
      "Epoch: [ 4 / 100 ]; TrainLoss: 1.90648; ValidLoss: 1.74496\n",
      "Saved model at epoch 4 with validation loss of 1.7449626380747014\n",
      "Epoch: [ 5 / 100 ]; TrainLoss: 1.74554; ValidLoss: 1.62442\n",
      "Saved model at epoch 5 with validation loss of 1.6244169365275989\n",
      "Epoch: [ 6 / 100 ]; TrainLoss: 1.63880; ValidLoss: 1.50499\n",
      "Saved model at epoch 6 with validation loss of 1.504985971884294\n",
      "Epoch: [ 7 / 100 ]; TrainLoss: 1.53814; ValidLoss: 1.37726\n",
      "Saved model at epoch 7 with validation loss of 1.3772583116184582\n",
      "Epoch: [ 8 / 100 ]; TrainLoss: 1.43068; ValidLoss: 1.25304\n",
      "Saved model at epoch 8 with validation loss of 1.2530405738136985\n",
      "Epoch: [ 9 / 100 ]; TrainLoss: 1.32698; ValidLoss: 1.11400\n",
      "Saved model at epoch 9 with validation loss of 1.1139983914115212\n",
      "Epoch: [ 10 / 100 ]; TrainLoss: 1.21836; ValidLoss: 0.98405\n",
      "Saved model at epoch 10 with validation loss of 0.9840519861741499\n",
      "Epoch: [ 11 / 100 ]; TrainLoss: 1.10997; ValidLoss: 0.84608\n",
      "Saved model at epoch 11 with validation loss of 0.8460752097043124\n",
      "Epoch: [ 12 / 100 ]; TrainLoss: 0.99719; ValidLoss: 0.74264\n",
      "Saved model at epoch 12 with validation loss of 0.7426411346955732\n",
      "Epoch: [ 13 / 100 ]; TrainLoss: 0.89454; ValidLoss: 0.66067\n",
      "Saved model at epoch 13 with validation loss of 0.6606661623174493\n",
      "Epoch: [ 14 / 100 ]; TrainLoss: 0.79587; ValidLoss: 0.55793\n",
      "Saved model at epoch 14 with validation loss of 0.5579283833503723\n",
      "Epoch: [ 15 / 100 ]; TrainLoss: 0.70475; ValidLoss: 0.37424\n",
      "Saved model at epoch 15 with validation loss of 0.3742403875697743\n",
      "Epoch: [ 16 / 100 ]; TrainLoss: 0.60303; ValidLoss: 0.31625\n",
      "Saved model at epoch 16 with validation loss of 0.3162484954703938\n",
      "Epoch: [ 17 / 100 ]; TrainLoss: 0.51828; ValidLoss: 0.22497\n",
      "Saved model at epoch 17 with validation loss of 0.2249733250249516\n",
      "Epoch: [ 18 / 100 ]; TrainLoss: 0.41112; ValidLoss: 0.14790\n",
      "Saved model at epoch 18 with validation loss of 0.14790361442349173\n",
      "Epoch: [ 19 / 100 ]; TrainLoss: 0.32297; ValidLoss: 0.07843\n",
      "Saved model at epoch 19 with validation loss of 0.07843398167328401\n",
      "Epoch: [ 20 / 100 ]; TrainLoss: 0.24742; ValidLoss: 0.07208\n",
      "Saved model at epoch 20 with validation loss of 0.07208230549638922\n",
      "Epoch: [ 21 / 100 ]; TrainLoss: 0.18680; ValidLoss: 0.05045\n",
      "Saved model at epoch 21 with validation loss of 0.050449652427976784\n",
      "Epoch: [ 22 / 100 ]; TrainLoss: 0.13962; ValidLoss: 0.03548\n",
      "Saved model at epoch 22 with validation loss of 0.03548206846145066\n",
      "Epoch: [ 23 / 100 ]; TrainLoss: 0.10745; ValidLoss: 0.02273\n",
      "Saved model at epoch 23 with validation loss of 0.022733743556521156\n",
      "Epoch: [ 24 / 100 ]; TrainLoss: 0.08768; ValidLoss: 0.01869\n",
      "Saved model at epoch 24 with validation loss of 0.01869078522378748\n",
      "Epoch: [ 25 / 100 ]; TrainLoss: 0.06680; ValidLoss: 0.01646\n",
      "Saved model at epoch 25 with validation loss of 0.016458226791159672\n",
      "Epoch: [ 26 / 100 ]; TrainLoss: 0.05307; ValidLoss: 0.01450\n",
      "Saved model at epoch 26 with validation loss of 0.014496668919243595\n",
      "Epoch: [ 27 / 100 ]; TrainLoss: 0.09159; ValidLoss: 0.04292\n",
      "Epoch: [ 28 / 100 ]; TrainLoss: 0.05031; ValidLoss: 0.01306\n",
      "Saved model at epoch 28 with validation loss of 0.013062474571845749\n",
      "Epoch: [ 29 / 100 ]; TrainLoss: 0.03098; ValidLoss: 0.01192\n",
      "Saved model at epoch 29 with validation loss of 0.011916388672861185\n",
      "Epoch: [ 30 / 100 ]; TrainLoss: 0.02859; ValidLoss: 0.01180\n",
      "Saved model at epoch 30 with validation loss of 0.01180103878405961\n",
      "Epoch: [ 31 / 100 ]; TrainLoss: 0.02817; ValidLoss: 0.01133\n",
      "Saved model at epoch 31 with validation loss of 0.011329002678394318\n",
      "Epoch: [ 32 / 100 ]; TrainLoss: 0.02431; ValidLoss: 0.01150\n",
      "Epoch: [ 33 / 100 ]; TrainLoss: 0.02319; ValidLoss: 0.01052\n",
      "Saved model at epoch 33 with validation loss of 0.010524789040738886\n",
      "Epoch: [ 34 / 100 ]; TrainLoss: 0.02054; ValidLoss: 0.01052\n",
      "Saved model at epoch 34 with validation loss of 0.010516269640489058\n",
      "Epoch: [ 35 / 100 ]; TrainLoss: 0.01935; ValidLoss: 0.01021\n",
      "Saved model at epoch 35 with validation loss of 0.010205171832984144\n",
      "Epoch: [ 36 / 100 ]; TrainLoss: 0.02222; ValidLoss: 0.01024\n",
      "Epoch: [ 37 / 100 ]; TrainLoss: 0.01664; ValidLoss: 0.00959\n",
      "Saved model at epoch 37 with validation loss of 0.009588280227035284\n",
      "Epoch: [ 38 / 100 ]; TrainLoss: 0.01403; ValidLoss: 0.00993\n",
      "Epoch: [ 39 / 100 ]; TrainLoss: 0.01431; ValidLoss: 0.00959\n",
      "Saved model at epoch 39 with validation loss of 0.009586601772091606\n",
      "Epoch: [ 40 / 100 ]; TrainLoss: 0.01691; ValidLoss: 0.00943\n",
      "Saved model at epoch 40 with validation loss of 0.009427404115823183\n",
      "Epoch: [ 41 / 100 ]; TrainLoss: 0.01208; ValidLoss: 0.00944\n",
      "Epoch: [ 42 / 100 ]; TrainLoss: 0.01312; ValidLoss: 0.00965\n",
      "Epoch: [ 43 / 100 ]; TrainLoss: 0.01239; ValidLoss: 0.00944\n",
      "Epoch: [ 44 / 100 ]; TrainLoss: 0.01105; ValidLoss: 0.00981\n",
      "Epoch: [ 45 / 100 ]; TrainLoss: 0.01119; ValidLoss: 0.00950\n",
      "Epoch: [ 46 / 100 ]; TrainLoss: 0.03771; ValidLoss: 0.01204\n",
      "Epoch: [ 47 / 100 ]; TrainLoss: 0.01260; ValidLoss: 0.00894\n",
      "Saved model at epoch 47 with validation loss of 0.008944372858174822\n",
      "Epoch: [ 48 / 100 ]; TrainLoss: 0.00804; ValidLoss: 0.00934\n",
      "Epoch: [ 49 / 100 ]; TrainLoss: 0.00774; ValidLoss: 0.00920\n",
      "Epoch: [ 50 / 100 ]; TrainLoss: 0.00801; ValidLoss: 0.00949\n",
      "Epoch: [ 51 / 100 ]; TrainLoss: 0.00860; ValidLoss: 0.00976\n",
      "Epoch: [ 52 / 100 ]; TrainLoss: 0.00879; ValidLoss: 0.00991\n",
      "Epoch: [ 53 / 100 ]; TrainLoss: 0.00874; ValidLoss: 0.01013\n",
      "Epoch: [ 54 / 100 ]; TrainLoss: 0.00851; ValidLoss: 0.00996\n",
      "Epoch: [ 55 / 100 ]; TrainLoss: 0.00765; ValidLoss: 0.01016\n",
      "Epoch: [ 56 / 100 ]; TrainLoss: 0.02736; ValidLoss: 0.01071\n",
      "Epoch: [ 57 / 100 ]; TrainLoss: 0.01256; ValidLoss: 0.00975\n",
      "Early stopping!\n",
      "Training complete!\n",
      "Best loss:  0.008944372858174822\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "best_loss = 50\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# save the train valid losses for each epoch, and print them after epoch ends\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    transformer.train()\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        src_data = batch['input'].to(device)\n",
    "        tgt_data = batch['target'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = transformer(src_data, tgt_data[:, :-1])\n",
    "        loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+=loss.item()\n",
    "    train_losses.append(train_loss/len(train_dataloader))\n",
    "\n",
    "    # evaluate on validation set\n",
    "    transformer.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dataloader:\n",
    "            src_data = batch['input'].to(device)\n",
    "            tgt_data = batch['target'].to(device)\n",
    "            output = transformer(src_data, tgt_data[:, :-1])\n",
    "            loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "            valid_loss+=loss.item()\n",
    "            \n",
    "    valid_losses.append(valid_loss/len(valid_dataloader))\n",
    "\n",
    "    print(\"Epoch: [ {} / {} ]; TrainLoss: {:.5f}; ValidLoss: {:.5f}\".format(\n",
    "        epoch, epochs, train_loss/len(train_dataloader), valid_loss/len(valid_dataloader)\n",
    "    ))\n",
    "\n",
    "    # if epoch>=10:\n",
    "    #     if valid_loss < best_loss:\n",
    "    #         best_loss = valid_loss\n",
    "    #         print(\"Saving...\")\n",
    "    #         torch.save(transformer.state_dict(), \"checkpoints/transformer.pt\")\n",
    "    #         print(\"Model saved!\")\n",
    "    # early stopping\n",
    "    cond, best_loss, epochs_no_improve = early_stopping(valid_loss/len(valid_dataloader), epoch, best_loss,epochs_no_improve, patience=10)\n",
    "    if cond:\n",
    "        break\n",
    "\n",
    "print(\"Training complete!\")\n",
    "print(\"Best loss: \", best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a sequence from the transformer model using test dataloader from the best model\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "transformer.to(device)\n",
    "transformer.load_state_dict(torch.load(\"checkpoints/transformer.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "temperature = 1.0\n",
    "end_token = 1\n",
    "\n",
    "transformer.eval()\n",
    "# current_token = start_token\n",
    "generated_musics = []\n",
    "original_musics = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input = batch['input'].to(device)\n",
    "        target = batch['target'].to(device)\n",
    "        for i in range(len(input)):\n",
    "            generated_tokens = []\n",
    "            output = transformer(input[i].unsqueeze(0), target[i].unsqueeze(0))\n",
    "            # Apply temperature to the output probabilities for diversity\n",
    "            probabilities = softmax(output.squeeze() / temperature, dim=-1)\n",
    "\n",
    "            for j in range(max_length):\n",
    "                current_token = torch.multinomial(probabilities[j], 1).item()\n",
    "                generated_tokens.append(current_token)\n",
    "\n",
    "                if current_token == end_token:\n",
    "                    break\n",
    "                if len(generated_tokens) == max_length:\n",
    "                    break\n",
    "            generated_musics.append(generated_tokens)\n",
    "            original_musics.append(target[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(generated_musics)):\n",
    "    midi_encoder_remi.words_to_midi(generated_musics[i],f'generated_musics/transformer_2/transformer{i}.mid')\n",
    "    # midi_encoder_remi.words_to_midi(original_musics[i],f'generated_musics/original/original{i}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1\n",
      "Q2\n",
      "Q3\n",
      "Q4\n"
     ]
    }
   ],
   "source": [
    "max_length = 256\n",
    "temperature = 1.0\n",
    "end_token = 1\n",
    "\n",
    "transformer.eval()\n",
    "# current_token = start_token\n",
    "generated_musics = {'Q1':[], 'Q2':[], 'Q3':[], 'Q4':[]}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for c in classifier_valid.keys():\n",
    "        print(c)\n",
    "        for batch in classifier_valid[c]:\n",
    "            input = batch['input'].to(device)\n",
    "            target = torch.cat((input[1:], torch.tensor([0],dtype=torch.long).to(device)))\n",
    "            generated_tokens = [input[0]]\n",
    "\n",
    "            # for i in range(len(input)):\n",
    "            generated_tokens = []\n",
    "            output = transformer(input.unsqueeze(0), target.unsqueeze(0))\n",
    "            # Apply temperature to the output probabilities for diversity\n",
    "            probabilities = softmax(output.squeeze() / temperature, dim=-1)\n",
    "\n",
    "            for j in range(max_length):\n",
    "                current_token = torch.multinomial(probabilities[j], 1).item()\n",
    "\n",
    "                if current_token == end_token:\n",
    "                    break\n",
    "                else:\n",
    "                    generated_tokens.append(current_token)\n",
    "            generated_musics[c].append(generated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in generated_musics.keys():\n",
    "    for i in range(len(generated_musics[c])):\n",
    "        midi_encoder_remi.words_to_midi(generated_musics[c][i],f'generated_musics/transformer_2_by_emotion/{c}/transformer{i}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_name = \"generated_musics/transformer\"\n",
    "test = os.listdir(dir_name)\n",
    "\n",
    "for item in test:\n",
    "    if item.endswith(\".mid\"):\n",
    "        os.remove(os.path.join(dir_name, item))\n",
    "\n",
    "dir_name = \"generated_musics/original\"\n",
    "test = os.listdir(dir_name)\n",
    "\n",
    "for item in test:\n",
    "    if item.endswith(\".mid\"):\n",
    "        os.remove(os.path.join(dir_name, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, emsize, d_hid, nhead, nlayers, dropout):\n",
    "        super(Generator, self).__init__()\n",
    "        # TransformerModel(max_seq_len, ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
    "        self.transformer = TransformerModel(max_seq_len, vocab_size, emsize, nhead, d_hid, nlayers, dropout)\n",
    "        # self.fc = nn.Linear(dim, vocab_size)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        output = self.transformer(src)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel_classifier(nn.Module):\n",
    "\n",
    "    def __init__(self, max_seq_length: int, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_seq_length, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.embedding = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.linear = nn.Linear(d_model, ntoken)\n",
    "        self.fc = nn.Linear(d_model, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor = None) -> Tensor:\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        # if src_mask is None:\n",
    "        #     \"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n",
    "        #     Unmasked positions are filled with float(0.0).\n",
    "        #     \"\"\"\n",
    "        #     src_mask = nn.Transformer.generate_square_subsequent_mask(len(src)).to(device)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output,_ = torch.max(output, dim=1)              # x has shape (Batch, Embd_dim)\n",
    "        output = self.fc(output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, emsize, d_hid, nhead, nlayers, dropout):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.transformer = TransformerModel_classifier(max_seq_len, vocab_size, emsize, nhead, d_hid, nlayers, dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        output = self.transformer(src)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the generator\n",
    "\n",
    "netG = Generator(vocab_size, max_seq_len, emsize, d_hid, nhead, nlayers, dropout).to(device)\n",
    "# Create the Discriminator\n",
    "netD = Discriminator(vocab_size, max_seq_len, emsize, d_hid, nhead, nlayers, dropout).to(device)\n",
    "\n",
    "# Initialize the ``BCELoss`` function\n",
    "criterion_BCE = nn.BCELoss()\n",
    "\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create batch of latent vectors that we will use to visualize\n",
    "#  the progression of the generator\n",
    "nz = 100\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "temperature = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0/5][63/54]\tLoss_D: 1.5515\tLoss_G: 5.6418\tD(x): 0.7517\tD(G(z)): 0.7159 / 0.7159\n",
      "[0/5][63/54]\tLoss_D: 0.0364\tLoss_G: 3.1777\tD(x): 0.9807\tD(G(z)): 0.0168 / 0.0168\n",
      "[1/5][63/54]\tLoss_D: 0.0229\tLoss_G: 3.1077\tD(x): 0.9906\tD(G(z)): 0.0134 / 0.0134\n",
      "[1/5][63/54]\tLoss_D: 0.0824\tLoss_G: 2.9925\tD(x): 0.9519\tD(G(z)): 0.0326 / 0.0326\n",
      "[2/5][63/54]\tLoss_D: 0.0695\tLoss_G: 2.9593\tD(x): 0.9766\tD(G(z)): 0.0447 / 0.0447\n",
      "[2/5][63/54]\tLoss_D: 0.0316\tLoss_G: 2.9662\tD(x): 0.9797\tD(G(z)): 0.0110 / 0.0110\n",
      "[3/5][63/54]\tLoss_D: 0.0208\tLoss_G: 2.9278\tD(x): 0.9939\tD(G(z)): 0.0146 / 0.0146\n",
      "[3/5][63/54]\tLoss_D: 0.0103\tLoss_G: 2.9537\tD(x): 0.9937\tD(G(z)): 0.0040 / 0.0040\n",
      "[4/5][63/54]\tLoss_D: 0.0084\tLoss_G: 2.9120\tD(x): 0.9977\tD(G(z)): 0.0060 / 0.0060\n",
      "[4/5][63/54]\tLoss_D: 0.0059\tLoss_G: 2.9447\tD(x): 0.9966\tD(G(z)): 0.0025 / 0.0025\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "# Lists to keep track of progress\n",
    "txt_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for k, data in enumerate(train_dataloader):\n",
    "        input = data['input']\n",
    "        target = data['target'].to(device)\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        ## Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        # Format batch\n",
    "        real_cpu = input.to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through D\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # Calculate loss on all-real batch\n",
    "        errD_real = criterion_BCE(output, label)\n",
    "        # Calculate gradients for D in backward pass\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        # noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake = netG(real_cpu)\n",
    "        fake_probabilities = softmax(fake.squeeze() / temperature, dim=-1)\n",
    "        fake_mat = torch.zeros((b_size, max_seq_length), dtype=torch.long).to(device)\n",
    "        for i in range(b_size):\n",
    "            for j in range(max_seq_length):\n",
    "                fake_mat[i][j] = torch.multinomial(fake_probabilities[i][j], 1).item()\n",
    "        \n",
    "        label.fill_(fake_label)\n",
    "        # Classify all fake batch with D\n",
    "        output = netD(fake_mat).view(-1)\n",
    "        # Calculate D's loss on the all-fake batch\n",
    "        errD_fake = criterion_BCE(output, label)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute error of D as sum over the fake and the real batches\n",
    "        errD = errD_real + errD_fake\n",
    "        # Update D\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "        # output = netD(fake_mat).view(-1)\n",
    "        # Calculate G's loss based on this output\n",
    "        # errG = criterion(output, label)\n",
    "        errG = criterion_ce(fake.view(-1, vocab_size), target.view(-1))\n",
    "        # Calculate gradients for G\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Update G\n",
    "        optimizerG.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if k % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(train_dataloader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(real_cpu).detach().cpu()\n",
    "            fake_probabilities = softmax(fake.squeeze() / temperature, dim=-1)\n",
    "            fake_mat = torch.zeros((b_size, max_seq_length), dtype=torch.long).to(device)\n",
    "            for i in range(b_size):\n",
    "                for j in range(max_seq_length):\n",
    "                    fake_mat[i][j] = torch.multinomial(fake_probabilities[i][j], 1).item()\n",
    "            txt_list.append(fake_mat)\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "temperature = 1.0\n",
    "end_token = 1\n",
    "\n",
    "model.eval()\n",
    "# current_token = start_token\n",
    "generated_musics = []\n",
    "original_musics = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        input = batch['input'].to(device)\n",
    "        target = batch['target'].to(device)\n",
    "        for i in range(len(input)):\n",
    "            generated_tokens = []\n",
    "            output = netG(input[i])\n",
    "            # Apply temperature to the output probabilities for diversity\n",
    "            probabilities = softmax(output.squeeze() / temperature, dim=-1)\n",
    "            for j in range(max_length):\n",
    "                current_token = torch.multinomial(probabilities[j], 1).item()\n",
    "                # current_token = torch.argmax(probabilities[j]).item()\n",
    "                generated_tokens.append(current_token)\n",
    "\n",
    "                if current_token == end_token:\n",
    "                    break\n",
    "            generated_musics.append(generated_tokens)\n",
    "            # original_musics.append(target[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(generated_musics)):\n",
    "    midi_encoder_remi.words_to_midi(generated_musics[i],f'generated_musics/gan/gan{i}.mid')\n",
    "    # midi_encoder_remi.words_to_midi(original_musics[i],f'generated_musics/original/original{i}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1\n",
      "Q2\n",
      "Q3\n",
      "Q4\n"
     ]
    }
   ],
   "source": [
    "max_length = 256\n",
    "temperature = 1.0\n",
    "end_token = 1\n",
    "\n",
    "model.eval()\n",
    "# current_token = start_token\n",
    "generated_musics = {'Q1':[], 'Q2':[], 'Q3':[], 'Q4':[]}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for c in classifier_valid.keys():\n",
    "        print(c)\n",
    "        for batch in classifier_valid[c]:\n",
    "            input = batch['input'].to(device)\n",
    "            target = batch['target'].to(device)\n",
    "            generated_tokens = [input[0]]\n",
    "            output = netG(input)\n",
    "            # Apply temperature to the output probabilities for diversity\n",
    "            probabilities = softmax(output.squeeze() / temperature, dim=-1)\n",
    "            for j in range(max_length):\n",
    "                current_token = torch.multinomial(probabilities[j], 1).item()\n",
    "                # current_token = torch.argmax(probabilities[j]).item()\n",
    "                if current_token == end_token:\n",
    "                    break\n",
    "                else:\n",
    "                    generated_tokens.append(current_token)\n",
    "\n",
    "            generated_musics[c].append(generated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in generated_musics.keys():\n",
    "    for i in range(len(generated_musics[c])):\n",
    "        midi_encoder_remi.words_to_midi(generated_musics[c][i],f'generated_musics/gan_by_emotion/{c}/transformer{i}.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
