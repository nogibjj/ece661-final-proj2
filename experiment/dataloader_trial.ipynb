{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import muspy\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MIDIDataset(Dataset):\n",
    "    def __init__(self, data_path, label_path, transform=None, max_seq_length=1000):\n",
    "        self.data = pd.read_csv(label_path)  # Load labels from CSV\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_id = self.data['ID'][idx]  # Fetch file ID/name from CSV\n",
    "        label = self.data['4Q'][idx]  # Fetch label\n",
    "        \n",
    "        file_path = os.path.join(self.data_path, f\"{file_id}.mid\")\n",
    "        midi_data = muspy.read(file_path)  # Use MusPy to read MIDI files\n",
    "        \n",
    "        # Process MIDI data to extract required events\n",
    "        note_on_events = []\n",
    "        note_durations = []\n",
    "        velocities = []\n",
    "        tempos = []\n",
    "        bars = []\n",
    "        beats = []\n",
    "        \n",
    "        for track in midi_data.tracks:\n",
    "            for event in track:\n",
    "                if isinstance(event, muspy.Note):\n",
    "                    note_on_events.append(event.pitch)\n",
    "                    note_durations.append(event.duration)\n",
    "                    velocities.append(event.velocity)\n",
    "                elif isinstance(event, muspy.Tempo):\n",
    "                    tempos.append(event.qpm)\n",
    "                elif isinstance(event, muspy.TimeSignature):\n",
    "                    bars.append(event.numerator)\n",
    "                    beats.append(event.denominator)\n",
    "        \n",
    "        # Example: Extract number of note events\n",
    "        num_note_events = len(note_on_events)\n",
    "        \n",
    "        sample = {\n",
    "            'file_path': file_path,\n",
    "            'label': label,\n",
    "            'num_note_events': num_note_events,\n",
    "            'note_on_events': note_on_events,\n",
    "            'note_durations': note_durations,\n",
    "            'velocities': velocities,\n",
    "            'tempos': tempos,\n",
    "            'bars': bars,\n",
    "            'beats': beats\n",
    "        }\n",
    "\n",
    "\n",
    "        # Pad sequences to a fixed length\n",
    "        pad_value = 0  # You can choose a different value if needed\n",
    "        pad = lambda x, length: pad_sequence([torch.tensor(x)] * length, batch_first=True, padding_value=pad_value)\n",
    "        \n",
    "        note_on_events = pad(sample['note_on_events'], self.max_seq_length)\n",
    "        note_durations = pad(sample['note_durations'], self.max_seq_length)\n",
    "        velocities = pad(sample['velocities'], self.max_seq_length)\n",
    "        tempos = pad(sample['tempos'], self.max_seq_length)\n",
    "        bars = pad(sample['bars'], self.max_seq_length)\n",
    "        beats = pad(sample['beats'], self.max_seq_length)\n",
    "\n",
    "        sample = {\n",
    "            'file_path': file_path,\n",
    "            'label': label,\n",
    "            'num_note_events': num_note_events,\n",
    "            'note_on_events': note_on_events,\n",
    "            'note_durations': note_durations,\n",
    "            'velocities': velocities,\n",
    "            'tempos': tempos,\n",
    "            'bars': bars,\n",
    "            'beats': beats\n",
    "            # Add other extracted events here\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_path = '/workspaces/dl/Final Project/fork/data/emopia/EMOPIA_2.2/midis'\n",
    "label_path = '/workspaces/dl/Final Project/fork/data/emopia/EMOPIA_2.2/label_new.csv'\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "dataset = MIDIDataset(data_path, label_path)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Get the maximum sequence length in this batch\n",
    "    max_seq_length = max(len(item['note_on_events']) for item in batch)\n",
    "\n",
    "    # Prepare sequences for padding\n",
    "    padded_note_on_events = []\n",
    "    # Add other sequences like note_durations, velocities, etc.\n",
    "\n",
    "    # Pad or truncate sequences to the maximum length\n",
    "    for item in batch:\n",
    "        # Pad sequences to match the maximum length\n",
    "        padded_note_on_events.append(\n",
    "            torch.nn.functional.pad(torch.tensor(item['note_on_events']), (0, max_seq_length - len(item['note_on_events'])))\n",
    "        )\n",
    "        # Similarly, pad or truncate other sequences like note_durations, velocities, etc.\n",
    "\n",
    "    # Use pad_sequence to create batch tensors\n",
    "    padded_note_on_events = pad_sequence(padded_note_on_events, batch_first=True)\n",
    "    # Similarly, use pad_sequence for other sequences\n",
    "\n",
    "    return {\n",
    "        'note_on_events': padded_note_on_events,\n",
    "        # Add other padded sequences to the returned dictionary\n",
    "    }\n",
    "\n",
    "# Create your DataLoader with the collate_fn\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show sample from dataloader\n",
    "sample = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store file name as a csv\n",
    "file_names = []\n",
    "for i in range(len(os.listdir(data_path))):\n",
    "    file_names.append(os.listdir(data_path)[i][:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "df = pd.DataFrame(file_names, columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1_9v2WSpn4FCw_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2_dtS02mrDMsM_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3_3ZnxqCZ7qGg_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4_vpTguZtJAFA_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q3_Ie5koh4qvJc_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>Q1_miqLU2739dk_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>Q1_0vLPYiPN7qY_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>Q1_V3Y9L4UOcpk_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>Q3_gvWDOIiocuE_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>Q1_nOIBJHkqrE8_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1071 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID\n",
       "0     Q1_9v2WSpn4FCw_10\n",
       "1      Q2_dtS02mrDMsM_1\n",
       "2      Q3_3ZnxqCZ7qGg_0\n",
       "3      Q4_vpTguZtJAFA_2\n",
       "4      Q3_Ie5koh4qvJc_5\n",
       "...                 ...\n",
       "1066   Q1_miqLU2739dk_1\n",
       "1067   Q1_0vLPYiPN7qY_1\n",
       "1068   Q1_V3Y9L4UOcpk_2\n",
       "1069   Q3_gvWDOIiocuE_0\n",
       "1070   Q1_nOIBJHkqrE8_0\n",
       "\n",
       "[1071 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>4Q</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Q1_9v2WSpn4FCw_5</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Q1_9v2WSpn4FCw_6</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Q1_JT1XJnVmABo_2</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Q1_ldCQ6N9G6Mk_2</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Q2_9v2WSpn4FCw_1</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Q2_9v2WSpn4FCw_2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>Q4_JT1XJnVmABo_1</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   ID  4Q annotator\n",
       "58   Q1_9v2WSpn4FCw_5   1         A\n",
       "59   Q1_9v2WSpn4FCw_6   1         A\n",
       "92   Q1_JT1XJnVmABo_2   1         A\n",
       "208  Q1_ldCQ6N9G6Mk_2   1         A\n",
       "305  Q2_9v2WSpn4FCw_1   2         D\n",
       "306  Q2_9v2WSpn4FCw_2   2         D\n",
       "876  Q4_JT1XJnVmABo_1   4         C"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the file names in label.csv that are not in the df\n",
    "label_df[~label_df['ID'].isin(df['ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
